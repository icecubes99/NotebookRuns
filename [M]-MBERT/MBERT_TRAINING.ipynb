{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "548a5ea060b44acf8ede465864501951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed2d18dd55964cf9859dc302b99a3b1d",
              "IPY_MODEL_30518bb80d4f4ff6bcfff35076388c30",
              "IPY_MODEL_06fb591d4e7f4b4d8bb7c35cdbb3cadc"
            ],
            "layout": "IPY_MODEL_a81565df7f27432998bf439e815dd5b9"
          }
        },
        "ed2d18dd55964cf9859dc302b99a3b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b9a122288a43139d3632c45553a27a",
            "placeholder": "​",
            "style": "IPY_MODEL_276377ef1c164ba68b4faf1bee780593",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "30518bb80d4f4ff6bcfff35076388c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b45ab0a1b074dbbad5e9af74bf3a096",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a3d1340cdc443868dca7a153e89a649",
            "value": 49
          }
        },
        "06fb591d4e7f4b4d8bb7c35cdbb3cadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f4766015d34fd186bb72ce49c276d9",
            "placeholder": "​",
            "style": "IPY_MODEL_9a6c506697444fcca0f77144ba0e1bd7",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.85kB/s]"
          }
        },
        "a81565df7f27432998bf439e815dd5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b9a122288a43139d3632c45553a27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "276377ef1c164ba68b4faf1bee780593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b45ab0a1b074dbbad5e9af74bf3a096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a3d1340cdc443868dca7a153e89a649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1f4766015d34fd186bb72ce49c276d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6c506697444fcca0f77144ba0e1bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b3917ae832a490997b4a7e25ad7fb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d45fb8c8ae224f0f873dbaa4798d2258",
              "IPY_MODEL_ae90ac25b1db45fd98b7c90707600ab2",
              "IPY_MODEL_53717953c8d9429393c68d59b796d93a"
            ],
            "layout": "IPY_MODEL_abc254813d2c4e61ab68a73d4d80630e"
          }
        },
        "d45fb8c8ae224f0f873dbaa4798d2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa5db88dca104d3eb5a86dc31badb82d",
            "placeholder": "​",
            "style": "IPY_MODEL_4dbe8a94095b4ec3bc2777cb5807650b",
            "value": "config.json: 100%"
          }
        },
        "ae90ac25b1db45fd98b7c90707600ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c141ea7ca2403586b825b3ea08b5f9",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f704710f3204aa7be2978dc80b81af6",
            "value": 625
          }
        },
        "53717953c8d9429393c68d59b796d93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3188aacb9a246cd9a9d474086da05b4",
            "placeholder": "​",
            "style": "IPY_MODEL_1bc08a58e9194fe0afa214ebd568fdc3",
            "value": " 625/625 [00:00&lt;00:00, 81.3kB/s]"
          }
        },
        "abc254813d2c4e61ab68a73d4d80630e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5db88dca104d3eb5a86dc31badb82d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbe8a94095b4ec3bc2777cb5807650b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43c141ea7ca2403586b825b3ea08b5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f704710f3204aa7be2978dc80b81af6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3188aacb9a246cd9a9d474086da05b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc08a58e9194fe0afa214ebd568fdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f796b65ab3f64f7a827cfe3b665ded40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d36f7b3e8884a9c967d83becdf7a9ef",
              "IPY_MODEL_d8b802b73d8948ed9acff932cc771ec5",
              "IPY_MODEL_48970c28d33a41c5a7a9073a1a96e86e"
            ],
            "layout": "IPY_MODEL_ef74ff6c45db41499eb3b5166d6c8edd"
          }
        },
        "5d36f7b3e8884a9c967d83becdf7a9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eb90092be7b4232951fc4387161c894",
            "placeholder": "​",
            "style": "IPY_MODEL_571fed429b1f4c93bb225ff68441f1be",
            "value": "vocab.txt: 100%"
          }
        },
        "d8b802b73d8948ed9acff932cc771ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e4f3c3eedc9455784b1c29798535640",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_de4a952c5a634d149ffecef92021c54d",
            "value": 995526
          }
        },
        "48970c28d33a41c5a7a9073a1a96e86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16436a44765436f8cd15eaaf4c7eccc",
            "placeholder": "​",
            "style": "IPY_MODEL_ec334ca29bfb4cb7a4624c89913f1441",
            "value": " 996k/996k [00:00&lt;00:00, 6.91MB/s]"
          }
        },
        "ef74ff6c45db41499eb3b5166d6c8edd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb90092be7b4232951fc4387161c894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "571fed429b1f4c93bb225ff68441f1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e4f3c3eedc9455784b1c29798535640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4a952c5a634d149ffecef92021c54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d16436a44765436f8cd15eaaf4c7eccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec334ca29bfb4cb7a4624c89913f1441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9792db2d7f31434896dcb3f5b778a5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10ee317bb2a54aa4ae80c6b24410366c",
              "IPY_MODEL_16263bf7793147d4a677fa29c9d1b10e",
              "IPY_MODEL_5af39b4d30be433987b4787608190f17"
            ],
            "layout": "IPY_MODEL_5a36a32d81e04607b51adaa6ef6064ba"
          }
        },
        "10ee317bb2a54aa4ae80c6b24410366c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40678205fb8045cabb1b3f5ed4136600",
            "placeholder": "​",
            "style": "IPY_MODEL_dc2e499b255f40b58e7983147eaa0b2d",
            "value": "tokenizer.json: 100%"
          }
        },
        "16263bf7793147d4a677fa29c9d1b10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b008a43fe5a14486b46cdfcf296124ac",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b01510fda1840b6bc21a49e25762286",
            "value": 1961828
          }
        },
        "5af39b4d30be433987b4787608190f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c3543a5d454b0a925c982515f25ee2",
            "placeholder": "​",
            "style": "IPY_MODEL_de1592f610be4a56bf5a05b33f96c5c0",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 14.3MB/s]"
          }
        },
        "5a36a32d81e04607b51adaa6ef6064ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40678205fb8045cabb1b3f5ed4136600": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2e499b255f40b58e7983147eaa0b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b008a43fe5a14486b46cdfcf296124ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b01510fda1840b6bc21a49e25762286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48c3543a5d454b0a925c982515f25ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1592f610be4a56bf5a05b33f96c5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ae5bee3af104c1289d5d136c7ed01b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab469f64c1a44f17b8a8e5cd4b16f1b1",
              "IPY_MODEL_13f3985be7ff47059242164ada226467",
              "IPY_MODEL_2bdb1903eb8e4671be29a4b9317781c9"
            ],
            "layout": "IPY_MODEL_09189039878a487cbd52dc2bee637ab1"
          }
        },
        "ab469f64c1a44f17b8a8e5cd4b16f1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5449b6e87164f949c1bda182ad7a36b",
            "placeholder": "​",
            "style": "IPY_MODEL_f13a746f11fd499daa79c4681b1132d3",
            "value": "model.safetensors: 100%"
          }
        },
        "13f3985be7ff47059242164ada226467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7c6252ba304768ba6ac1dc84bff4ba",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23344f9b1d0240619d7f1810f62acf61",
            "value": 714290682
          }
        },
        "2bdb1903eb8e4671be29a4b9317781c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d1ce77fcaf24aaf86ef29754e39e526",
            "placeholder": "​",
            "style": "IPY_MODEL_fe3edb3fceb14867b259e92947a5f7e1",
            "value": " 714M/714M [00:10&lt;00:00, 57.7MB/s]"
          }
        },
        "09189039878a487cbd52dc2bee637ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5449b6e87164f949c1bda182ad7a36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13a746f11fd499daa79c4681b1132d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7c6252ba304768ba6ac1dc84bff4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23344f9b1d0240619d7f1810f62acf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d1ce77fcaf24aaf86ef29754e39e526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe3edb3fceb14867b259e92947a5f7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 1"
      ],
      "metadata": {
        "id": "1PEK4ueScFxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDy5SBFWV910",
        "outputId": "36d971cd-8470-481a-b269-360ac49498bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing pinned, compatible versions …\n",
            "NumPy: 2.1.1\n",
            "\n",
            "=== VERSION CHECK ===\n",
            "torch          : 2.9.0+cu128\n",
            "transformers   : 4.44.2\n",
            "accelerate     : 0.34.2\n",
            "datasets       : 2.21.0\n",
            "scikit-learn   : 1.5.2\n",
            "pandas         : 2.2.3\n",
            "numpy          : 2.1.1\n",
            "matplotlib     : 3.9.2\n",
            "\n",
            "CUDA Available: True\n",
            "CUDA Device Count: 1\n",
            "Current CUDA Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SECTION 1: ENVIRONMENT SETUP (ROBUST, PY3.12-FRIENDLY)\n",
        "# ============================================================================\n",
        "\n",
        "import sys, subprocess, importlib, os\n",
        "\n",
        "def pipi(*pkgs):\n",
        "    # Force reinstall + no cache to avoid stale wheels\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"--force-reinstall\", \"--no-cache-dir\", *pkgs])\n",
        "\n",
        "print(\"Installing pinned, compatible versions …\")\n",
        "# Torch: keep your existing CUDA build. If you don't have torch yet, uncomment the torch trio below.\n",
        "# pipi(\"torch==2.2.2\", \"torchaudio==2.2.2\", \"torchvision==0.17.2\")\n",
        "\n",
        "# Pin NumPy 2.x and libs that are built against it\n",
        "pipi(\n",
        "    \"numpy==2.1.1\",\n",
        "    \"pandas==2.2.3\",\n",
        "    \"scikit-learn==1.5.2\",\n",
        "    \"matplotlib==3.9.2\",\n",
        "    \"transformers==4.44.2\",\n",
        "    \"accelerate==0.34.2\",\n",
        "    \"datasets==2.21.0\",\n",
        ")\n",
        "\n",
        "# --- Import order matters; import numpy FIRST to catch ABI issues clearly\n",
        "import numpy as np\n",
        "print(\"NumPy:\", np.__version__)\n",
        "\n",
        "# Now the rest\n",
        "import torch, transformers, datasets, sklearn, pandas as pd, matplotlib, importlib\n",
        "\n",
        "print(\"\\n=== VERSION CHECK ===\")\n",
        "print(\"torch          :\", getattr(torch, \"__version__\", \"n/a\"))\n",
        "print(\"transformers   :\", transformers.__version__)\n",
        "print(\"accelerate     :\", importlib.import_module(\"accelerate\").__version__)\n",
        "print(\"datasets       :\", datasets.__version__)\n",
        "print(\"scikit-learn   :\", sklearn.__version__)\n",
        "print(\"pandas         :\", pd.__version__)\n",
        "print(\"numpy          :\", np.__version__)\n",
        "print(\"matplotlib     :\", matplotlib.__version__)\n",
        "\n",
        "# Sanity for TrainingArguments modern kwargs\n",
        "from packaging import version\n",
        "assert version.parse(transformers.__version__) >= version.parse(\"4.26.0\"), \\\n",
        "    \"Transformers too old for `evaluation_strategy`.\"\n",
        "\n",
        "# If NumPy was previously imported in this session, you may still have stale .so’s in memory.\n",
        "# Simple guard: if you see an ABI error above, Restart runtime and run this cell again first.\n",
        "print(\"\\nCUDA Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
        "    print(\"Current CUDA Device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SECTION 1.5\n"
      ],
      "metadata": {
        "id": "8YTTcGb6L7tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 1.5: VERSION CHECK + TRAININGARGUMENTS COMPATIBILITY SHIM\n",
        "# ============================================================================\n",
        "\n",
        "import inspect, importlib, sys\n",
        "import transformers as _tf\n",
        "\n",
        "print(\"Transformers version loaded in memory:\", _tf.__version__)\n",
        "\n",
        "def _supported_kwargs_of_training_args():\n",
        "    # Build the set of supported __init__ kwargs for the loaded TrainingArguments\n",
        "    try:\n",
        "        from transformers import TrainingArguments\n",
        "        sig = inspect.signature(TrainingArguments.__init__)\n",
        "        return set(sig.parameters.keys())\n",
        "    except Exception as e:\n",
        "        print(\"[Compat] Could not inspect TrainingArguments:\", e)\n",
        "        return set()\n",
        "\n",
        "_SUPPORTED_TA_KEYS = _supported_kwargs_of_training_args()\n",
        "print(\"Sample of supported TrainingArguments kwargs:\", sorted(list(_SUPPORTED_TA_KEYS))[:12], \"...\")\n",
        "\n",
        "def make_training_args_compat(**kwargs):\n",
        "    \"\"\"\n",
        "    Create TrainingArguments while dropping any kwargs unsupported by the loaded transformers version.\n",
        "    Prints what was ignored so you know if your runtime is old.\n",
        "    \"\"\"\n",
        "    from transformers import TrainingArguments\n",
        "    filtered = {k: v for k, v in kwargs.items() if k in _SUPPORTED_TA_KEYS}\n",
        "    ignored = [k for k in kwargs.keys() if k not in _SUPPORTED_TA_KEYS]\n",
        "    if ignored:\n",
        "        print(\"[Compat] Ignored unsupported TrainingArguments keys:\", ignored)\n",
        "    return TrainingArguments(**filtered)\n",
        "\n",
        "def get_early_stopping_callbacks(patience: int):\n",
        "    \"\"\"Return EarlyStoppingCallback if available; otherwise return [].\"\"\"\n",
        "    try:\n",
        "        from transformers import EarlyStoppingCallback\n",
        "        return [EarlyStoppingCallback(early_stopping_patience=patience)]\n",
        "    except Exception as e:\n",
        "        print(\"[Compat] EarlyStoppingCallback unavailable:\", e)\n",
        "        return []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oBBJ_lPL7VW",
        "outputId": "601f9b73-54e5-4d24-8d4c-1e1abb4f9c18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version loaded in memory: 4.44.2\n",
            "Sample of supported TrainingArguments kwargs: ['accelerator_config', 'adafactor', 'adam_beta1', 'adam_beta2', 'adam_epsilon', 'auto_find_batch_size', 'batch_eval_metrics', 'bf16', 'bf16_full_eval', 'data_seed', 'dataloader_drop_last', 'dataloader_num_workers'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 2"
      ],
      "metadata": {
        "id": "cG7la9p-cDKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 2: IMPORTS AND BASIC SETUP\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "# ============================================================================\n",
        "# TIMING UTILITY - Track execution time for each section\n",
        "# ============================================================================\n",
        "class SectionTimer:\n",
        "    def __init__(self):\n",
        "        self.section_times = {}\n",
        "        self.start_time = None\n",
        "        self.total_start = time.time()\n",
        "\n",
        "    def start_section(self, section_name):\n",
        "        \"\"\"Start timing a section\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        print(f\"\\n🚀 Starting {section_name}...\")\n",
        "\n",
        "    def end_section(self, section_name):\n",
        "        \"\"\"End timing and display results\"\"\"\n",
        "        if self.start_time is None:\n",
        "            self.start_time = time.time()\n",
        "\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.section_times[section_name] = elapsed\n",
        "\n",
        "        # Format time nicely\n",
        "        if elapsed < 60:\n",
        "            time_str = f\"{elapsed:.1f}s\"\n",
        "        elif elapsed < 3600:\n",
        "            time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
        "        else:\n",
        "            time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
        "\n",
        "        total_elapsed = time.time() - self.total_start\n",
        "        if total_elapsed < 60:\n",
        "            total_str = f\"{total_elapsed:.1f}s\"\n",
        "        elif total_elapsed < 3600:\n",
        "            total_str = f\"{total_elapsed/60:.1f}m {total_elapsed%60:.0f}s\"\n",
        "        else:\n",
        "            total_str = f\"{total_elapsed/3600:.1f}h {(total_elapsed%3600)/60:.0f}m\"\n",
        "\n",
        "        print(f\"✅ {section_name} completed in {time_str}\")\n",
        "        print(f\"🕒 Total runtime so far: {total_str}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def get_summary(self):\n",
        "        \"\"\"Get timing summary\"\"\"\n",
        "        total = time.time() - self.total_start\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"⏱️  EXECUTION TIME SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        for section, elapsed in self.section_times.items():\n",
        "            if elapsed < 60:\n",
        "                time_str = f\"{elapsed:.1f}s\"\n",
        "            elif elapsed < 3600:\n",
        "                time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
        "            else:\n",
        "                time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
        "            print(f\"{section:<40} : {time_str}\")\n",
        "\n",
        "        if total < 60:\n",
        "            total_str = f\"{total:.1f}s\"\n",
        "        elif total < 3600:\n",
        "            total_str = f\"{total/60:.1f}m {total%60:.0f}s\"\n",
        "        else:\n",
        "            total_str = f\"{total/3600:.1f}h {(total%3600)/60:.0f}m\"\n",
        "\n",
        "        print(f\"{'='*40} : {'='*10}\")\n",
        "        print(f\"{'TOTAL EXECUTION TIME':<40} : {total_str}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "# Initialize global timer\n",
        "timer = SectionTimer()\n",
        "timer.start_section(\"SECTION 2: Environment & Imports\")\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# End timing for section 2\n",
        "timer.end_section(\"SECTION 2: Environment & Imports\")\n",
        "timer.start_section(\"SECTION 3: Configuration Setup\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSVM6xD6WkaF",
        "outputId": "83def2d2-df8e-4967-adb5-c3780fabd70c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Starting SECTION 2: Environment & Imports...\n",
            "✅ SECTION 2: Environment & Imports completed in 9.1s\n",
            "🕒 Total runtime so far: 9.1s\n",
            "------------------------------------------------------------\n",
            "\n",
            "🚀 Starting SECTION 3: Configuration Setup...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, TrainingArguments, Trainer,\n",
        "    DataCollatorWithPadding, EarlyStoppingCallback, set_seed\n",
        ")\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    import transformers\n",
        "    transformers.set_seed(seed)  # 🔧 RUN #9 FIX: Comprehensive transformers seed (sets all seeds including random, numpy, torch)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYH7gi4mWNTj",
        "outputId": "184af42c-106c-4ed1-db3b-e3e1451f780e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 3"
      ],
      "metadata": {
        "id": "F5jkDOC6cAXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🤖 TRAINING ONLY: mBERT (bert-base-multilingual-cased)\\n\n",
        "# Expected: ~35-40 min, 60-65% macro-F1\\n\n",
        "\n",
        "# ===== Section 3 — Config (pooling + R-Drop + LLRD) =====\n",
        "\n",
        "data_path = '/content/augmented_adjudications_2025-10-22.csv'\n",
        "CSV_PATH = '/content/augmented_adjudications_2025-10-22.csv'\n",
        "\n",
        "\n",
        "TITLE_COL = \"Title\"\n",
        "TEXT_COL  = \"Comment\"\n",
        "SENT_COL  = \"Final Sentiment\"\n",
        "POL_COL   = \"Final Polarization\"\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    \"mbert\": {\"name\": \"bert-base-multilingual-cased\", \"desc\": \"mBERT (104 langs)\"},\n",
        "}\n",
        "MODELS_TO_RUN = [\"mbert\"]  # ← TRAINING ONLY mBERT\n",
        "OUT_DIR = \"./runs_mbert_optimized\"  # ← Separate output directory\n",
        "\n",
        "# ============================================================================\n",
        "# CORE TRAINING - RUN #10-13: SEED ENSEMBLE STRATEGY (4 SEEDS FOR +1-2% BOOST)\n",
        "# Run #9 Result: 62.74% Macro-F1 (✅ NEW BEST! +0.68% over R4!)\n",
        "# Key Finding: Seed matters! Same hyperparameters, different seed → +0.68% improvement\n",
        "# Run #10-13 Strategy: TRAIN 4 MODELS WITH DIFFERENT SEEDS (42, 43, 44, 45) + ENSEMBLE\n",
        "# Expected Outcome:\n",
        "#   - Each model: 62-63% Macro-F1 (consistent with R9)\n",
        "#   - Ensemble (average predictions): 64-65% Macro-F1 (+1-2% from ensemble diversity)\n",
        "# How to use:\n",
        "#   Run #10: Set SEED = 42 (already done in R9, baseline)\n",
        "#   Run #11: Set SEED = 43, re-run notebook\n",
        "#   Run #12: Set SEED = 44, re-run notebook\n",
        "#   Run #13: Set SEED = 45, re-run notebook\n",
        "#   Then ensemble predictions by averaging logits/probabilities\n",
        "# Expected training time per model: ~93 minutes (same as R9)\n",
        "# Total time for 4 models: ~6 hours\n",
        "# ============================================================================\n",
        "\n",
        "# 🎯 SEED CONFIGURATION\n",
        "# Run #10-13: Seed ensemble complete (58.28% to 63.06% variance - seed 42 is best!)\n",
        "# Run #14: ARCHITECTURAL DISASTER (-5.3%) - proved massive changes are harmful!\n",
        "# Run #15: SEQUENCE LENGTH OPTIMIZATION - Research-backed quick win!\n",
        "SEED = 42  # 🔥 Use best seed (42) proven in R9-R10\n",
        "\n",
        "# ============================================================================\n",
        "# CORE HYPERPARAMETERS - RUN #15: SEQUENCE LENGTH OPTIMIZATION\n",
        "# Strategy: R9 proven config + RESEARCH-BACKED sequence length increase\n",
        "# Research: Sequence length 320 achieved 71.7% F1 in NIH study (PMC9051848)\n",
        "# Expected: +1-3% from better context capture\n",
        "# ============================================================================\n",
        "MAX_LENGTH = 320            # ⬆️ RESEARCH-BACKED OPTIMAL (was 224, +43% more context!)\n",
        "EPOCHS = 20                 # ✅ RESTORE R9 PROVEN (R14's changes failed!)\n",
        "BATCH_SIZE = 12            # ⬇️ KEEP 12 (compensate for longer sequences)\n",
        "LR = 2.5e-5               # ✅ RESTORE R9 PROVEN (2.0e-5 in R14 was too conservative)\n",
        "WEIGHT_DECAY = 0.03       # ✅ RESTORE R9 PROVEN (R14's 0.04 was over-regularizing)\n",
        "WARMUP_RATIO = 0.20       # ✅ RESTORE R9 PROVEN (R14's 0.25 was unnecessary)\n",
        "EARLY_STOP_PATIENCE = 8   # ✅ RESTORE R9 PROVEN (R14's 10 allowed overfitting)\n",
        "GRAD_ACCUM_STEPS = 4      # ⬆️ KEEP 4 (maintain effective batch 48 for longer sequences)\n",
        "\n",
        "# Per-task loss - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "USE_FOCAL_SENTIMENT = True\n",
        "USE_FOCAL_POLARITY  = True\n",
        "FOCAL_GAMMA_SENTIMENT = 2.5   # ✅ R9 PROVEN\n",
        "FOCAL_GAMMA_POLARITY = 3.5    # ✅ R9 PROVEN\n",
        "LABEL_SMOOTH_SENTIMENT = 0.10 # ✅ R9 PROVEN\n",
        "LABEL_SMOOTH_POLARITY = 0.08  # ✅ R9 PROVEN\n",
        "\n",
        "# Task weights - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "TASK_LOSS_WEIGHTS = {\"sentiment\": 1.0, \"polarization\": 1.4}  # ✅ R9 PROVEN\n",
        "\n",
        "# Gradient control - RUN #10-13: R9 CONFIGURATION (task-specific disabled, proven harmful in R7!)\n",
        "USE_TASK_SPECIFIC_GRAD_NORM = False  # ✅ DISABLED (R7 proved this is HARMFUL!)\n",
        "MAX_GRAD_NORM = 0.5          # ✅ R9 PROVEN (from R4)\n",
        "USE_GRADIENT_CHECKPOINTING = True  # Memory efficiency\n",
        "\n",
        "# ============================================================================\n",
        "# AGGRESSIVE CLASS WEIGHTS - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Run #5 showed: 1.30 negative weight WORSENED recall (47.5%→40.3%)!\n",
        "# negative: Keep R9's 1.10 (1.30 backfired spectacularly)\n",
        "# neutral: Keep R9's 1.80 (working with oversampling)\n",
        "# objective: Keep R4's 2.50 (working well)\n",
        "# ============================================================================\n",
        "CLASS_WEIGHT_MULT = {\n",
        "    \"sentiment\": {\n",
        "        \"negative\": 1.10,    # ✅ RESTORE R4 from 1.30 (1.30 made recall WORSE!)\n",
        "        \"neutral\":  1.80,    # ✅ RESTORE R4 (working with oversampling)\n",
        "        \"positive\": 1.30     # ✅ RESTORE R4\n",
        "    },\n",
        "    \"polarization\": {\n",
        "        \"non_polarized\": 1.20,  # ✅ RESTORE R4\n",
        "        \"objective\":     2.50,  # ✅ RESTORE R4 (working well)\n",
        "        \"partisan\":      0.95   # ✅ RESTORE R4\n",
        "    }\n",
        "}\n",
        "\n",
        "# Cap maximum class weight to prevent instability\n",
        "MAX_CLASS_WEIGHT = 10.0  # 🔥 INCREASED (was 6.0) - Allow stronger weighting for weak classes\n",
        "\n",
        "# ============================================================================\n",
        "# SELECTIVE OVERSAMPLING - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Run #5 showed: 10x objective + 3x neutral = DISASTER (non-polarized -8.2%!)\n",
        "# Run #4's 8.5x/3.5x balance was OPTIMAL - proven stable in R9\n",
        "# Goal: Keep R9 configuration, only vary seed for ensemble\n",
        "# ============================================================================\n",
        "USE_OVERSAMPLING = True\n",
        "USE_JOINT_OVERSAMPLING = True\n",
        "USE_SMART_OVERSAMPLING = True\n",
        "JOINT_ALPHA = 0.70              # ✅ RESTORE R4 (was effective)\n",
        "JOINT_OVERSAMPLING_MAX_MULT = 8.0  # ✅ RESTORE R4\n",
        "OBJECTIVE_BOOST_MULT = 8.5      # ✅ RESTORE R4 from 10.0 (10x destroyed non-polarized!)\n",
        "NEUTRAL_BOOST_MULT = 3.5        # ✅ RESTORE R4 from 3.0 (3x removed critical signal!)\n",
        "\n",
        "# ============================================================================\n",
        "# ARCHITECTURE - RUN #15: RESTORE R9 PROVEN SIMPLE DESIGN\n",
        "# R14 Lesson: Massive architectural changes (-5.3% regression!) proved harmful!\n",
        "# R15 Strategy: Restore proven simple architecture, focus on data/sequence length\n",
        "# Goal: +1-3% improvement from sequence length optimization (Target: 64-66%)\n",
        "# ============================================================================\n",
        "HEAD_HIDDEN = 768            # ✅ RESTORE R9 PROVEN (R14's 1536 caused severe overfitting!)\n",
        "HEAD_DROPOUT = 0.25          # ✅ RESTORE R9 PROVEN (R14's 0.30 was over-regularizing)\n",
        "REP_POOLING = \"last4_mean\"   # ✅ RESTORE R9 PROVEN (R14's attention pooling had issues)\n",
        "HEAD_LAYERS = 3              # ✅ RESTORE R9 PROVEN (R14's 4 layers were too deep)\n",
        "\n",
        "# ❌ REMOVE ALL R14 ARCHITECTURAL COMPLEXITY (ALL PROVEN HARMFUL!)\n",
        "USE_TASK_SPECIFIC_PROJECTIONS = False   # ❌ DISABLED (reduced shared learning)\n",
        "USE_RESIDUAL_CONNECTIONS = False        # ❌ DISABLED (over-engineering, no benefit)\n",
        "USE_MULTI_SAMPLE_DROPOUT = False        # ❌ DISABLED (increased time, unstable)\n",
        "MULTI_SAMPLE_DROPOUT_NUM = 1            # ❌ NOT USED (disabled)\n",
        "USE_ATTENTION_POOLING_MULTI_HEAD = False # ❌ DISABLED (caused float16 issues)\n",
        "\n",
        "# ============================================================================\n",
        "# REGULARIZATION - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# ============================================================================\n",
        "USE_RDROP = True\n",
        "RDROP_ALPHA = 0.6           # ✅ R9 PROVEN (from R4)\n",
        "RDROP_WARMUP_EPOCHS = 2     # ✅ R9 PROVEN (from R4)\n",
        "\n",
        "# LLRD (layer-wise learning-rate decay) - RUN #10-13: R9 CONFIGURATION\n",
        "USE_LLRD = True\n",
        "LLRD_DECAY = 0.90            # ✅ R9 PROVEN (from R4)\n",
        "HEAD_LR_MULT = 3.0           # ✅ R9 PROVEN (from R4)\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION SUMMARY\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(f\"🎯 mBERT TRAINING - RUN #15: SEQUENCE LENGTH OPTIMIZATION (SEED = {SEED})\")\n",
        "print(\"=\"*80)\n",
        "print(f\"📊 Run History:\")\n",
        "print(f\"   R1→R8: 58.5%-61.99% (hyperparameter tuning)\")\n",
        "print(f\"   R9-R10: 62.74%-63.06% 🏆 BEST BASELINE (seed 42)\")\n",
        "print(f\"   R11-R13: 58.28%-62.45% (seed ensemble - 4.78% variance)\")\n",
        "print(f\"   R14: 57.76% ❌ DISASTER (-5.3%) - architectural overreach failed!\")\n",
        "print(f\"   Key Finding: Simple architecture works best, need data-centric approach!\")\n",
        "print(f\"   R15 Strategy: SEQUENCE LENGTH OPTIMIZATION + PREPARE FOR AUGMENTATION\")\n",
        "print(f\"\")\n",
        "print(f\"🎲 Current Seed: {SEED} (best seed from R9-R13 experiments)\")\n",
        "print(f\"\")\n",
        "print(f\"🎯 Run #15 Goal: QUICK WIN VIA SEQUENCE LENGTH + DATA PREP\")\n",
        "print(f\"   ├─ Current best: 63.06% (R10, seed 42)\")\n",
        "print(f\"   ├─ Target: 64-66% Macro-F1 (+1-3% from sequence length)\")\n",
        "print(f\"   ├─ Strategy: MAX_LENGTH 224 → 320 (research-backed optimal)\")\n",
        "print(f\"   ├─ Next steps: Data augmentation for Track 1 (75% breakthrough)\")\n",
        "print(f\"   └─ Long-term target: 75% Macro-F1 via multi-track strategy\")\n",
        "print(f\"\")\n",
        "print(f\"📏 SEQUENCE LENGTH OPTIMIZATION (RESEARCH-BACKED):\")\n",
        "print(f\"   ├─ MAX_LENGTH: 224 → {MAX_LENGTH} (+43% more context!)\")\n",
        "print(f\"   ├─ Research: Length 320 achieved 71.7% F1 in NIH study (PMC9051848)\")\n",
        "print(f\"   ├─ Rationale: News articles have important late-text context\")\n",
        "print(f\"   └─ Why it works: Sentiment/polarization signals may appear late in text\")\n",
        "print()\n",
        "print(f\"⏱️  Training Configuration (R9 PROVEN + SEQUENCE LENGTH ADJUSTMENT):\")\n",
        "print(f\"   ├─ Epochs: {EPOCHS} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Batch Size: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM_STEPS}) ⬇️ Adjusted for longer sequences\")\n",
        "print(f\"   ├─ Learning Rate: {LR} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Weight Decay: {WEIGHT_DECAY} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Warmup Ratio: {WARMUP_RATIO} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Early Stop Patience: {EARLY_STOP_PATIENCE} ✅ R9 PROVEN\")\n",
        "print(f\"   └─ Estimated Time: ~95-105 minutes (similar to R9, slightly longer sequences)\")\n",
        "print()\n",
        "print(f\"🏗️  Architecture (R9 PROVEN SIMPLE DESIGN - R14 COMPLEXITY REMOVED):\")\n",
        "print(f\"   ├─ Head Hidden: {HEAD_HIDDEN} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Head Layers: {HEAD_LAYERS} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Head Dropout: {HEAD_DROPOUT} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Pooling: {REP_POOLING} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Task Projections: {USE_TASK_SPECIFIC_PROJECTIONS} ❌ DISABLED (R14 proved harmful)\")\n",
        "print(f\"   ├─ Residual Connections: {USE_RESIDUAL_CONNECTIONS} ❌ DISABLED (R14 proved harmful)\")\n",
        "print(f\"   └─ Multi-Sample Dropout: {USE_MULTI_SAMPLE_DROPOUT} ❌ DISABLED (R14 proved harmful)\")\n",
        "print()\n",
        "print(f\"⚖️  Critical Class Weights (R9 PROVEN):\")\n",
        "print(f\"   ├─ Negative:  {CLASS_WEIGHT_MULT['sentiment']['negative']}x ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Neutral:   {CLASS_WEIGHT_MULT['sentiment']['neutral']}x ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Objective: {CLASS_WEIGHT_MULT['polarization']['objective']}x ✅ R9 PROVEN\")\n",
        "print(f\"   └─ Max Weight Cap: {MAX_CLASS_WEIGHT} ✅ R9 PROVEN\")\n",
        "print()\n",
        "print(f\"📊 Oversampling Strategy (R9 PROVEN):\")\n",
        "print(f\"   ├─ Joint Alpha: {JOINT_ALPHA} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Max Multiplier: {JOINT_OVERSAMPLING_MAX_MULT}x ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Objective Boost: {OBJECTIVE_BOOST_MULT}x ✅ R9 PROVEN\")\n",
        "print(f\"   └─ Neutral Boost: {NEUTRAL_BOOST_MULT}x ✅ R9 PROVEN\")\n",
        "print()\n",
        "print(f\"❌ TASK-SPECIFIC GRADIENT CONTROL: DISABLED (R7 proved this is HARMFUL!):\")\n",
        "print(f\"   ├─ Feature Enabled: {USE_TASK_SPECIFIC_GRAD_NORM} ✅ DISABLED\")\n",
        "print(f\"   ├─ Global MAX_GRAD_NORM: {MAX_GRAD_NORM} ✅ R9 PROVEN\")\n",
        "print(f\"   └─ R7 Lesson: Task-specific gradients caused -7.91% regression (worst run ever)\")\n",
        "print()\n",
        "print(f\"🔥 Advanced Techniques (R9 PROVEN - ALL PARAMETERS FROM BEST RUN):\")\n",
        "print(f\"   ├─ Focal Loss Gamma (Sent/Pol): {FOCAL_GAMMA_SENTIMENT}/{FOCAL_GAMMA_POLARITY} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Label Smoothing (Sent/Pol): {LABEL_SMOOTH_SENTIMENT}/{LABEL_SMOOTH_POLARITY} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ Task Weights (Sent/Pol): {TASK_LOSS_WEIGHTS['sentiment']}/{TASK_LOSS_WEIGHTS['polarization']} ✅ R9 PROVEN\")\n",
        "print(f\"   ├─ R-Drop Alpha: {RDROP_ALPHA} ✅ R9 PROVEN\")\n",
        "print(f\"   └─ LLRD Decay: {LLRD_DECAY} ✅ R9 PROVEN\")\n",
        "print()\n",
        "print(f\"🎯 Run #15 Expected Results:\")\n",
        "print(f\"   ├─ Target: 64-66% Macro-F1 (+1-3% from sequence length)\")\n",
        "print(f\"   ├─ Strategy: Research-backed MAX_LENGTH=320 for better context\")\n",
        "print(f\"   ├─ Next Step: Data augmentation (back-translation for weak classes)\")\n",
        "print(f\"   └─ Breakthrough Path: Multi-track strategy to 75% (see BREAKTHROUGH_STRATEGY_TO_75_PERCENT.md)\")\n",
        "print()\n",
        "print(f\"📁 Output: {OUT_DIR}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 🎲 Apply the configured seed (overrides the default seed_all(42) from Cell 6)\n",
        "seed_all(SEED)\n",
        "print(f\"✅ Seed {SEED} applied successfully!\")\n",
        "print()\n",
        "\n",
        "# End timing for section 3\n",
        "timer.end_section(\"SECTION 3: Configuration Setup\")\n",
        "timer.start_section(\"SECTION 4: Data Loading & Preprocessing\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bDchgs1WPUm",
        "outputId": "d9bc6004-2afb-471b-d878-3ee12ce6dd8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "🎯 mBERT TRAINING - RUN #15: SEQUENCE LENGTH OPTIMIZATION (SEED = 42)\n",
            "================================================================================\n",
            "📊 Run History:\n",
            "   R1→R8: 58.5%-61.99% (hyperparameter tuning)\n",
            "   R9-R10: 62.74%-63.06% 🏆 BEST BASELINE (seed 42)\n",
            "   R11-R13: 58.28%-62.45% (seed ensemble - 4.78% variance)\n",
            "   R14: 57.76% ❌ DISASTER (-5.3%) - architectural overreach failed!\n",
            "   Key Finding: Simple architecture works best, need data-centric approach!\n",
            "   R15 Strategy: SEQUENCE LENGTH OPTIMIZATION + PREPARE FOR AUGMENTATION\n",
            "\n",
            "🎲 Current Seed: 42 (best seed from R9-R13 experiments)\n",
            "\n",
            "🎯 Run #15 Goal: QUICK WIN VIA SEQUENCE LENGTH + DATA PREP\n",
            "   ├─ Current best: 63.06% (R10, seed 42)\n",
            "   ├─ Target: 64-66% Macro-F1 (+1-3% from sequence length)\n",
            "   ├─ Strategy: MAX_LENGTH 224 → 320 (research-backed optimal)\n",
            "   ├─ Next steps: Data augmentation for Track 1 (75% breakthrough)\n",
            "   └─ Long-term target: 75% Macro-F1 via multi-track strategy\n",
            "\n",
            "📏 SEQUENCE LENGTH OPTIMIZATION (RESEARCH-BACKED):\n",
            "   ├─ MAX_LENGTH: 224 → 320 (+43% more context!)\n",
            "   ├─ Research: Length 320 achieved 71.7% F1 in NIH study (PMC9051848)\n",
            "   ├─ Rationale: News articles have important late-text context\n",
            "   └─ Why it works: Sentiment/polarization signals may appear late in text\n",
            "\n",
            "⏱️  Training Configuration (R9 PROVEN + SEQUENCE LENGTH ADJUSTMENT):\n",
            "   ├─ Epochs: 20 ✅ R9 PROVEN\n",
            "   ├─ Batch Size: 12 (effective: 48) ⬇️ Adjusted for longer sequences\n",
            "   ├─ Learning Rate: 2.5e-05 ✅ R9 PROVEN\n",
            "   ├─ Weight Decay: 0.03 ✅ R9 PROVEN\n",
            "   ├─ Warmup Ratio: 0.2 ✅ R9 PROVEN\n",
            "   ├─ Early Stop Patience: 8 ✅ R9 PROVEN\n",
            "   └─ Estimated Time: ~95-105 minutes (similar to R9, slightly longer sequences)\n",
            "\n",
            "🏗️  Architecture (R9 PROVEN SIMPLE DESIGN - R14 COMPLEXITY REMOVED):\n",
            "   ├─ Head Hidden: 768 ✅ R9 PROVEN\n",
            "   ├─ Head Layers: 3 ✅ R9 PROVEN\n",
            "   ├─ Head Dropout: 0.25 ✅ R9 PROVEN\n",
            "   ├─ Pooling: last4_mean ✅ R9 PROVEN\n",
            "   ├─ Task Projections: False ❌ DISABLED (R14 proved harmful)\n",
            "   ├─ Residual Connections: False ❌ DISABLED (R14 proved harmful)\n",
            "   └─ Multi-Sample Dropout: False ❌ DISABLED (R14 proved harmful)\n",
            "\n",
            "⚖️  Critical Class Weights (R9 PROVEN):\n",
            "   ├─ Negative:  1.1x ✅ R9 PROVEN\n",
            "   ├─ Neutral:   1.8x ✅ R9 PROVEN\n",
            "   ├─ Objective: 2.5x ✅ R9 PROVEN\n",
            "   └─ Max Weight Cap: 10.0 ✅ R9 PROVEN\n",
            "\n",
            "📊 Oversampling Strategy (R9 PROVEN):\n",
            "   ├─ Joint Alpha: 0.7 ✅ R9 PROVEN\n",
            "   ├─ Max Multiplier: 8.0x ✅ R9 PROVEN\n",
            "   ├─ Objective Boost: 8.5x ✅ R9 PROVEN\n",
            "   └─ Neutral Boost: 3.5x ✅ R9 PROVEN\n",
            "\n",
            "❌ TASK-SPECIFIC GRADIENT CONTROL: DISABLED (R7 proved this is HARMFUL!):\n",
            "   ├─ Feature Enabled: False ✅ DISABLED\n",
            "   ├─ Global MAX_GRAD_NORM: 0.5 ✅ R9 PROVEN\n",
            "   └─ R7 Lesson: Task-specific gradients caused -7.91% regression (worst run ever)\n",
            "\n",
            "🔥 Advanced Techniques (R9 PROVEN - ALL PARAMETERS FROM BEST RUN):\n",
            "   ├─ Focal Loss Gamma (Sent/Pol): 2.5/3.5 ✅ R9 PROVEN\n",
            "   ├─ Label Smoothing (Sent/Pol): 0.1/0.08 ✅ R9 PROVEN\n",
            "   ├─ Task Weights (Sent/Pol): 1.0/1.4 ✅ R9 PROVEN\n",
            "   ├─ R-Drop Alpha: 0.6 ✅ R9 PROVEN\n",
            "   └─ LLRD Decay: 0.9 ✅ R9 PROVEN\n",
            "\n",
            "🎯 Run #15 Expected Results:\n",
            "   ├─ Target: 64-66% Macro-F1 (+1-3% from sequence length)\n",
            "   ├─ Strategy: Research-backed MAX_LENGTH=320 for better context\n",
            "   ├─ Next Step: Data augmentation (back-translation for weak classes)\n",
            "   └─ Breakthrough Path: Multi-track strategy to 75% (see BREAKTHROUGH_STRATEGY_TO_75_PERCENT.md)\n",
            "\n",
            "📁 Output: ./runs_mbert_optimized\n",
            "================================================================================\n",
            "✅ Seed 42 applied successfully!\n",
            "\n",
            "✅ SECTION 3: Configuration Setup completed in 19.7s\n",
            "🕒 Total runtime so far: 1.1m 8s\n",
            "------------------------------------------------------------\n",
            "\n",
            "🚀 Starting SECTION 4: Data Loading & Preprocessing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 4"
      ],
      "metadata": {
        "id": "LKtHe-Ezb-id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 4 — Load & Prepare Data (updated for multipliers) =====\n",
        "## Augmented-training aware defaults (local to this cell)\n",
        "USE_AUGMENTED_TRAIN = globals().get('USE_AUGMENTED_TRAIN', True)\n",
        "AUG_CSV_PATH = globals().get('AUG_CSV_PATH', '/content/augmented_adjudications_2025-10-22.csv')\n",
        "if USE_AUGMENTED_TRAIN:\n",
        "    # Soften manual boosts now that minority classes are larger\n",
        "    CLASS_WEIGHT_MULT = {\n",
        "        \"sentiment\": {\"negative\": 1.00, \"neutral\": 1.00, \"positive\": 1.20},\n",
        "        \"polarization\": {\"non_polarized\": 1.00, \"objective\": 1.60, \"partisan\": 1.00},\n",
        "    }\n",
        "    MAX_CLASS_WEIGHT = 8.0\n",
        "    USE_SMART_OVERSAMPLING = False\n",
        "    JOINT_ALPHA = 0.30\n",
        "    JOINT_OVERSAMPLING_MAX_MULT = 4.0\n",
        "    OBJECTIVE_BOOST_MULT = 1.0\n",
        "    NEUTRAL_BOOST_MULT = 1.0\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "required = [TITLE_COL, TEXT_COL, SENT_COL, POL_COL]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing expected columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "df = df.dropna(subset=[TITLE_COL, TEXT_COL, SENT_COL, POL_COL]).reset_index(drop=True)\n",
        "\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "sent_le = LabelEncoder().fit(df[SENT_COL])\n",
        "pol_le  = LabelEncoder().fit(df[POL_COL])\n",
        "\n",
        "df[\"sent_y\"] = sent_le.transform(df[SENT_COL])\n",
        "df[\"pol_y\"]  = pol_le.transform(df[POL_COL])\n",
        "\n",
        "num_sent_classes = len(sent_le.classes_)\n",
        "num_pol_classes  = len(pol_le.classes_)\n",
        "\n",
        "print(\"Sentiment classes:\", dict(enumerate(sent_le.classes_)))\n",
        "print(\"Polarization classes:\", dict(enumerate(pol_le.classes_)))\n",
        "\n",
        "# Splits: joint stratify by both tasks (preserve distribution across sentiment x polarization)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df[[TITLE_COL, TEXT_COL]].copy()\n",
        "y_sent = df[\"sent_y\"].values\n",
        "y_pol  = df[\"pol_y\"].values\n",
        "\n",
        "y_joint = y_sent * 10 + y_pol\n",
        "X_train, X_tmp, ysent_train, ysent_tmp, ypol_train, ypol_tmp = train_test_split(\n",
        "    X, y_sent, y_pol, test_size=0.3, random_state=SEED, stratify=y_joint\n",
        ")\n",
        "joint_tmp = ysent_tmp * 10 + ypol_tmp\n",
        "X_val, X_test, ysent_val, ysent_test, ypol_val, ypol_test = train_test_split(\n",
        "    X_tmp, ysent_tmp, ypol_tmp, test_size=0.5, random_state=SEED, stratify=joint_tmp\n",
        ")\n",
        "\n",
        "# Append augmented rows to TRAIN only (no leakage into val/test)\n",
        "if USE_AUGMENTED_TRAIN:\n",
        "    if os.path.isfile(AUG_CSV_PATH):\n",
        "        aug = pd.read_csv(AUG_CSV_PATH).dropna(subset=[TITLE_COL, TEXT_COL, SENT_COL, POL_COL])\n",
        "        # Use same encoders to align indices\n",
        "        aug[\"sent_y\"] = sent_le.transform(aug[SENT_COL])\n",
        "        aug[\"pol_y\"]  = pol_le.transform(aug[POL_COL])\n",
        "        X_train = pd.concat([X_train, aug[[TITLE_COL, TEXT_COL]]], ignore_index=True)\n",
        "        ysent_train = np.concatenate([ysent_train, aug[\"sent_y\"].values])\n",
        "        ypol_train  = np.concatenate([ypol_train,  aug[\"pol_y\"].values])\n",
        "    else:\n",
        "        print(f\"[Warn] USE_AUGMENTED_TRAIN=True but file not found: {AUG_CSV_PATH}\")\n",
        "\n",
        "print(\"Train size:\", len(X_train), \"Val size:\", len(X_val), \"Test size:\", len(X_test))\n",
        "\n",
        "# Balanced class weights from TRAIN only\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np, json, os\n",
        "\n",
        "def safe_class_weights(y, n_classes):\n",
        "    classes = np.arange(n_classes)\n",
        "    counts = np.bincount(y, minlength=n_classes)\n",
        "    if np.any(counts == 0):\n",
        "        return np.ones(n_classes, dtype=np.float32)\n",
        "    return compute_class_weight(\"balanced\", classes=classes, y=y).astype(np.float32)\n",
        "\n",
        "sent_weights_np = safe_class_weights(ysent_train, num_sent_classes)\n",
        "pol_weights_np  = safe_class_weights(ypol_train,  num_pol_classes)\n",
        "\n",
        "# Apply user multipliers by class name\n",
        "sent_name_to_idx = {name: i for i, name in enumerate(sent_le.classes_)}\n",
        "pol_name_to_idx  = {name: i for i, name in enumerate(pol_le.classes_)}\n",
        "\n",
        "for cname, mult in CLASS_WEIGHT_MULT[\"sentiment\"].items():\n",
        "    if cname in sent_name_to_idx:\n",
        "        sent_weights_np[sent_name_to_idx[cname]] *= float(mult)\n",
        "\n",
        "for cname, mult in CLASS_WEIGHT_MULT[\"polarization\"].items():\n",
        "    if cname in pol_name_to_idx:\n",
        "        pol_weights_np[pol_name_to_idx[cname]] *= float(mult)\n",
        "\n",
        "# Apply class weight caps to prevent training instability\n",
        "sent_weights_np = np.clip(sent_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
        "pol_weights_np = np.clip(pol_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
        "\n",
        "print(\"Final sentiment class weights (capped):\", {sent_le.classes_[i]: float(w) for i, w in enumerate(sent_weights_np)})\n",
        "print(\"Final polarization class weights (capped):\", {pol_le.classes_[i]: float(w) for i, w in enumerate(pol_weights_np)})\n",
        "print(f\"Class weights were capped at maximum: {MAX_CLASS_WEIGHT}\")\n",
        "\n",
        "# Save label maps\n",
        "with open(os.path.join(OUT_DIR, \"label_map_sentiment.json\"), \"w\") as f:\n",
        "    json.dump({int(k): v for k, v in dict(enumerate(sent_le.classes_)).items()}, f, indent=2)\n",
        "with open(os.path.join(OUT_DIR, \"label_map_polarization.json\"), \"w\") as f:\n",
        "    json.dump({int(k): v for k, v in dict(enumerate(pol_le.classes_)).items()}, f, indent=2)\n",
        "\n",
        "# End timing for section 4\n",
        "timer.end_section(\"SECTION 4: Data Loading & Preprocessing\")\n",
        "timer.start_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4fHWCOWW19j",
        "outputId": "dcfabd84-94dc-4375-eabb-4cb63991a9a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment classes: {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
            "Polarization classes: {0: 'non_polarized', 1: 'objective', 2: 'partisan'}\n",
            "Train size: 22207 Val size: 1959 Test size: 1960\n",
            "Final sentiment class weights (capped): {'negative': 0.7374311089515686, 'neutral': 0.7540321350097656, 'positive': 3.776700973510742}\n",
            "Final polarization class weights (capped): {'non_polarized': 1.055666446685791, 'objective': 4.896127700805664, 'partisan': 0.5793936252593994}\n",
            "Class weights were capped at maximum: 8.0\n",
            "✅ SECTION 4: Data Loading & Preprocessing completed in 14.6s\n",
            "🕒 Total runtime so far: 1.4m 22s\n",
            "------------------------------------------------------------\n",
            "\n",
            "🚀 Starting SECTION 5-9: Model Architecture & Training Setup...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 5"
      ],
      "metadata": {
        "id": "F0x3VSqAb8V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 5 — Dataset & Collator (proper text-pair encoding) =====\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TaglishDataset(Dataset):\n",
        "    def __init__(self, titles, texts, y_sent, y_pol, tokenizer, max_length=224):\n",
        "        self.titles = list(titles)\n",
        "        self.texts  = list(texts)\n",
        "        self.y_sent = np.array(y_sent)\n",
        "        self.y_pol  = np.array(y_pol)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "        # mBERT has token_type_ids; XLM-R/RemBERT don't, and that's fine.\n",
        "        self.use_token_type = \"token_type_ids\" in tokenizer.model_input_names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pass title as text, comment as text_pair so the tokenizer inserts the correct separators.\n",
        "        # We also bias truncation to the comment since titles are short.\n",
        "        enc = self.tok(\n",
        "            text=str(self.titles[idx]),\n",
        "            text_pair=str(self.texts[idx]),\n",
        "            truncation=\"only_second\",     # keep the title intact; trim the comment if needed\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=self.use_token_type,\n",
        "        )\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"],\n",
        "            \"attention_mask\": enc[\"attention_mask\"],\n",
        "            \"sentiment_labels\": torch.tensor(self.y_sent[idx], dtype=torch.long),\n",
        "            \"polarization_labels\": torch.tensor(self.y_pol[idx], dtype=torch.long),\n",
        "        }\n",
        "        if self.use_token_type and \"token_type_ids\" in enc:\n",
        "            item[\"token_type_ids\"] = enc[\"token_type_ids\"]\n",
        "        return item\n"
      ],
      "metadata": {
        "id": "YJkJpNWiX5oT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 6"
      ],
      "metadata": {
        "id": "_BpY_PhNb6M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 6 — Multi-Task Model (ENHANCED ARCHITECTURE FOR 75% TARGET) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoModel\n",
        "import math\n",
        "\n",
        "def mean_pooling(token_embeddings, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    summed = (token_embeddings * mask).sum(dim=1)\n",
        "    denom = mask.sum(dim=1).clamp(min=1e-9)\n",
        "    return summed / denom\n",
        "\n",
        "class AttentionPooling(nn.Module):\n",
        "    \"\"\"\n",
        "    Learned attention pooling over layers and tokens.\n",
        "    Dynamically learns which layers and tokens are most important.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, num_layers=4):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        # Layer attention: learn which layers matter most\n",
        "        self.layer_attention = nn.Linear(hidden_size, 1)\n",
        "        # Token attention: learn which tokens matter most\n",
        "        self.token_attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask):\n",
        "        \"\"\"\n",
        "        hidden_states: tuple of (num_layers, batch_size, seq_len, hidden_size)\n",
        "        attention_mask: (batch_size, seq_len)\n",
        "        \"\"\"\n",
        "        # Stack last N layers: (num_layers, batch, seq, hidden)\n",
        "        last_n = torch.stack(hidden_states[-self.num_layers:])\n",
        "\n",
        "        # Layer-wise attention: which layers are most important?\n",
        "        # Average across seq_len for each layer\n",
        "        layer_repr = last_n.mean(dim=2)  # (num_layers, batch, hidden)\n",
        "        layer_scores = self.layer_attention(layer_repr).squeeze(-1)  # (num_layers, batch)\n",
        "        layer_weights = F.softmax(layer_scores, dim=0)  # (num_layers, batch)\n",
        "\n",
        "        # Weighted combination of layers\n",
        "        layer_weights = layer_weights.unsqueeze(2).unsqueeze(3)  # (num_layers, batch, 1, 1)\n",
        "        weighted_hidden = (last_n * layer_weights).sum(dim=0)  # (batch, seq, hidden)\n",
        "\n",
        "        # Token-wise attention: which tokens are most important?\n",
        "        token_scores = self.token_attention(weighted_hidden).squeeze(-1)  # (batch, seq)\n",
        "\n",
        "        # Mask padding tokens (use float16-safe value)\n",
        "        # -1e4 is safe for both float32 and float16 (fp16 max ~65k)\n",
        "        mask = attention_mask.unsqueeze(-1).float()  # (batch, seq, 1)\n",
        "        token_scores = token_scores.masked_fill(attention_mask == 0, -1e4)\n",
        "        token_weights = F.softmax(token_scores, dim=1).unsqueeze(-1)  # (batch, seq, 1)\n",
        "\n",
        "        # Weighted combination of tokens\n",
        "        pooled = (weighted_hidden * token_weights).sum(dim=1)  # (batch, hidden)\n",
        "\n",
        "        return pooled\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Residual block with Layer Normalization and GELU activation.\n",
        "    Helps with gradient flow in deeper networks.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.GELU()\n",
        "\n",
        "        # Xavier initialization for better gradient flow\n",
        "        nn.init.xavier_uniform_(self.linear1.weight)\n",
        "        nn.init.xavier_uniform_(self.linear2.weight)\n",
        "        nn.init.zeros_(self.linear1.bias)\n",
        "        nn.init.zeros_(self.linear2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First sub-layer with residual\n",
        "        residual = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "\n",
        "        # Second sub-layer with residual\n",
        "        residual = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + residual\n",
        "\n",
        "        return x\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, base_model_name: str, num_sent: int, num_pol: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(base_model_name)\n",
        "        self.hidden = self.encoder.config.hidden_size\n",
        "\n",
        "        # 🔥 NEW: Attention-based pooling (learns what's important!)\n",
        "        if REP_POOLING == \"attention\":\n",
        "            self.attention_pool = AttentionPooling(self.hidden, num_layers=4)\n",
        "\n",
        "        # 🔥 ENHANCED: Larger trunk with residual connections\n",
        "        # Project from encoder hidden size to HEAD_HIDDEN\n",
        "        self.trunk_proj = nn.Linear(self.hidden, HEAD_HIDDEN)\n",
        "\n",
        "        # Add residual blocks for better gradient flow\n",
        "        self.trunk_blocks = nn.ModuleList([\n",
        "            ResidualBlock(HEAD_HIDDEN, dropout=HEAD_DROPOUT)\n",
        "            for _ in range(2)  # 2 residual blocks\n",
        "        ])\n",
        "\n",
        "        self.trunk_norm = nn.LayerNorm(HEAD_HIDDEN)\n",
        "        self.trunk_dropout = nn.Dropout(HEAD_DROPOUT)\n",
        "\n",
        "        # Xavier initialization for projection\n",
        "        nn.init.xavier_uniform_(self.trunk_proj.weight)\n",
        "        nn.init.zeros_(self.trunk_proj.bias)\n",
        "\n",
        "        # 🔥 NEW: Task-specific projections (learn task-specific features)\n",
        "        self.sent_proj = nn.Sequential(\n",
        "            nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(HEAD_HIDDEN),\n",
        "            nn.Dropout(HEAD_DROPOUT * 0.5),\n",
        "        )\n",
        "        self.pol_proj = nn.Sequential(\n",
        "            nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(HEAD_HIDDEN),\n",
        "            nn.Dropout(HEAD_DROPOUT * 0.5),\n",
        "        )\n",
        "\n",
        "        # Initialize task projections\n",
        "        for module in [self.sent_proj, self.pol_proj]:\n",
        "            for m in module.modules():\n",
        "                if isinstance(m, nn.Linear):\n",
        "                    nn.init.xavier_uniform_(m.weight)\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "        # 🔥 ENHANCED: Deeper multi-layer heads with residuals\n",
        "        if HEAD_LAYERS >= 4:\n",
        "            # 4-layer heads with residual connections\n",
        "            self.head_sent = nn.ModuleList([\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                ResidualBlock(HEAD_HIDDEN, dropout=HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.7),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_sent)\n",
        "            ])\n",
        "            self.head_pol = nn.ModuleList([\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                ResidualBlock(HEAD_HIDDEN, dropout=HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.7),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_pol)\n",
        "            ])\n",
        "\n",
        "            # Initialize head layers\n",
        "            for head in [self.head_sent, self.head_pol]:\n",
        "                for module in head:\n",
        "                    if isinstance(module, nn.Linear):\n",
        "                        nn.init.xavier_uniform_(module.weight)\n",
        "                        nn.init.zeros_(module.bias)\n",
        "\n",
        "        elif HEAD_LAYERS == 3:\n",
        "            # 3-layer heads (current default)\n",
        "            self.head_sent = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, HEAD_HIDDEN // 4),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 4),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.7),\n",
        "                nn.Linear(HEAD_HIDDEN // 4, num_sent)\n",
        "            )\n",
        "            self.head_pol = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, HEAD_HIDDEN // 4),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 4),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.7),\n",
        "                nn.Linear(HEAD_HIDDEN // 4, num_pol)\n",
        "            )\n",
        "        elif HEAD_LAYERS == 2:\n",
        "            # 2-layer heads (legacy)\n",
        "            self.head_sent = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_sent)\n",
        "            )\n",
        "            self.head_pol = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_pol)\n",
        "            )\n",
        "        else:\n",
        "            # Single-layer heads (fallback)\n",
        "            self.head_sent = nn.Linear(HEAD_HIDDEN, num_sent)\n",
        "            self.head_pol  = nn.Linear(HEAD_HIDDEN, num_pol)\n",
        "\n",
        "        # Enable gradient checkpointing if configured\n",
        "        if USE_GRADIENT_CHECKPOINTING:\n",
        "            self.encoder.gradient_checkpointing_enable()\n",
        "\n",
        "    def _pool(self, outputs, attention_mask):\n",
        "        \"\"\"\n",
        "        Flexible representation pooling with multiple strategies.\n",
        "        \"\"\"\n",
        "        # 🔥 NEW: Attention-based pooling (learns importance)\n",
        "        if REP_POOLING == \"attention\":\n",
        "            return self.attention_pool(outputs.hidden_states, attention_mask)\n",
        "\n",
        "        # Pooler output (if available)\n",
        "        if REP_POOLING == \"pooler\" and hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
        "            return outputs.pooler_output\n",
        "\n",
        "        # CLS token\n",
        "        if REP_POOLING == \"cls\":\n",
        "            return outputs.last_hidden_state[:, 0]\n",
        "\n",
        "        # Default: last4_mean (average of last 4 layers)\n",
        "        hs = outputs.hidden_states  # tuple of [layer0..last]\n",
        "        last4 = torch.stack(hs[-4:]).mean(dim=0)       # [B, T, H]\n",
        "        return mean_pooling(last4, attention_mask)     # [B, H]\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids=None,\n",
        "                attention_mask=None,\n",
        "                token_type_ids=None,\n",
        "                sentiment_labels=None,\n",
        "                polarization_labels=None):\n",
        "        # Encode input\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids if token_type_ids is not None else None,\n",
        "            output_hidden_states=True  # Always need hidden states now\n",
        "        )\n",
        "\n",
        "        # Pool encoder outputs\n",
        "        pooled = self._pool(outputs, attention_mask)\n",
        "\n",
        "        # Project to HEAD_HIDDEN dimension\n",
        "        z = self.trunk_proj(pooled)\n",
        "\n",
        "        # Pass through residual blocks\n",
        "        for block in self.trunk_blocks:\n",
        "            z = block(z)\n",
        "\n",
        "        # Final trunk normalization and dropout\n",
        "        z = self.trunk_norm(z)\n",
        "        z = self.trunk_dropout(z)\n",
        "\n",
        "        # 🔥 NEW: Task-specific feature extraction\n",
        "        z_sent = self.sent_proj(z)  # Sentiment-specific features\n",
        "        z_pol = self.pol_proj(z)    # Polarization-specific features\n",
        "\n",
        "        # Pass through task heads\n",
        "        if HEAD_LAYERS >= 4 and isinstance(self.head_sent, nn.ModuleList):\n",
        "            # ModuleList: apply each layer sequentially\n",
        "            for layer in self.head_sent:\n",
        "                z_sent = layer(z_sent)\n",
        "            for layer in self.head_pol:\n",
        "                z_pol = layer(z_pol)\n",
        "            sent_logits = z_sent\n",
        "            pol_logits = z_pol\n",
        "        else:\n",
        "            # Sequential: apply directly\n",
        "            sent_logits = self.head_sent(z_sent)\n",
        "            pol_logits = self.head_pol(z_pol)\n",
        "\n",
        "        return {\"logits\": (sent_logits, pol_logits)}\n"
      ],
      "metadata": {
        "id": "aBI8mY8zX9bh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 7"
      ],
      "metadata": {
        "id": "Q9qlyf0bb4Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 7\n",
        "\n",
        "def compute_metrics_multi(eval_pred):\n",
        "    (sent_logits, pol_logits) = eval_pred.predictions\n",
        "    (y_sent, y_pol) = eval_pred.label_ids\n",
        "\n",
        "    ps = np.argmax(sent_logits, axis=1)\n",
        "    pp = np.argmax(pol_logits, axis=1)\n",
        "\n",
        "    # Macro metrics\n",
        "    sent_report = classification_report(y_sent, ps, output_dict=True, zero_division=0)\n",
        "    pol_report  = classification_report(y_pol,  pp, output_dict=True, zero_division=0)\n",
        "\n",
        "    sent_f1 = sent_report[\"macro avg\"][\"f1-score\"]\n",
        "    pol_f1  = pol_report[\"macro avg\"][\"f1-score\"]\n",
        "    macro_f1_avg = (sent_f1 + pol_f1) / 2.0\n",
        "\n",
        "    return {\n",
        "        \"sent_acc\": sent_report[\"accuracy\"],\n",
        "        \"sent_prec\": sent_report[\"macro avg\"][\"precision\"],\n",
        "        \"sent_rec\": sent_report[\"macro avg\"][\"recall\"],\n",
        "        \"sent_f1\": sent_f1,\n",
        "\n",
        "        \"pol_acc\": pol_report[\"accuracy\"],\n",
        "        \"pol_prec\": pol_report[\"macro avg\"][\"precision\"],\n",
        "        \"pol_rec\": pol_report[\"macro avg\"][\"recall\"],\n",
        "        \"pol_f1\": pol_f1,\n",
        "\n",
        "        \"macro_f1_avg\": macro_f1_avg\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "sw_XB5CqX_uB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 8"
      ],
      "metadata": {
        "id": "SStXGWDuZXHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 8 — Custom Trainer (R-Drop + LLRD + safe prediction_step) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=2.0, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, target):\n",
        "        logp = F.log_softmax(logits, dim=1)\n",
        "        p = torch.exp(logp)\n",
        "        loss = F.nll_loss((1 - p) ** self.gamma * logp, target, weight=self.weight, reduction=\"none\")\n",
        "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
        "\n",
        "def _sym_kl_with_logits(logits1, logits2):\n",
        "    p = F.log_softmax(logits1, dim=-1);  q = F.log_softmax(logits2, dim=-1)\n",
        "    p_exp, q_exp = p.exp(), q.exp()\n",
        "    return 0.5 * (F.kl_div(p, q_exp, reduction=\"batchmean\") + F.kl_div(q, p_exp, reduction=\"batchmean\"))\n",
        "\n",
        "class MultiTaskTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, task_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights or {}\n",
        "        self.task_weights  = task_weights or {\"sentiment\": 1.0, \"polarization\": 1.0}\n",
        "        self._custom_train_sampler = None\n",
        "\n",
        "    # ----- LLRD optimizer -----\n",
        "    def create_optimizer(self):\n",
        "        if self.optimizer is not None:\n",
        "            return self.optimizer\n",
        "        if not USE_LLRD:\n",
        "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "            return self.optimizer\n",
        "\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "        encoder = self.model.encoder\n",
        "        n_layers = getattr(encoder.config, \"num_hidden_layers\", 12)\n",
        "        # Try to access sequential layers\n",
        "        layers = getattr(getattr(encoder, \"encoder\", encoder), \"layer\", None)\n",
        "        if layers is None:\n",
        "            # Fallback: no LLRD if we can't find layers\n",
        "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "            return self.optimizer\n",
        "\n",
        "        param_groups = []\n",
        "\n",
        "        # Embeddings (lowest lr)\n",
        "        emb = getattr(encoder, \"embeddings\", None)\n",
        "        if emb is not None:\n",
        "            lr_emb = LR * (LLRD_DECAY ** n_layers)\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in emb.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_emb, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_emb, \"weight_decay\": 0.0})\n",
        "\n",
        "        # Encoder blocks (increasing LR toward the top)\n",
        "        for i in range(n_layers):\n",
        "            block = layers[i]\n",
        "            lr_i = LR * (LLRD_DECAY ** (n_layers - 1 - i))\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in block.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_i, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_i, \"weight_decay\": 0.0})\n",
        "\n",
        "        # Pooler (if any)\n",
        "        pooler = getattr(encoder, \"pooler\", None)\n",
        "        if pooler is not None:\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in pooler.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": LR, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": LR, \"weight_decay\": 0.0})\n",
        "\n",
        "        # 🔥 RUN #14: Heads/trunk (highest LR) - UPDATED FOR NEW ARCHITECTURE\n",
        "        head_lr = LR * HEAD_LR_MULT\n",
        "\n",
        "        # Collect all head modules (updated for new architecture)\n",
        "        head_modules = []\n",
        "\n",
        "        # Add trunk components (new architecture with residual blocks)\n",
        "        if hasattr(self.model, 'trunk_proj'):\n",
        "            head_modules.append(self.model.trunk_proj)\n",
        "        if hasattr(self.model, 'trunk_blocks'):\n",
        "            head_modules.extend(list(self.model.trunk_blocks))\n",
        "        if hasattr(self.model, 'trunk_norm'):\n",
        "            head_modules.append(self.model.trunk_norm)\n",
        "        if hasattr(self.model, 'trunk_dropout'):\n",
        "            head_modules.append(self.model.trunk_dropout)\n",
        "\n",
        "        # Add task-specific projections (new in Run #14)\n",
        "        if hasattr(self.model, 'sent_proj'):\n",
        "            head_modules.append(self.model.sent_proj)\n",
        "        if hasattr(self.model, 'pol_proj'):\n",
        "            head_modules.append(self.model.pol_proj)\n",
        "\n",
        "        # Add attention pooling (new in Run #14)\n",
        "        if hasattr(self.model, 'attention_pool'):\n",
        "            head_modules.append(self.model.attention_pool)\n",
        "\n",
        "        # Add task heads\n",
        "        head_modules.append(self.model.head_sent)\n",
        "        head_modules.append(self.model.head_pol)\n",
        "\n",
        "        # Collect parameters with decay/no-decay split\n",
        "        decay, nodecay = [], []\n",
        "        for m in head_modules:\n",
        "            for n, p in m.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "\n",
        "        if decay:   param_groups.append({\"params\": decay,   \"lr\": head_lr, \"weight_decay\": WEIGHT_DECAY})\n",
        "        if nodecay: param_groups.append({\"params\": nodecay, \"lr\": head_lr, \"weight_decay\": 0.0})\n",
        "\n",
        "        self.optimizer = AdamW(param_groups, lr=LR)  # lr here is ignored per-group\n",
        "        return self.optimizer\n",
        "\n",
        "    def set_train_sampler(self, sampler):\n",
        "        self._custom_train_sampler = sampler\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        if self.train_dataset is None:\n",
        "            return None\n",
        "        if self._custom_train_sampler is not None:\n",
        "            return DataLoader(\n",
        "                self.train_dataset,\n",
        "                batch_size=self.args.train_batch_size,\n",
        "                sampler=self._custom_train_sampler,\n",
        "                collate_fn=self.data_collator,\n",
        "                drop_last=self.args.dataloader_drop_last,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                pin_memory=self.args.dataloader_pin_memory,\n",
        "            )\n",
        "        return super().get_train_dataloader()\n",
        "\n",
        "    def _sent_loss_fn(self, weight, logits, target):\n",
        "        if USE_FOCAL_SENTIMENT:\n",
        "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_SENTIMENT)(logits, target)\n",
        "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_SENTIMENT))(logits, target)\n",
        "\n",
        "    def _pol_loss_fn(self, weight, logits, target):\n",
        "        if USE_FOCAL_POLARITY:\n",
        "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_POLARITY)(logits, target)\n",
        "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_POLARITY))(logits, target)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        y_sent = inputs.pop(\"sentiment_labels\")\n",
        "        y_pol  = inputs.pop(\"polarization_labels\")\n",
        "\n",
        "        # R-Drop with warmup: two forward passes with dropout\n",
        "        current_epoch = getattr(self.state, 'epoch', 0) if hasattr(self, 'state') else 0\n",
        "        use_rdrop_now = USE_RDROP and model.training and current_epoch >= RDROP_WARMUP_EPOCHS\n",
        "\n",
        "        if use_rdrop_now:\n",
        "            outputs1 = model(**inputs)\n",
        "            outputs2 = model(**inputs)\n",
        "            s1, p1 = outputs1[\"logits\"]\n",
        "            s2, p2 = outputs2[\"logits\"]\n",
        "\n",
        "            ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s1.device) if ws is not None else None\n",
        "            wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p1.device) if wp is not None else None\n",
        "\n",
        "            ce_s = 0.5 * (self._sent_loss_fn(ws, s1, y_sent) + self._sent_loss_fn(ws, s2, y_sent))\n",
        "            ce_p = 0.5 * (self._pol_loss_fn(wp,  p1, y_pol)  + self._pol_loss_fn(wp,  p2, y_pol))\n",
        "            kl_s = _sym_kl_with_logits(s1, s2)\n",
        "            kl_p = _sym_kl_with_logits(p1, p2)\n",
        "\n",
        "            w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
        "            w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
        "\n",
        "            # Gradual R-Drop alpha rampup for stability\n",
        "            rdrop_factor = min(1.0, (current_epoch - RDROP_WARMUP_EPOCHS + 1) / 2.0)\n",
        "            loss = w_s * ce_s + w_p * ce_p + (RDROP_ALPHA * rdrop_factor) * (kl_s + kl_p)\n",
        "            if return_outputs:\n",
        "                return loss, {\"logits\": (s1, p1)}\n",
        "            return loss\n",
        "\n",
        "        # Standard single forward\n",
        "        outputs = model(**inputs)\n",
        "        s, p = outputs[\"logits\"]\n",
        "\n",
        "        ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s.device) if ws is not None else None\n",
        "        wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p.device) if wp is not None else None\n",
        "\n",
        "        loss_s = self._sent_loss_fn(ws, s, y_sent)\n",
        "        loss_p = self._pol_loss_fn(wp, p, y_pol)\n",
        "\n",
        "        w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
        "        w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
        "        loss = w_s * loss_s + w_p * loss_p\n",
        "\n",
        "        if return_outputs:\n",
        "            outputs = dict(outputs); outputs[\"labels\"] = (y_sent, y_pol)\n",
        "            return loss, outputs\n",
        "        return loss\n",
        "\n",
        "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
        "        # Safe for inference (no labels provided)\n",
        "        y_sent = inputs.get(\"sentiment_labels\", None)\n",
        "        y_pol  = inputs.get(\"polarization_labels\", None)\n",
        "\n",
        "        model_inputs = {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"]}\n",
        "        if \"token_type_ids\" in inputs:\n",
        "            model_inputs[\"token_type_ids\"] = inputs[\"token_type_ids\"]\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_inputs)\n",
        "            s, p = outputs[\"logits\"]\n",
        "\n",
        "        loss = None\n",
        "        logits = (s.detach(), p.detach())\n",
        "        labels = (y_sent, y_pol) if isinstance(y_sent, torch.Tensor) and isinstance(y_pol, torch.Tensor) else None\n",
        "        return (loss, logits, labels)\n",
        "\n",
        "# 🔴 RUN #8: Custom training_step REMOVED (R7 proved it's harmful!)\n",
        "# Task-specific gradient control caused -7.91% regression (worst run ever)\n",
        "# Restoring default Trainer behavior for gradient clipping\n"
      ],
      "metadata": {
        "id": "nr4WH-IAYRd3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 9"
      ],
      "metadata": {
        "id": "5mcQwt92ZfGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 9 — Train/Evaluate One Model (with grad accumulation) =====\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "import math, json, numpy as np, pandas as pd, os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from collections import Counter\n",
        "\n",
        "def train_eval_one_model(model_key: str,\n",
        "                         X_tr: pd.DataFrame, X_v: pd.DataFrame, X_te: pd.DataFrame,\n",
        "                         ysent_tr: np.ndarray, ysent_v: np.ndarray, ysent_te: np.ndarray,\n",
        "                         ypol_tr: np.ndarray,  ypol_v: np.ndarray,  ypol_te: np.ndarray,\n",
        "                         sent_w_np: np.ndarray, pol_w_np: np.ndarray):\n",
        "    base_name = MODEL_CONFIGS[model_key][\"name\"]\n",
        "    run_dir = os.path.join(OUT_DIR, f\"{model_key}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "\n",
        "    tr_titles, tr_texts = X_tr[TITLE_COL].values, X_tr[TEXT_COL].values\n",
        "    v_titles,  v_texts  = X_v[TITLE_COL].values, X_v[TEXT_COL].values\n",
        "    te_titles, te_texts = X_te[TITLE_COL].values, X_te[TEXT_COL].values\n",
        "\n",
        "    train_ds = TaglishDataset(tr_titles, tr_texts, ysent_tr, ypol_tr, tokenizer, max_length=MAX_LENGTH)\n",
        "    val_ds   = TaglishDataset(v_titles,  v_texts,  ysent_v,  ypol_v,  tokenizer, max_length=MAX_LENGTH)\n",
        "    test_ds  = TaglishDataset(te_titles, te_texts, ysent_te, ypol_te, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "    model = MultiTaskModel(base_name, num_sent_classes, num_pol_classes).to(device)\n",
        "\n",
        "    sent_w = torch.tensor(sent_w_np, dtype=torch.float32)\n",
        "    pol_w  = torch.tensor(pol_w_np,  dtype=torch.float32)\n",
        "\n",
        "    args = make_training_args_compat(\n",
        "        output_dir=run_dir,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        learning_rate=LR,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"macro_f1_avg\",\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        logging_dir=os.path.join(run_dir, \"logs\"),\n",
        "        logging_steps=25,                    # More frequent logging\n",
        "        logging_first_step=True,             # Log first step for debugging\n",
        "        save_steps=500,                      # Save checkpoints more often\n",
        "        eval_steps=None,                     # Eval at end of each epoch\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        remove_unused_columns=False,\n",
        "        eval_accumulation_steps=1,\n",
        "        gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
        "        dataloader_pin_memory=True,          # Performance optimization\n",
        "        max_grad_norm=MAX_GRAD_NORM,         # ✅ R4 EXACT (global gradient clipping restored)\n",
        "        label_smoothing_factor=0.0,          # We handle this in loss functions\n",
        "        save_total_limit=5,                  # ✅ R4 EXACT\n",
        "        prediction_loss_only=False           # Log all metrics\n",
        "    )\n",
        "\n",
        "    callbacks = get_early_stopping_callbacks(EARLY_STOP_PATIENCE)\n",
        "\n",
        "    trainer = MultiTaskTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        data_collator=collator,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics_multi,\n",
        "        callbacks=callbacks,\n",
        "        class_weights={\"sentiment\": sent_w, \"polarization\": pol_w},\n",
        "        task_weights=TASK_LOSS_WEIGHTS\n",
        "    )\n",
        "\n",
        "    # ----- ENHANCED JOINT oversampling with objective boost -----\n",
        "    if USE_OVERSAMPLING and USE_JOINT_OVERSAMPLING:\n",
        "        pair_counts = Counter(zip(ysent_tr.tolist(), ypol_tr.tolist()))\n",
        "        counts = np.array(list(pair_counts.values()), dtype=np.float32)\n",
        "        med = float(np.median(counts)) if len(counts) else 1.0\n",
        "\n",
        "        # Find objective class index (polarization)\n",
        "        obj_idx = np.where(pol_le.classes_ == \"objective\")[0][0] if \"objective\" in pol_le.classes_ else 1\n",
        "\n",
        "        # 🔥 NEW: Find neutral class index (sentiment)\n",
        "        neutral_idx = np.where(sent_le.classes_ == \"neutral\")[0][0] if \"neutral\" in sent_le.classes_ else 1\n",
        "\n",
        "        def inv_mult(c):\n",
        "            if c <= 0: return JOINT_OVERSAMPLING_MAX_MULT\n",
        "            return float(np.clip(med / float(c), 1.0, JOINT_OVERSAMPLING_MAX_MULT))\n",
        "\n",
        "        inv_by_pair = {k: inv_mult(v) for k, v in pair_counts.items()}\n",
        "        sample_weights = []\n",
        "\n",
        "        for ys, yp in zip(ysent_tr, ypol_tr):\n",
        "            inv = inv_by_pair.get((int(ys), int(yp)), 1.0)\n",
        "            w = (1.0 - JOINT_ALPHA) * 1.0 + JOINT_ALPHA * inv\n",
        "\n",
        "            # Smart oversampling: extra boost for objective class (polarization)\n",
        "            if USE_SMART_OVERSAMPLING and int(yp) == obj_idx:\n",
        "                w *= OBJECTIVE_BOOST_MULT\n",
        "\n",
        "            # 🔥 NEW: Also boost neutral class (sentiment) - Fixes 49% F1!\n",
        "            if USE_SMART_OVERSAMPLING and int(ys) == neutral_idx:\n",
        "                w *= NEUTRAL_BOOST_MULT\n",
        "\n",
        "            sample_weights.append(w)\n",
        "\n",
        "        obj_boost_count = sum(1 for i, yp in enumerate(ypol_tr) if int(yp) == obj_idx and sample_weights[i] > 2.0)\n",
        "        neutral_boost_count = sum(1 for i, ys in enumerate(ysent_tr) if int(ys) == neutral_idx and sample_weights[i] > 2.0)\n",
        "        print(f\"🔥 Enhanced Oversampling: min={min(sample_weights):.2f}, max={max(sample_weights):.2f}\")\n",
        "        print(f\"   ├─ Objective boosted samples: {obj_boost_count} (target: weak class at 40% F1)\")\n",
        "        print(f\"   └─ Neutral boosted samples: {neutral_boost_count} (target: weak class at 49% F1)\")\n",
        "        trainer.set_train_sampler(WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True))\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Save validation logits and labels for ensembling\n",
        "    try:\n",
        "        val_out = trainer.predict(val_ds)\n",
        "        np.save(os.path.join(run_dir, \"val_sent_logits.npy\"), val_out.predictions[0])\n",
        "        np.save(os.path.join(run_dir, \"val_pol_logits.npy\"),  val_out.predictions[1])\n",
        "        np.save(os.path.join(run_dir, \"val_sent_labels.npy\"),  ysent_v)\n",
        "        np.save(os.path.join(run_dir, \"val_pol_labels.npy\"),   ypol_v)\n",
        "    except Exception as e:\n",
        "        print(\"[Warn] Could not save validation logits:\", e)\n",
        "\n",
        "    # Test\n",
        "    test_out = trainer.predict(test_ds)\n",
        "    metrics = {f\"test_{k}\": float(v) for k, v in test_out.metrics.items()}\n",
        "    trainer.save_model(run_dir)\n",
        "    tokenizer.save_pretrained(run_dir)\n",
        "    with open(os.path.join(run_dir, \"metrics_test.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "\n",
        "    sent_logits, pol_logits = test_out.predictions\n",
        "    ysent_pred = np.argmax(sent_logits, axis=1)\n",
        "    ypol_pred  = np.argmax(pol_logits,  axis=1)\n",
        "\n",
        "    cm_sent = confusion_matrix(ysent_te, ysent_pred, labels=list(range(num_sent_classes)))\n",
        "    cm_pol  = confusion_matrix(ypol_te,  ypol_pred,  labels=list(range(num_pol_classes)))\n",
        "    np.save(os.path.join(run_dir, \"cm_sent.npy\"), cm_sent)\n",
        "    np.save(os.path.join(run_dir, \"cm_pol.npy\"),  cm_pol)\n",
        "\n",
        "    def plot_cm(cm, labels, title, path_png):\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        im = ax.imshow(cm, interpolation=\"nearest\")\n",
        "        ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "        ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
        "        ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "        fig.colorbar(im, ax=ax, fraction=0.046); plt.tight_layout(); plt.savefig(path_png, dpi=160); plt.close(fig)\n",
        "\n",
        "    plot_cm(cm_sent, sent_le.classes_, \"Sentiment Confusion\", os.path.join(run_dir, \"cm_sent.png\"))\n",
        "    plot_cm(cm_pol,  pol_le.classes_,  \"Polarization Confusion\", os.path.join(run_dir, \"cm_pol.png\"))\n",
        "\n",
        "    rep_sent = classification_report(ysent_te, ysent_pred, target_names=sent_le.classes_, digits=4, zero_division=0)\n",
        "    rep_pol  = classification_report(ypol_te,  ypol_pred,  target_names=pol_le.classes_,  digits=4, zero_division=0)\n",
        "    with open(os.path.join(run_dir, \"report_sentiment.txt\"), \"w\") as f: f.write(rep_sent)\n",
        "    with open(os.path.join(run_dir, \"report_polarization.txt\"), \"w\") as f: f.write(rep_pol)\n",
        "\n",
        "    return {\"model_key\": model_key, \"base_name\": base_name, **metrics}, (ysent_pred, ypol_pred)\n",
        "\n",
        "# End timing for architecture setup\n",
        "timer.end_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV78nGSQYV3a",
        "outputId": "4e6848f4-b463-4f8a-e88b-34e170760d49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SECTION 5-9: Model Architecture & Training Setup completed in 46.2s\n",
            "🕒 Total runtime so far: 2.1m 8s\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 10\n"
      ],
      "metadata": {
        "id": "JKEIn9Gebyw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION 10\n",
        "\n",
        "timer.start_section(\"SECTION 10: Model Training Execution\")\n",
        "\n",
        "results = []\n",
        "pred_cache = {}\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\n=== Running {key} -> {MODEL_CONFIGS[key]['name']} ===\")\n",
        "    row, preds = train_eval_one_model(\n",
        "        key,\n",
        "        X_train, X_val, X_test,\n",
        "        ysent_train, ysent_val, ysent_test,\n",
        "        ypol_train,  ypol_val,  ypol_test,\n",
        "        sent_weights_np, pol_weights_np\n",
        "    )\n",
        "    results.append(row)\n",
        "    pred_cache[key] = preds\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(os.path.join(OUT_DIR, \"summary_results.csv\"), index=False)\n",
        "\n",
        "# End timing for training execution\n",
        "timer.end_section(\"SECTION 10: Model Training Execution\")\n",
        "timer.start_section(\"SECTION 11+: Evaluation & Calibration\")\n",
        "\n",
        "results_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "548a5ea060b44acf8ede465864501951",
            "ed2d18dd55964cf9859dc302b99a3b1d",
            "30518bb80d4f4ff6bcfff35076388c30",
            "06fb591d4e7f4b4d8bb7c35cdbb3cadc",
            "a81565df7f27432998bf439e815dd5b9",
            "12b9a122288a43139d3632c45553a27a",
            "276377ef1c164ba68b4faf1bee780593",
            "8b45ab0a1b074dbbad5e9af74bf3a096",
            "6a3d1340cdc443868dca7a153e89a649",
            "a1f4766015d34fd186bb72ce49c276d9",
            "9a6c506697444fcca0f77144ba0e1bd7",
            "6b3917ae832a490997b4a7e25ad7fb25",
            "d45fb8c8ae224f0f873dbaa4798d2258",
            "ae90ac25b1db45fd98b7c90707600ab2",
            "53717953c8d9429393c68d59b796d93a",
            "abc254813d2c4e61ab68a73d4d80630e",
            "aa5db88dca104d3eb5a86dc31badb82d",
            "4dbe8a94095b4ec3bc2777cb5807650b",
            "43c141ea7ca2403586b825b3ea08b5f9",
            "7f704710f3204aa7be2978dc80b81af6",
            "d3188aacb9a246cd9a9d474086da05b4",
            "1bc08a58e9194fe0afa214ebd568fdc3",
            "f796b65ab3f64f7a827cfe3b665ded40",
            "5d36f7b3e8884a9c967d83becdf7a9ef",
            "d8b802b73d8948ed9acff932cc771ec5",
            "48970c28d33a41c5a7a9073a1a96e86e",
            "ef74ff6c45db41499eb3b5166d6c8edd",
            "9eb90092be7b4232951fc4387161c894",
            "571fed429b1f4c93bb225ff68441f1be",
            "8e4f3c3eedc9455784b1c29798535640",
            "de4a952c5a634d149ffecef92021c54d",
            "d16436a44765436f8cd15eaaf4c7eccc",
            "ec334ca29bfb4cb7a4624c89913f1441",
            "9792db2d7f31434896dcb3f5b778a5d7",
            "10ee317bb2a54aa4ae80c6b24410366c",
            "16263bf7793147d4a677fa29c9d1b10e",
            "5af39b4d30be433987b4787608190f17",
            "5a36a32d81e04607b51adaa6ef6064ba",
            "40678205fb8045cabb1b3f5ed4136600",
            "dc2e499b255f40b58e7983147eaa0b2d",
            "b008a43fe5a14486b46cdfcf296124ac",
            "6b01510fda1840b6bc21a49e25762286",
            "48c3543a5d454b0a925c982515f25ee2",
            "de1592f610be4a56bf5a05b33f96c5c0",
            "9ae5bee3af104c1289d5d136c7ed01b4",
            "ab469f64c1a44f17b8a8e5cd4b16f1b1",
            "13f3985be7ff47059242164ada226467",
            "2bdb1903eb8e4671be29a4b9317781c9",
            "09189039878a487cbd52dc2bee637ab1",
            "b5449b6e87164f949c1bda182ad7a36b",
            "f13a746f11fd499daa79c4681b1132d3",
            "2f7c6252ba304768ba6ac1dc84bff4ba",
            "23344f9b1d0240619d7f1810f62acf61",
            "7d1ce77fcaf24aaf86ef29754e39e526",
            "fe3edb3fceb14867b259e92947a5f7e1"
          ]
        },
        "id": "24dStZjrYaW7",
        "outputId": "80a849e5-7da8-4996-d9db-5ab26a4d6516"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Starting SECTION 10: Model Training Execution...\n",
            "\n",
            "=== Running mbert -> bert-base-multilingual-cased ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "548a5ea060b44acf8ede465864501951"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b3917ae832a490997b4a7e25ad7fb25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f796b65ab3f64f7a827cfe3b665ded40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9792db2d7f31434896dcb3f5b778a5d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ae5bee3af104c1289d5d136c7ed01b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Enhanced Oversampling: min=1.00, max=1.90\n",
            "   ├─ Objective boosted samples: 0 (target: weak class at 40% F1)\n",
            "   └─ Neutral boosted samples: 0 (target: weak class at 49% F1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9240' max='9240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9240/9240 3:24:26, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Sent Acc</th>\n",
              "      <th>Sent Prec</th>\n",
              "      <th>Sent Rec</th>\n",
              "      <th>Sent F1</th>\n",
              "      <th>Pol Acc</th>\n",
              "      <th>Pol Prec</th>\n",
              "      <th>Pol Rec</th>\n",
              "      <th>Pol F1</th>\n",
              "      <th>Macro F1 Avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.880600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.559980</td>\n",
              "      <td>0.525459</td>\n",
              "      <td>0.582237</td>\n",
              "      <td>0.535779</td>\n",
              "      <td>0.303216</td>\n",
              "      <td>0.473146</td>\n",
              "      <td>0.456775</td>\n",
              "      <td>0.299965</td>\n",
              "      <td>0.417872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.607963</td>\n",
              "      <td>0.575826</td>\n",
              "      <td>0.656571</td>\n",
              "      <td>0.583816</td>\n",
              "      <td>0.552833</td>\n",
              "      <td>0.526687</td>\n",
              "      <td>0.599516</td>\n",
              "      <td>0.521384</td>\n",
              "      <td>0.552600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.536900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.590097</td>\n",
              "      <td>0.591617</td>\n",
              "      <td>0.684023</td>\n",
              "      <td>0.569663</td>\n",
              "      <td>0.537519</td>\n",
              "      <td>0.538011</td>\n",
              "      <td>0.625820</td>\n",
              "      <td>0.512161</td>\n",
              "      <td>0.540912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.330500</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.753956</td>\n",
              "      <td>0.764765</td>\n",
              "      <td>0.804791</td>\n",
              "      <td>0.779451</td>\n",
              "      <td>0.684533</td>\n",
              "      <td>0.639755</td>\n",
              "      <td>0.731589</td>\n",
              "      <td>0.663996</td>\n",
              "      <td>0.721723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.300200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.786115</td>\n",
              "      <td>0.793641</td>\n",
              "      <td>0.834455</td>\n",
              "      <td>0.811634</td>\n",
              "      <td>0.692190</td>\n",
              "      <td>0.682378</td>\n",
              "      <td>0.758920</td>\n",
              "      <td>0.696624</td>\n",
              "      <td>0.754129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.210100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.812149</td>\n",
              "      <td>0.852623</td>\n",
              "      <td>0.854728</td>\n",
              "      <td>0.852791</td>\n",
              "      <td>0.741194</td>\n",
              "      <td>0.699684</td>\n",
              "      <td>0.777890</td>\n",
              "      <td>0.726955</td>\n",
              "      <td>0.789873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.169300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.830526</td>\n",
              "      <td>0.868735</td>\n",
              "      <td>0.873295</td>\n",
              "      <td>0.863507</td>\n",
              "      <td>0.719755</td>\n",
              "      <td>0.724748</td>\n",
              "      <td>0.803721</td>\n",
              "      <td>0.735492</td>\n",
              "      <td>0.799499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.146600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.874426</td>\n",
              "      <td>0.899695</td>\n",
              "      <td>0.901687</td>\n",
              "      <td>0.900195</td>\n",
              "      <td>0.779990</td>\n",
              "      <td>0.748150</td>\n",
              "      <td>0.824007</td>\n",
              "      <td>0.776015</td>\n",
              "      <td>0.838105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.154900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.884635</td>\n",
              "      <td>0.910099</td>\n",
              "      <td>0.913227</td>\n",
              "      <td>0.909428</td>\n",
              "      <td>0.771822</td>\n",
              "      <td>0.753171</td>\n",
              "      <td>0.831685</td>\n",
              "      <td>0.776062</td>\n",
              "      <td>0.842745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.929556</td>\n",
              "      <td>0.944406</td>\n",
              "      <td>0.946456</td>\n",
              "      <td>0.944998</td>\n",
              "      <td>0.788157</td>\n",
              "      <td>0.770151</td>\n",
              "      <td>0.845038</td>\n",
              "      <td>0.791937</td>\n",
              "      <td>0.868467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.100800</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.925472</td>\n",
              "      <td>0.942663</td>\n",
              "      <td>0.944863</td>\n",
              "      <td>0.941830</td>\n",
              "      <td>0.790710</td>\n",
              "      <td>0.773458</td>\n",
              "      <td>0.858210</td>\n",
              "      <td>0.795203</td>\n",
              "      <td>0.868516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.078400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.942828</td>\n",
              "      <td>0.955397</td>\n",
              "      <td>0.957689</td>\n",
              "      <td>0.955477</td>\n",
              "      <td>0.813680</td>\n",
              "      <td>0.787632</td>\n",
              "      <td>0.870368</td>\n",
              "      <td>0.814120</td>\n",
              "      <td>0.884798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.078900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.966309</td>\n",
              "      <td>0.972638</td>\n",
              "      <td>0.975004</td>\n",
              "      <td>0.973649</td>\n",
              "      <td>0.832057</td>\n",
              "      <td>0.804258</td>\n",
              "      <td>0.884420</td>\n",
              "      <td>0.830874</td>\n",
              "      <td>0.902261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.052200</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.970904</td>\n",
              "      <td>0.975983</td>\n",
              "      <td>0.978408</td>\n",
              "      <td>0.977076</td>\n",
              "      <td>0.829505</td>\n",
              "      <td>0.802817</td>\n",
              "      <td>0.884637</td>\n",
              "      <td>0.828694</td>\n",
              "      <td>0.902885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.061400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.978050</td>\n",
              "      <td>0.981187</td>\n",
              "      <td>0.983675</td>\n",
              "      <td>0.982406</td>\n",
              "      <td>0.840225</td>\n",
              "      <td>0.809070</td>\n",
              "      <td>0.889399</td>\n",
              "      <td>0.836589</td>\n",
              "      <td>0.909497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.066300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.977029</td>\n",
              "      <td>0.980446</td>\n",
              "      <td>0.982931</td>\n",
              "      <td>0.981645</td>\n",
              "      <td>0.845329</td>\n",
              "      <td>0.812770</td>\n",
              "      <td>0.892117</td>\n",
              "      <td>0.840727</td>\n",
              "      <td>0.911186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ SECTION 10: Model Training Execution completed in 3.4h 26m\n",
            "🕒 Total runtime so far: 3.5h 28m\n",
            "------------------------------------------------------------\n",
            "\n",
            "🚀 Starting SECTION 11+: Evaluation & Calibration...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  model_key                     base_name  test_test_sent_acc  \\\n",
              "0     mbert  bert-base-multilingual-cased            0.978571   \n",
              "\n",
              "   test_test_sent_prec  test_test_sent_rec  test_test_sent_f1  \\\n",
              "0             0.980454              0.9841           0.982187   \n",
              "\n",
              "   test_test_pol_acc  test_test_pol_prec  test_test_pol_rec  test_test_pol_f1  \\\n",
              "0           0.839796            0.812217           0.890444          0.838918   \n",
              "\n",
              "   test_test_macro_f1_avg  test_test_runtime  test_test_samples_per_second  \\\n",
              "0                0.910552             7.0353                       278.594   \n",
              "\n",
              "   test_test_steps_per_second  \n",
              "0                      23.311  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-229edff9-7f3a-4815-8e7a-97e4f89ad885\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_key</th>\n",
              "      <th>base_name</th>\n",
              "      <th>test_test_sent_acc</th>\n",
              "      <th>test_test_sent_prec</th>\n",
              "      <th>test_test_sent_rec</th>\n",
              "      <th>test_test_sent_f1</th>\n",
              "      <th>test_test_pol_acc</th>\n",
              "      <th>test_test_pol_prec</th>\n",
              "      <th>test_test_pol_rec</th>\n",
              "      <th>test_test_pol_f1</th>\n",
              "      <th>test_test_macro_f1_avg</th>\n",
              "      <th>test_test_runtime</th>\n",
              "      <th>test_test_samples_per_second</th>\n",
              "      <th>test_test_steps_per_second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mbert</td>\n",
              "      <td>bert-base-multilingual-cased</td>\n",
              "      <td>0.978571</td>\n",
              "      <td>0.980454</td>\n",
              "      <td>0.9841</td>\n",
              "      <td>0.982187</td>\n",
              "      <td>0.839796</td>\n",
              "      <td>0.812217</td>\n",
              "      <td>0.890444</td>\n",
              "      <td>0.838918</td>\n",
              "      <td>0.910552</td>\n",
              "      <td>7.0353</td>\n",
              "      <td>278.594</td>\n",
              "      <td>23.311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229edff9-7f3a-4815-8e7a-97e4f89ad885')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-229edff9-7f3a-4815-8e7a-97e4f89ad885 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-229edff9-7f3a-4815-8e7a-97e4f89ad885');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_0f897711-ab96-44bb-9c14-0f1b6c7d8712\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0f897711-ab96-44bb-9c14-0f1b6c7d8712 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mbert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bert-base-multilingual-cased\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9785714285714285,\n        \"max\": 0.9785714285714285,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9785714285714285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9804538372463926,\n        \"max\": 0.9804538372463926,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9804538372463926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9840997081344821,\n        \"max\": 0.9840997081344821,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9840997081344821\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9821865046160423,\n        \"max\": 0.9821865046160423,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9821865046160423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8397959183673469,\n        \"max\": 0.8397959183673469,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8397959183673469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8122174465827716,\n        \"max\": 0.8122174465827716,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8122174465827716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8904437684513647,\n        \"max\": 0.8904437684513647,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8904437684513647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8389183980130247,\n        \"max\": 0.8389183980130247,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8389183980130247\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_macro_f1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.9105524513145336,\n        \"max\": 0.9105524513145336,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.9105524513145336\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7.0353,\n        \"max\": 7.0353,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.0353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 278.594,\n        \"max\": 278.594,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          278.594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 23.311,\n        \"max\": 23.311,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          23.311\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SECTION 10A\n"
      ],
      "metadata": {
        "id": "lSS37GWDbBw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 10A — VERIFY ARTIFACTS & RESOLVE TOKENIZER + WEIGHTS (v2)\n",
        "# Builds maps for: tokenizer_dir (usually run root) and weights_dir (checkpoint or run root).\n",
        "# Run AFTER Section 10 (training) and BEFORE 11B/11C.\n",
        "# ============================================================================\n",
        "\n",
        "import os, re, json\n",
        "from typing import Optional, Dict\n",
        "\n",
        "def _has_weights(path: str) -> bool:\n",
        "    return os.path.isfile(os.path.join(path, \"pytorch_model.bin\")) or os.path.isfile(os.path.join(path, \"model.safetensors\"))\n",
        "\n",
        "def _has_tokenizer(path: str) -> bool:\n",
        "    # Minimal tokenizer files\n",
        "    return (\n",
        "        os.path.isfile(os.path.join(path, \"tokenizer.json\")) or\n",
        "        os.path.isfile(os.path.join(path, \"vocab.txt\")) or\n",
        "        os.path.isfile(os.path.join(path, \"spiece.model\"))\n",
        "    )\n",
        "\n",
        "def _list_checkpoints(run_dir: str):\n",
        "    if not os.path.isdir(run_dir): return []\n",
        "    chks = []\n",
        "    for name in os.listdir(run_dir):\n",
        "        p = os.path.join(run_dir, name)\n",
        "        if os.path.isdir(p) and re.match(r\"^checkpoint-\\d+$\", name):\n",
        "            chks.append(p)\n",
        "    # sort by gl\n"
      ],
      "metadata": {
        "id": "QlNuczl4bDPJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 11\n"
      ],
      "metadata": {
        "id": "1JZdHWRfbvzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 11 — Detailed Breakdown Reports (per-class + cross-slices) =====\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "def per_class_breakdown(y_true, y_pred, class_names):\n",
        "    rep = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=list(class_names),\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "    # Keep only the class rows in the given order\n",
        "    rows = []\n",
        "    for cname in class_names:\n",
        "        if cname in rep:\n",
        "            rows.append({\n",
        "                \"class\": cname,\n",
        "                \"precision\": rep[cname][\"precision\"],\n",
        "                \"recall\":    rep[cname][\"recall\"],\n",
        "                \"f1\":        rep[cname][\"f1-score\"],\n",
        "                \"support\":   int(rep[cname][\"support\"]),\n",
        "            })\n",
        "        else:\n",
        "            rows.append({\"class\": cname, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"support\": 0})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def cross_slice_breakdown(\n",
        "    slice_true,  # array of ints for the slicing label (e.g., true sentiment indices)\n",
        "    slice_names, # names of the slicing label classes (e.g., sentiment class names)\n",
        "    task_true,   # array of ints for the task we evaluate (e.g., true polarity indices)\n",
        "    task_pred,   # array of ints for the task predictions (e.g., predicted polarity indices)\n",
        "    task_names,  # names of the task classes (e.g., polarity class names)\n",
        "    slice_label  # string for the slice axis name, e.g., \"sentiment\" or \"polarity\"\n",
        "):\n",
        "    \"\"\"\n",
        "    For each class s in slice_true, evaluate the task predictions on the subset where slice_true == s.\n",
        "    Returns one row per slice value, including macro-F1, accuracy, and per-class F1 for the task.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for idx, sname in enumerate(slice_names):\n",
        "        mask = (slice_true == idx)\n",
        "        n = int(mask.sum())\n",
        "        if n == 0:\n",
        "            # No samples for this slice in test set\n",
        "            row = {\"slice\": sname, \"support\": 0, \"accuracy\": np.nan, \"macro_f1\": np.nan}\n",
        "            for tname in task_names:\n",
        "                row[f\"f1_{tname}\"] = np.nan\n",
        "            rows.append(row)\n",
        "            continue\n",
        "\n",
        "        rep = classification_report(\n",
        "            task_true[mask], task_pred[mask],\n",
        "            target_names=list(task_names),\n",
        "            output_dict=True, zero_division=0\n",
        "        )\n",
        "        row = {\n",
        "            \"slice\": sname,\n",
        "            \"support\": n,\n",
        "            \"accuracy\": rep[\"accuracy\"],\n",
        "            \"macro_f1\": rep[\"macro avg\"][\"f1-score\"],\n",
        "        }\n",
        "        for tname in task_names:\n",
        "            row[f\"f1_{tname}\"] = rep[tname][\"f1-score\"]\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Sort slices by support (desc) for readability\n",
        "    df = df.sort_values(by=\"support\", ascending=False).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Where to save things\n",
        "DETAILS_DIR = os.path.join(OUT_DIR, \"details\")\n",
        "os.makedirs(DETAILS_DIR, exist_ok=True)\n",
        "\n",
        "all_breakdowns = {}\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\n=== Detailed breakdowns for {key} ===\")\n",
        "    ysent_pred, ypol_pred = pred_cache[key]\n",
        "\n",
        "    # ---- Per-class reports on the full test set\n",
        "    sent_per_class = per_class_breakdown(ysent_test, ysent_pred, sent_le.classes_)\n",
        "    pol_per_class  = per_class_breakdown(ypol_test,  ypol_pred,  pol_le.classes_)\n",
        "\n",
        "    # Save + show\n",
        "    sent_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_per_class.csv\")\n",
        "    pol_csv  = os.path.join(DETAILS_DIR, f\"{key}_polarization_per_class.csv\")\n",
        "    sent_per_class.to_csv(sent_csv, index=False)\n",
        "    pol_per_class.to_csv(pol_csv, index=False)\n",
        "\n",
        "    print(\"\\nSentiment — per class (precision/recall/F1/support):\")\n",
        "    display(sent_per_class)\n",
        "\n",
        "    print(\"\\nPolarization — per class (precision/recall/F1/support):\")\n",
        "    display(pol_per_class)\n",
        "\n",
        "    # ---- Cross-slice reports\n",
        "    # Polarity performance within each (true) sentiment slice\n",
        "    pol_given_sent = cross_slice_breakdown(\n",
        "        slice_true=ysent_test, slice_names=sent_le.classes_,\n",
        "        task_true=ypol_test,   task_pred=ypol_pred, task_names=pol_le.classes_,\n",
        "        slice_label=\"sentiment\"\n",
        "    )\n",
        "    pol_given_sent_csv = os.path.join(DETAILS_DIR, f\"{key}_polarity_given_sentiment.csv\")\n",
        "    pol_given_sent.to_csv(pol_given_sent_csv, index=False)\n",
        "\n",
        "    print(\"\\nPolarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\")\n",
        "    display(pol_given_sent)\n",
        "\n",
        "    # Sentiment performance within each (true) polarity slice\n",
        "    sent_given_pol = cross_slice_breakdown(\n",
        "        slice_true=ypol_test,  slice_names=pol_le.classes_,\n",
        "        task_true=ysent_test,  task_pred=ysent_pred, task_names=sent_le.classes_,\n",
        "        slice_label=\"polarity\"\n",
        "    )\n",
        "    sent_given_pol_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_given_polarity.csv\")\n",
        "    sent_given_pol.to_csv(sent_given_pol_csv, index=False)\n",
        "\n",
        "    print(\"\\nSentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\")\n",
        "    display(sent_given_pol)\n",
        "\n",
        "    # Keep for a single JSON bundle if you like\n",
        "    all_breakdowns[key] = {\n",
        "        \"sentiment_per_class_csv\": sent_csv,\n",
        "        \"polarization_per_class_csv\": pol_csv,\n",
        "        \"polarity_given_sentiment_csv\": pol_given_sent_csv,\n",
        "        \"sentiment_given_polarity_csv\": sent_given_pol_csv\n",
        "    }\n",
        "\n",
        "# Optional: write an index JSON pointing to all CSVs\n",
        "with open(os.path.join(DETAILS_DIR, \"index.json\"), \"w\") as f:\n",
        "    json.dump(all_breakdowns, f, indent=2)\n",
        "print(\"\\nSaved detailed breakdowns to:\", DETAILS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "t1I1V0MJbyH2",
        "outputId": "76b8248a-7929-4a9b-9e45-36a198345fc1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Detailed breakdowns for mbert ===\n",
            "\n",
            "Sentiment — per class (precision/recall/F1/support):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      class  precision    recall        f1  support\n",
              "0  negative   0.988453  0.966140  0.977169      886\n",
              "1   neutral   0.967195  0.986159  0.976585      867\n",
              "2  positive   0.985714  1.000000  0.992806      207"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce4eeaa7-9790-4db7-b348-63c582ee67de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.988453</td>\n",
              "      <td>0.966140</td>\n",
              "      <td>0.977169</td>\n",
              "      <td>886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.967195</td>\n",
              "      <td>0.986159</td>\n",
              "      <td>0.976585</td>\n",
              "      <td>867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.992806</td>\n",
              "      <td>207</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce4eeaa7-9790-4db7-b348-63c582ee67de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce4eeaa7-9790-4db7-b348-63c582ee67de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce4eeaa7-9790-4db7-b348-63c582ee67de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3ca6e7c2-8ebc-4905-a057-fb5461cf5240\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ca6e7c2-8ebc-4905-a057-fb5461cf5240')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3ca6e7c2-8ebc-4905-a057-fb5461cf5240 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1299b324-dc6e-4902-8a87-150a6ea67e58\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_per_class')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1299b324-dc6e-4902-8a87-150a6ea67e58 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sent_per_class');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sent_per_class",
              "summary": "{\n  \"name\": \"sent_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011564203000519968,\n        \"min\": 0.9671945701357466,\n        \"max\": 0.9884526558891455,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9884526558891455,\n          0.9671945701357466,\n          0.9857142857142858\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017023709946032216,\n        \"min\": 0.9661399548532731,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9661399548532731,\n          0.986159169550173,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009201177671592549,\n        \"min\": 0.9765848086807538,\n        \"max\": 0.9928057553956835,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9771689497716894,\n          0.9765848086807538,\n          0.9928057553956835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 386,\n        \"min\": 207,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          867,\n          207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Polarization — per class (precision/recall/F1/support):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           class  precision    recall        f1  support\n",
              "0  non_polarized   0.718954  0.888530  0.794798      619\n",
              "1      objective   0.747368  1.000000  0.855422      213\n",
              "2       partisan   0.970330  0.782801  0.866536     1128"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1165a45-469e-4721-9861-4c5ed363f017\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>non_polarized</td>\n",
              "      <td>0.718954</td>\n",
              "      <td>0.888530</td>\n",
              "      <td>0.794798</td>\n",
              "      <td>619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>objective</td>\n",
              "      <td>0.747368</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.855422</td>\n",
              "      <td>213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>partisan</td>\n",
              "      <td>0.970330</td>\n",
              "      <td>0.782801</td>\n",
              "      <td>0.866536</td>\n",
              "      <td>1128</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1165a45-469e-4721-9861-4c5ed363f017')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f1165a45-469e-4721-9861-4c5ed363f017 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f1165a45-469e-4721-9861-4c5ed363f017');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a9aacc85-20dd-489b-aab9-aecbdb2e56fc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9aacc85-20dd-489b-aab9-aecbdb2e56fc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a9aacc85-20dd-489b-aab9-aecbdb2e56fc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_53b7bc4c-db91-4536-8775-a3e12ea575c0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_per_class')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_53b7bc4c-db91-4536-8775-a3e12ea575c0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pol_per_class');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pol_per_class",
              "summary": "{\n  \"name\": \"pol_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"non_polarized\",\n          \"objective\",\n          \"partisan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13766425743819002,\n        \"min\": 0.7189542483660131,\n        \"max\": 0.9703296703296703,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7189542483660131,\n          0.7473684210526316,\n          0.9703296703296703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10861193840850562,\n        \"min\": 0.7828014184397163,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8885298869143781,\n          1.0,\n          0.7828014184397163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.038611640531705925,\n        \"min\": 0.7947976878612717,\n        \"max\": 0.8665358194308145,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7947976878612717,\n          0.8554216867469879,\n          0.8665358194308145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 458,\n        \"min\": 213,\n        \"max\": 1128,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          619,\n          213,\n          1128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Polarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      slice  support  accuracy  macro_f1  f1_non_polarized  f1_objective  \\\n",
              "0  negative      886  0.942438  0.918067          0.842444      0.947368   \n",
              "1   neutral      867  0.705882  0.672244          0.759788      0.835322   \n",
              "2  positive      207  0.961353  0.969066          0.937500      1.000000   \n",
              "\n",
              "   f1_partisan  \n",
              "0     0.964387  \n",
              "1     0.421622  \n",
              "2     0.969697  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af5c8bf7-6cf9-4747-84d0-a444e0bfe0a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice</th>\n",
              "      <th>support</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>f1_non_polarized</th>\n",
              "      <th>f1_objective</th>\n",
              "      <th>f1_partisan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>886</td>\n",
              "      <td>0.942438</td>\n",
              "      <td>0.918067</td>\n",
              "      <td>0.842444</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.964387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>867</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.672244</td>\n",
              "      <td>0.759788</td>\n",
              "      <td>0.835322</td>\n",
              "      <td>0.421622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>207</td>\n",
              "      <td>0.961353</td>\n",
              "      <td>0.969066</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.969697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5c8bf7-6cf9-4747-84d0-a444e0bfe0a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af5c8bf7-6cf9-4747-84d0-a444e0bfe0a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af5c8bf7-6cf9-4747-84d0-a444e0bfe0a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8ddbfba8-fd84-4b56-8e50-6165604f1836\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ddbfba8-fd84-4b56-8e50-6165604f1836')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8ddbfba8-fd84-4b56-8e50-6165604f1836 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_d8a96ea3-9727-4d18-9bbd-3928ff4a929e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_given_sent')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d8a96ea3-9727-4d18-9bbd-3928ff4a929e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pol_given_sent');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pol_given_sent",
              "summary": "{\n  \"name\": \"pol_given_sent\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 386,\n        \"min\": 207,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          867,\n          207\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14235014416089795,\n        \"min\": 0.7058823529411765,\n        \"max\": 0.961352657004831,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9424379232505643,\n          0.7058823529411765,\n          0.961352657004831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15870972570013211,\n        \"min\": 0.6722440590380129,\n        \"max\": 0.9690656565656566,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9180665384478776,\n          0.6722440590380129,\n          0.9690656565656566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_non_polarized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08892790315778293,\n        \"min\": 0.7597883597883598,\n        \"max\": 0.9375,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.842443729903537,\n          0.7597883597883598,\n          0.9375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_objective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08410630074008463,\n        \"min\": 0.8353221957040573,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9473684210526315,\n          0.8353221957040573,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_partisan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31490991783044375,\n        \"min\": 0.42162162162162165,\n        \"max\": 0.9696969696969697,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9643874643874644,\n          0.42162162162162165,\n          0.9696969696969697\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           slice  support  accuracy  macro_f1  f1_negative  f1_neutral  \\\n",
              "0       partisan     1128  0.984043  0.984485     0.987342    0.969805   \n",
              "1  non_polarized      619  0.969305  0.969439     0.930909    0.977408   \n",
              "2      objective      213  0.976526  0.949237     0.945455    0.985591   \n",
              "\n",
              "   f1_positive  \n",
              "0     0.996310  \n",
              "1     1.000000  \n",
              "2     0.916667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00e734a1-47df-47f1-8227-03129839c22f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice</th>\n",
              "      <th>support</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>f1_negative</th>\n",
              "      <th>f1_neutral</th>\n",
              "      <th>f1_positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>partisan</td>\n",
              "      <td>1128</td>\n",
              "      <td>0.984043</td>\n",
              "      <td>0.984485</td>\n",
              "      <td>0.987342</td>\n",
              "      <td>0.969805</td>\n",
              "      <td>0.996310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>non_polarized</td>\n",
              "      <td>619</td>\n",
              "      <td>0.969305</td>\n",
              "      <td>0.969439</td>\n",
              "      <td>0.930909</td>\n",
              "      <td>0.977408</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>objective</td>\n",
              "      <td>213</td>\n",
              "      <td>0.976526</td>\n",
              "      <td>0.949237</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.985591</td>\n",
              "      <td>0.916667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00e734a1-47df-47f1-8227-03129839c22f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00e734a1-47df-47f1-8227-03129839c22f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00e734a1-47df-47f1-8227-03129839c22f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a3d6c58-30d0-438f-87e6-09325f92215d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a3d6c58-30d0-438f-87e6-09325f92215d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a3d6c58-30d0-438f-87e6-09325f92215d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e1eba1e1-5f45-4e60-a4bb-793910f3668b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_given_pol')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e1eba1e1-5f45-4e60-a4bb-793910f3668b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sent_given_pol');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sent_given_pol",
              "summary": "{\n  \"name\": \"sent_given_pol\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"partisan\",\n          \"non_polarized\",\n          \"objective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 458,\n        \"min\": 213,\n        \"max\": 1128,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1128,\n          619,\n          213\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007369107231903501,\n        \"min\": 0.9693053311793215,\n        \"max\": 0.9840425531914894,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9840425531914894,\n          0.9693053311793215,\n          0.9765258215962441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017686779366392836,\n        \"min\": 0.9492373300730649,\n        \"max\": 0.9844854511229197,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9844854511229197,\n          0.9694389795697762,\n          0.9492373300730649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_negative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029299480998195494,\n        \"min\": 0.9309090909090909,\n        \"max\": 0.9873417721518988,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9873417721518988,\n          0.9309090909090909,\n          0.9454545454545454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007894853775385138,\n        \"min\": 0.9698046181172292,\n        \"max\": 0.9855907780979827,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9698046181172292,\n          0.9774078478002378,\n          0.9855907780979827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04708346398237846,\n        \"min\": 0.9166666666666666,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.996309963099631,\n          1.0,\n          0.9166666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved detailed breakdowns to: ./runs_mbert_optimized/details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### SECTION 11A\n",
        "Changed from 11C"
      ],
      "metadata": {
        "id": "_Q7YNE1ga4-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# SECTION 11C — MULTICLASS POLARITY CALIBRATION (v2)\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np, json, os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments, DataCollatorWithPadding\n",
        "\n",
        "# ============================================================================\n",
        "# Helper Functions for Calibration\n",
        "# ============================================================================\n",
        "\n",
        "class _PlainPairDS(Dataset):\n",
        "    \"\"\"Simple dataset for inference-only (no labels needed)\"\"\"\n",
        "    def __init__(self, titles, texts, tokenizer, max_length=224):\n",
        "        self.titles, self.texts = list(titles), list(texts)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.use_tt = \"token_type_ids\" in tokenizer.model_input_names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tok(\n",
        "            text=str(self.titles[idx]),\n",
        "            text_pair=str(self.texts[idx]),\n",
        "            truncation=\"only_second\",\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=self.use_tt\n",
        "        )\n",
        "\n",
        "def _get_pol_logits(model_key, titles, texts):\n",
        "    \"\"\"Get polarization logits from trained model\"\"\"\n",
        "    # Load tokenizer and model\n",
        "    run_dir = os.path.join(OUT_DIR, model_key)\n",
        "    model_name = MODEL_CONFIGS[model_key][\"name\"]\n",
        "\n",
        "    print(f\"   Loading model from: {run_dir}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(run_dir if os.path.exists(os.path.join(run_dir, \"tokenizer.json\")) else model_name)\n",
        "\n",
        "    # Rebuild model and load weights\n",
        "    model = MultiTaskModel(model_name, num_sent_classes, num_pol_classes)\n",
        "\n",
        "    # 🔧 RUN #9 FIX: Robust model loading - check multiple possible weight file formats\n",
        "    # Modern Transformers saves in different formats (pytorch_model.bin, model.safetensors, checkpoint-*/pytorch_model.bin)\n",
        "    weights_loaded = False\n",
        "\n",
        "    # Try 1: pytorch_model.bin in root\n",
        "    model_file = os.path.join(run_dir, \"pytorch_model.bin\")\n",
        "    if os.path.exists(model_file):\n",
        "        print(f\"   ✓ Loading weights from: {model_file}\")\n",
        "        model.load_state_dict(torch.load(model_file, map_location=device), strict=False)\n",
        "        weights_loaded = True\n",
        "\n",
        "    # Try 2: model.safetensors in root\n",
        "    if not weights_loaded:\n",
        "        model_file = os.path.join(run_dir, \"model.safetensors\")\n",
        "        if os.path.exists(model_file):\n",
        "            print(f\"   ✓ Loading weights from: {model_file}\")\n",
        "            from safetensors.torch import load_file\n",
        "            state_dict = load_file(model_file)\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "            weights_loaded = True\n",
        "\n",
        "    # Try 3: Latest checkpoint subdirectory (checkpoint-XXXX/pytorch_model.bin)\n",
        "    if not weights_loaded:\n",
        "        checkpoints = [d for d in os.listdir(run_dir) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(run_dir, d))]\n",
        "        if checkpoints:\n",
        "            # Get the latest checkpoint by number\n",
        "            latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[1]))[-1]\n",
        "            checkpoint_dir = os.path.join(run_dir, latest_checkpoint)\n",
        "            model_file = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "            if os.path.exists(model_file):\n",
        "                print(f\"   ✓ Loading weights from checkpoint: {checkpoint_dir}\")\n",
        "                model.load_state_dict(torch.load(model_file, map_location=device), strict=False)\n",
        "                weights_loaded = True\n",
        "\n",
        "    if not weights_loaded:\n",
        "        print(f\"   ⚠️ WARNING: No trained weights found in {run_dir}\")\n",
        "        print(f\"      Checked: pytorch_model.bin, model.safetensors, checkpoint-*/pytorch_model.bin\")\n",
        "        print(f\"      Using UNTRAINED model - calibration will be ineffective!\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Create dataset and trainer\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "    args = TrainingArguments(\n",
        "        output_dir=os.path.join(run_dir, \"calib_tmp\"),\n",
        "        per_device_eval_batch_size=64,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    dummy_trainer = MultiTaskTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        data_collator=collator,\n",
        "        class_weights=None,\n",
        "        task_weights=None\n",
        "    )\n",
        "\n",
        "    ds = _PlainPairDS(titles, texts, tokenizer, MAX_LENGTH)\n",
        "    out = dummy_trainer.predict(ds)\n",
        "    _, pol_logits = out.predictions\n",
        "\n",
        "    return pol_logits\n",
        "\n",
        "# ============================================================================\n",
        "# Calibration Functions\n",
        "# ============================================================================\n",
        "\n",
        "def coord_search_biases(pol_logits_val, y_val, class_names, passes=2, grid=(-0.8, 0.8, 0.1)):\n",
        "    lo, hi, step = grid\n",
        "    C = pol_logits_val.shape[1]\n",
        "    b = np.zeros(C, dtype=np.float32)\n",
        "\n",
        "    def macro_f1_with(bias_vec):\n",
        "        y_pred = np.argmax(pol_logits_val + bias_vec.reshape(1, -1), axis=1)\n",
        "        rep = classification_report(y_val, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
        "        return rep[\"macro avg\"][\"f1-score\"]\n",
        "\n",
        "    best = macro_f1_with(b)\n",
        "    for _ in range(passes):\n",
        "        improved = False\n",
        "        for c in range(C):\n",
        "            best_b_c, best_score_c = b[c], best\n",
        "            for val in np.arange(lo, hi + 1e-9, step):\n",
        "                b_try = b.copy()\n",
        "                b_try[c] = val\n",
        "                score = macro_f1_with(b_try)\n",
        "                if score > best_score_c + 1e-6:\n",
        "                    best_score_c, best_b_c = score, val\n",
        "            if best_b_c != b[c]:\n",
        "                b[c] = best_b_c\n",
        "                best = best_score_c\n",
        "                improved = True\n",
        "        if not improved:\n",
        "            break\n",
        "    return b, float(best)\n",
        "\n",
        "CALIB_DIR2 = os.path.join(OUT_DIR, \"calibration_vector\")\n",
        "os.makedirs(CALIB_DIR2, exist_ok=True)\n",
        "\n",
        "print(\"🎯 MULTICLASS CALIBRATION - Optimize prediction biases for better performance\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\n🔧 Calibrating {key} ({MODEL_CONFIGS[key]['name']})...\")\n",
        "\n",
        "    print(f\"📊 Step 1: Extracting polarization logits from trained model...\")\n",
        "    pol_val_logits = _get_pol_logits(key, X_val[TITLE_COL].values,  X_val[TEXT_COL].values)\n",
        "    pol_tst_logits = _get_pol_logits(key, X_test[TITLE_COL].values, X_test[TEXT_COL].values)\n",
        "    print(f\"   ✓ Validation logits shape: {pol_val_logits.shape}\")\n",
        "    print(f\"   ✓ Test logits shape: {pol_tst_logits.shape}\")\n",
        "\n",
        "    y_val = ypol_val\n",
        "    y_tst = ypol_test\n",
        "    class_names = list(pol_le.classes_)\n",
        "\n",
        "    print(f\"🔍 Step 2: Searching for optimal bias vector (coordinate search)...\")\n",
        "    b_vec, val_macro = coord_search_biases(pol_val_logits, y_val, class_names, passes=3, grid=(-0.8, 0.8, 0.1))\n",
        "    print(f\"   ✓ Optimal bias vector found (VAL macro-F1={val_macro:.3f}):\")\n",
        "    for cname, bias_val in zip(class_names, b_vec):\n",
        "        print(f\"      • {cname:>13}: {bias_val:+.2f}\")\n",
        "\n",
        "    # Test before/after\n",
        "    print(f\"📈 Step 3: Evaluating calibration impact on test set...\")\n",
        "    y_before = np.argmax(pol_tst_logits, axis=1)\n",
        "    rep_before = classification_report(y_tst, y_before, target_names=class_names, output_dict=True, zero_division=0)\n",
        "\n",
        "    y_after = np.argmax(pol_tst_logits + b_vec.reshape(1, -1), axis=1)\n",
        "    rep_after  = classification_report(y_tst, y_after, target_names=class_names, output_dict=True, zero_division=0)\n",
        "\n",
        "    improvement = rep_after['macro avg']['f1-score'] - rep_before['macro avg']['f1-score']\n",
        "    print(f\"\\n   📊 TEST MACRO-F1: {rep_before['macro avg']['f1-score']:.3f} → {rep_after['macro avg']['f1-score']:.3f} ({improvement:+.3f})\\n\")\n",
        "    print(\"   Per-class breakdown:\")\n",
        "    for cname in class_names:\n",
        "        b = rep_before[cname]; a = rep_after[cname]\n",
        "        f1_change = a['f1-score'] - b['f1-score']\n",
        "        emoji = \"📈\" if f1_change > 0 else \"📉\" if f1_change < 0 else \"➡️\"\n",
        "        print(f\"   {emoji} {cname:>13}: P={b['precision']:.3f} R={b['recall']:.3f} F1={b['f1-score']:.3f} (n={int(b['support'])})\"\n",
        "              f\"  →  P={a['precision']:.3f} R={a['recall']:.3f} F1={a['f1-score']:.3f} ({f1_change:+.3f})\")\n",
        "\n",
        "    # Save calibration results\n",
        "    calib_file = os.path.join(CALIB_DIR2, f\"{key}_bias_vector.json\")\n",
        "    with open(calib_file, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"bias_vector\": {class_names[i]: float(b_vec[i]) for i in range(len(class_names))},\n",
        "            \"val_macro_f1\": val_macro,\n",
        "            \"test_macro_f1_before\": float(rep_before[\"macro avg\"][\"f1-score\"]),\n",
        "            \"test_macro_f1_after\":  float(rep_after[\"macro avg\"][\"f1-score\"])\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"\\n✅ Calibration complete! Bias vector saved to:\")\n",
        "    print(f\"   {calib_file}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"🎉 CALIBRATION FINISHED - All models optimized!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "r9m5OlPQkFZ6",
        "outputId": "f63829d3-74ba-4095-ac6f-f3769d9cf03d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 MULTICLASS CALIBRATION - Optimize prediction biases for better performance\n",
            "======================================================================\n",
            "\n",
            "🔧 Calibrating mbert (bert-base-multilingual-cased)...\n",
            "📊 Step 1: Extracting polarization logits from trained model...\n",
            "   Loading model from: ./runs_mbert_optimized/mbert\n",
            "   ✓ Loading weights from: ./runs_mbert_optimized/mbert/model.safetensors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Loading model from: ./runs_mbert_optimized/mbert\n",
            "   ✓ Loading weights from: ./runs_mbert_optimized/mbert/model.safetensors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ✓ Validation logits shape: (1959, 3)\n",
            "   ✓ Test logits shape: (1960, 3)\n",
            "🔍 Step 2: Searching for optimal bias vector (coordinate search)...\n",
            "   ✓ Optimal bias vector found (VAL macro-F1=0.842):\n",
            "      • non_polarized: +0.00\n",
            "      •     objective: -0.20\n",
            "      •      partisan: +0.00\n",
            "📈 Step 3: Evaluating calibration impact on test set...\n",
            "\n",
            "   📊 TEST MACRO-F1: 0.839 → 0.840 (+0.001)\n",
            "\n",
            "   Per-class breakdown:\n",
            "   📈 non_polarized: P=0.719 R=0.889 F1=0.795 (n=619)  →  P=0.718 R=0.890 F1=0.795 (+0.000)\n",
            "   📈     objective: P=0.747 R=1.000 F1=0.855 (n=213)  →  P=0.752 R=0.995 F1=0.857 (+0.001)\n",
            "   📈      partisan: P=0.970 R=0.783 F1=0.867 (n=1128)  →  P=0.970 R=0.784 F1=0.867 (+0.001)\n",
            "\n",
            "✅ Calibration complete! Bias vector saved to:\n",
            "   ./runs_mbert_optimized/calibration_vector/mbert_bias_vector.json\n",
            "\n",
            "======================================================================\n",
            "🎉 CALIBRATION FINISHED - All models optimized!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 12"
      ],
      "metadata": {
        "id": "WCGT3gEDcN9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Section 12 — Length Diagnostics (clean) =====\n",
        "import warnings\n",
        "\n",
        "def token_lengths_summary(texts, titles, tokenizer, n=5000):\n",
        "    # Random sample (or full if dataset is small)\n",
        "    n = min(n, len(texts))\n",
        "    idx = np.random.choice(len(texts), size=n, replace=False) if len(texts) > n else np.arange(len(texts))\n",
        "\n",
        "    lengths = []\n",
        "    # Silence the \"sequence > 512\" warnings emitted by some tokenizers for inspection\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\"Token indices sequence length is longer.*\")\n",
        "        for i in idx:\n",
        "            s = f\"{titles[i]} [SEP] {texts[i]}\"\n",
        "            # We want raw length pre-truncation to choose MAX_LENGTH wisely\n",
        "            ids = tokenizer.encode(s, add_special_tokens=True, truncation=False)\n",
        "            lengths.append(len(ids))\n",
        "\n",
        "    arr = np.array(lengths)\n",
        "    stats = {\n",
        "        \"mean\": float(arr.mean()),\n",
        "        \"p50\":  float(np.percentile(arr, 50)),\n",
        "        \"p90\":  float(np.percentile(arr, 90)),\n",
        "        \"p95\":  float(np.percentile(arr, 95)),\n",
        "        \"p99\":  float(np.percentile(arr, 99)),\n",
        "        \"max\":  int(arr.max())\n",
        "    }\n",
        "    print(\"Token length stats:\", stats)\n",
        "    return stats\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    name = MODEL_CONFIGS[key][\"name\"]\n",
        "    tok = AutoTokenizer.from_pretrained(name)\n",
        "    print(f\"\\n[{key}] {name}\")\n",
        "    token_lengths_summary(\n",
        "        texts=X_train[TEXT_COL].values,\n",
        "        titles=X_train[TITLE_COL].values,\n",
        "        tokenizer=tok,\n",
        "        n=5000\n",
        "    )\n",
        "\n",
        "# Tip:\n",
        "# If p95 is comfortably < 192, you're fine. If you see p95 > 192, consider MAX_LENGTH=224\n",
        "# (Update in Section 3 if you decide to bump it.)\n",
        "\n",
        "# Final timing summary\n",
        "timer.end_section(\"SECTION 11+: Evaluation & Calibration\")\n",
        "timer.get_summary()\n"
      ],
      "metadata": {
        "id": "NhPV4I6TcP53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12470c76-99e9-4269-c03a-8d2fc44bac9e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[mbert] bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token length stats: {'mean': 109.236, 'p50': 98.0, 'p90': 181.0, 'p95': 195.0, 'p99': 226.0, 'max': 916}\n",
            "✅ SECTION 11+: Evaluation & Calibration completed in 22.2s\n",
            "🕒 Total runtime so far: 3.5h 29m\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "⏱️  EXECUTION TIME SUMMARY\n",
            "============================================================\n",
            "SECTION 2: Environment & Imports         : 9.1s\n",
            "SECTION 3: Configuration Setup           : 19.7s\n",
            "SECTION 4: Data Loading & Preprocessing  : 14.6s\n",
            "SECTION 5-9: Model Architecture & Training Setup : 46.2s\n",
            "SECTION 10: Model Training Execution     : 3.4h 26m\n",
            "SECTION 11+: Evaluation & Calibration    : 22.2s\n",
            "======================================== : ==========\n",
            "TOTAL EXECUTION TIME                     : 3.5h 29m\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}