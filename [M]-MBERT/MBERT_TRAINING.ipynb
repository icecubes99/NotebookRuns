{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PEK4ueScFxe"
      },
      "source": [
        "## SECTION 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDy5SBFWV910",
        "outputId": "53be20b8-db8c-4c86-b4f1-1e4ce99e5b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing pinned, compatible versions â€¦\n",
            "NumPy: 2.1.1\n",
            "\n",
            "=== VERSION CHECK ===\n",
            "torch          : 2.9.0+cu128\n",
            "transformers   : 4.44.2\n",
            "accelerate     : 0.34.2\n",
            "datasets       : 2.21.0\n",
            "scikit-learn   : 1.5.2\n",
            "pandas         : 2.2.3\n",
            "numpy          : 2.1.1\n",
            "matplotlib     : 3.9.2\n",
            "\n",
            "CUDA Available: True\n",
            "CUDA Device Count: 1\n",
            "Current CUDA Device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SECTION 1: ENVIRONMENT SETUP (ROBUST, PY3.12-FRIENDLY)\n",
        "# ============================================================================\n",
        "\n",
        "import sys, subprocess, importlib, os\n",
        "\n",
        "def pipi(*pkgs):\n",
        "    # Force reinstall + no cache to avoid stale wheels\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"--force-reinstall\", \"--no-cache-dir\", *pkgs])\n",
        "\n",
        "print(\"Installing pinned, compatible versions â€¦\")\n",
        "# Torch: keep your existing CUDA build. If you don't have torch yet, uncomment the torch trio below.\n",
        "# pipi(\"torch==2.2.2\", \"torchaudio==2.2.2\", \"torchvision==0.17.2\")\n",
        "\n",
        "# Pin NumPy 2.x and libs that are built against it\n",
        "pipi(\n",
        "    \"numpy==2.1.1\",\n",
        "    \"pandas==2.2.3\",\n",
        "    \"scikit-learn==1.5.2\",\n",
        "    \"matplotlib==3.9.2\",\n",
        "    \"transformers==4.44.2\",\n",
        "    \"accelerate==0.34.2\",\n",
        "    \"datasets==2.21.0\",\n",
        ")\n",
        "\n",
        "# --- Import order matters; import numpy FIRST to catch ABI issues clearly\n",
        "import numpy as np\n",
        "print(\"NumPy:\", np.__version__)\n",
        "\n",
        "# Now the rest\n",
        "import torch, transformers, datasets, sklearn, pandas as pd, matplotlib, importlib\n",
        "\n",
        "print(\"\\n=== VERSION CHECK ===\")\n",
        "print(\"torch          :\", getattr(torch, \"__version__\", \"n/a\"))\n",
        "print(\"transformers   :\", transformers.__version__)\n",
        "print(\"accelerate     :\", importlib.import_module(\"accelerate\").__version__)\n",
        "print(\"datasets       :\", datasets.__version__)\n",
        "print(\"scikit-learn   :\", sklearn.__version__)\n",
        "print(\"pandas         :\", pd.__version__)\n",
        "print(\"numpy          :\", np.__version__)\n",
        "print(\"matplotlib     :\", matplotlib.__version__)\n",
        "\n",
        "# Sanity for TrainingArguments modern kwargs\n",
        "from packaging import version\n",
        "assert version.parse(transformers.__version__) >= version.parse(\"4.26.0\"), \\\n",
        "    \"Transformers too old for `evaluation_strategy`.\"\n",
        "\n",
        "# If NumPy was previously imported in this session, you may still have stale .soâ€™s in memory.\n",
        "# Simple guard: if you see an ABI error above, Restart runtime and run this cell again first.\n",
        "print(\"\\nCUDA Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
        "    print(\"Current CUDA Device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YTTcGb6L7tv"
      },
      "source": [
        "### SECTION 1.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oBBJ_lPL7VW",
        "outputId": "621ef0e2-7319-45cc-c272-fe6d09b16d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers version loaded in memory: 4.44.2\n",
            "Sample of supported TrainingArguments kwargs: ['accelerator_config', 'adafactor', 'adam_beta1', 'adam_beta2', 'adam_epsilon', 'auto_find_batch_size', 'batch_eval_metrics', 'bf16', 'bf16_full_eval', 'data_seed', 'dataloader_drop_last', 'dataloader_num_workers'] ...\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SECTION 1.5: VERSION CHECK + TRAININGARGUMENTS COMPATIBILITY SHIM\n",
        "# ============================================================================\n",
        "\n",
        "import inspect, importlib, sys\n",
        "import transformers as _tf\n",
        "\n",
        "print(\"Transformers version loaded in memory:\", _tf.__version__)\n",
        "\n",
        "def _supported_kwargs_of_training_args():\n",
        "    # Build the set of supported __init__ kwargs for the loaded TrainingArguments\n",
        "    try:\n",
        "        from transformers import TrainingArguments\n",
        "        sig = inspect.signature(TrainingArguments.__init__)\n",
        "        return set(sig.parameters.keys())\n",
        "    except Exception as e:\n",
        "        print(\"[Compat] Could not inspect TrainingArguments:\", e)\n",
        "        return set()\n",
        "\n",
        "_SUPPORTED_TA_KEYS = _supported_kwargs_of_training_args()\n",
        "print(\"Sample of supported TrainingArguments kwargs:\", sorted(list(_SUPPORTED_TA_KEYS))[:12], \"...\")\n",
        "\n",
        "def make_training_args_compat(**kwargs):\n",
        "    \"\"\"\n",
        "    Create TrainingArguments while dropping any kwargs unsupported by the loaded transformers version.\n",
        "    Prints what was ignored so you know if your runtime is old.\n",
        "    \"\"\"\n",
        "    from transformers import TrainingArguments\n",
        "    filtered = {k: v for k, v in kwargs.items() if k in _SUPPORTED_TA_KEYS}\n",
        "    ignored = [k for k in kwargs.keys() if k not in _SUPPORTED_TA_KEYS]\n",
        "    if ignored:\n",
        "        print(\"[Compat] Ignored unsupported TrainingArguments keys:\", ignored)\n",
        "    return TrainingArguments(**filtered)\n",
        "\n",
        "def get_early_stopping_callbacks(patience: int):\n",
        "    \"\"\"Return EarlyStoppingCallback if available; otherwise return [].\"\"\"\n",
        "    try:\n",
        "        from transformers import EarlyStoppingCallback\n",
        "        return [EarlyStoppingCallback(early_stopping_patience=patience)]\n",
        "    except Exception as e:\n",
        "        print(\"[Compat] EarlyStoppingCallback unavailable:\", e)\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG7la9p-cDKM"
      },
      "source": [
        "## SECTION 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSVM6xD6WkaF",
        "outputId": "0bc309d0-281d-4f29-d867-91a262e3b783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸš€ Starting SECTION 2: Environment & Imports...\n",
            "âœ… SECTION 2: Environment & Imports completed in 9.2s\n",
            "ðŸ•’ Total runtime so far: 9.2s\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸš€ Starting SECTION 3: Configuration Setup...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# SECTION 2: IMPORTS AND BASIC SETUP\n",
        "# ============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "# ============================================================================\n",
        "# TIMING UTILITY - Track execution time for each section\n",
        "# ============================================================================\n",
        "class SectionTimer:\n",
        "    def __init__(self):\n",
        "        self.section_times = {}\n",
        "        self.start_time = None\n",
        "        self.total_start = time.time()\n",
        "\n",
        "    def start_section(self, section_name):\n",
        "        \"\"\"Start timing a section\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        print(f\"\\nðŸš€ Starting {section_name}...\")\n",
        "\n",
        "    def end_section(self, section_name):\n",
        "        \"\"\"End timing and display results\"\"\"\n",
        "        if self.start_time is None:\n",
        "            self.start_time = time.time()\n",
        "\n",
        "        elapsed = time.time() - self.start_time\n",
        "        self.section_times[section_name] = elapsed\n",
        "\n",
        "        # Format time nicely\n",
        "        if elapsed < 60:\n",
        "            time_str = f\"{elapsed:.1f}s\"\n",
        "        elif elapsed < 3600:\n",
        "            time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
        "        else:\n",
        "            time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
        "\n",
        "        total_elapsed = time.time() - self.total_start\n",
        "        if total_elapsed < 60:\n",
        "            total_str = f\"{total_elapsed:.1f}s\"\n",
        "        elif total_elapsed < 3600:\n",
        "            total_str = f\"{total_elapsed/60:.1f}m {total_elapsed%60:.0f}s\"\n",
        "        else:\n",
        "            total_str = f\"{total_elapsed/3600:.1f}h {(total_elapsed%3600)/60:.0f}m\"\n",
        "\n",
        "        print(f\"âœ… {section_name} completed in {time_str}\")\n",
        "        print(f\"ðŸ•’ Total runtime so far: {total_str}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def get_summary(self):\n",
        "        \"\"\"Get timing summary\"\"\"\n",
        "        total = time.time() - self.total_start\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"â±ï¸  EXECUTION TIME SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        for section, elapsed in self.section_times.items():\n",
        "            if elapsed < 60:\n",
        "                time_str = f\"{elapsed:.1f}s\"\n",
        "            elif elapsed < 3600:\n",
        "                time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
        "            else:\n",
        "                time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
        "            print(f\"{section:<40} : {time_str}\")\n",
        "\n",
        "        if total < 60:\n",
        "            total_str = f\"{total:.1f}s\"\n",
        "        elif total < 3600:\n",
        "            total_str = f\"{total/60:.1f}m {total%60:.0f}s\"\n",
        "        else:\n",
        "            total_str = f\"{total/3600:.1f}h {(total%3600)/60:.0f}m\"\n",
        "\n",
        "        print(f\"{'='*40} : {'='*10}\")\n",
        "        print(f\"{'TOTAL EXECUTION TIME':<40} : {total_str}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "# Initialize global timer\n",
        "timer = SectionTimer()\n",
        "timer.start_section(\"SECTION 2: Environment & Imports\")\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# End timing for section 2\n",
        "timer.end_section(\"SECTION 2: Environment & Imports\")\n",
        "timer.start_section(\"SECTION 3: Configuration Setup\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYH7gi4mWNTj",
        "outputId": "e9588d35-05d1-49ac-f96a-8fe91010ce33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os, random, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModel, TrainingArguments, Trainer,\n",
        "    DataCollatorWithPadding, EarlyStoppingCallback, set_seed\n",
        ")\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    import transformers\n",
        "    transformers.set_seed(seed)  # ðŸ”§ RUN #9 FIX: Comprehensive transformers seed (sets all seeds including random, numpy, torch)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_all(42)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5jkDOC6cAXz"
      },
      "source": [
        "## SECTION 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bDchgs1WPUm",
        "outputId": "d5fe8487-9738-401c-a5c0-247ad42bd57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "ðŸŽ¯ mBERT TRAINING - RUN #9: R4 + BUG FIXES (CALIBRATION + SEED)\n",
            "================================================================================\n",
            "ðŸ“Š Run History: R1: 58.5% â†’ R2: 60.97% â†’ R3: 60.55% â†’ R4: 62.06% ðŸ† â†’ R5: 58.54% â†’ R6: 61.59% â†’ R7: 53.68% ðŸ’¥ â†’ R8: 61.99% âœ…\n",
            "   Run #8 Result: Reproduced R4 within 0.07% (confirmed R4 is stable!)\n",
            "   Run #9 Strategy: R4 HYPERPARAMETERS + FIX CALIBRATION BUG + ADD TRANSFORMERS SEED\n",
            "   Run #9 Fixes Applied:\n",
            "      1. âœ… transformers.set_seed(42) - eliminates 0-16% per-class variance\n",
            "      2. âœ… Robust calibration loading - checks multiple weight file formats\n",
            "   Run #9 Target: 64-67% Macro-F1 (R4 62.06% + calibration fix +2-5%)\n",
            "\n",
            "â±ï¸  Training Configuration (R4 EXACT - ZERO HYPERPARAMETER CHANGES!):\n",
            "   â”œâ”€ Epochs: 20 âœ… R4 EXACT\n",
            "   â”œâ”€ Batch Size: 16 (effective: 48) âœ… R4 EXACT\n",
            "   â”œâ”€ Learning Rate: 2.5e-05 âœ… R4 EXACT\n",
            "   â”œâ”€ Weight Decay: 0.03 âœ… RESTORED from 0.05 (R7's over-regularization)\n",
            "   â”œâ”€ Early Stop Patience: 8 âœ… RESTORED from 7 (R7 stopped too early)\n",
            "   â””â”€ Estimated Time: ~70 minutes (same as R4)\n",
            "\n",
            "ðŸ—ï¸  Architecture (R4 EXACT):\n",
            "   â”œâ”€ Head Hidden: 768 âœ… R4 EXACT\n",
            "   â”œâ”€ Head Layers: 3 âœ… R4 EXACT\n",
            "   â””â”€ Head Dropout: 0.25 âœ… RESTORED from 0.30 (R7's over-regularization)\n",
            "\n",
            "âš–ï¸  Critical Class Weights (R4 EXACT):\n",
            "   â”œâ”€ Negative:  1.1x âœ… R4 EXACT\n",
            "   â”œâ”€ Neutral:   1.8x âœ… R4 EXACT\n",
            "   â”œâ”€ Objective: 2.5x âœ… R4 EXACT\n",
            "   â””â”€ Max Weight Cap: 10.0 âœ… R4 EXACT\n",
            "\n",
            "ðŸ“Š Oversampling Strategy (R4 EXACT):\n",
            "   â”œâ”€ Joint Alpha: 0.7 âœ… R4 EXACT\n",
            "   â”œâ”€ Max Multiplier: 8.0x âœ… R4 EXACT\n",
            "   â”œâ”€ Objective Boost: 8.5x âœ… R4 EXACT\n",
            "   â””â”€ Neutral Boost: 3.5x âœ… R4 EXACT\n",
            "\n",
            "âŒ TASK-SPECIFIC GRADIENT CONTROL: DISABLED (R7 proved this is HARMFUL!):\n",
            "   â”œâ”€ Feature Enabled: False âœ… DISABLED\n",
            "   â”œâ”€ Global MAX_GRAD_NORM: 0.5 âœ… R4 EXACT\n",
            "   â””â”€ R7 Lesson: Task-specific gradients caused -7.91% regression (worst run ever)\n",
            "\n",
            "ðŸ”¥ Advanced Techniques (R4 EXACT - ALL PARAMETERS RESTORED):\n",
            "   â”œâ”€ Focal Loss Gamma (Sent/Pol): 2.5/3.5 âœ… R4 EXACT\n",
            "   â”œâ”€ Label Smoothing (Sent/Pol): 0.1/0.08 âœ… R4 EXACT\n",
            "   â”œâ”€ Task Weights (Sent/Pol): 1.0/1.4 âœ… R4 EXACT\n",
            "   â”œâ”€ R-Drop Alpha: 0.6 âœ… RESTORED from 0.7 (R7's over-regularization)\n",
            "   â””â”€ LLRD Decay: 0.9 âœ… R4 EXACT\n",
            "\n",
            "ðŸŽ¯ Run #8 Expected Results (Confirm R4 Reproducibility):\n",
            "   â”œâ”€ Overall Macro-F1: 62-63% (should match R4's 62.06%) â†’ Long-term Target: 75%\n",
            "   â”œâ”€ Purpose: Sanity check that R4 wasn't random luck\n",
            "   â”œâ”€ If successful: R4 is confirmed as hyperparameter tuning limit\n",
            "   â””â”€ Next step: Shift to architectural changes (XLM-RoBERTa, data aug, ensembles)\n",
            "\n",
            "ðŸ“ Output: ./runs_mbert_optimized\n",
            "================================================================================\n",
            "âœ… SECTION 3: Configuration Setup completed in 15.8m 49s\n",
            "ðŸ•’ Total runtime so far: 2.8h 45m\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸš€ Starting SECTION 4: Data Loading & Preprocessing...\n"
          ]
        }
      ],
      "source": [
        "# ðŸ¤– TRAINING ONLY: mBERT (bert-base-multilingual-cased)\\n\n",
        "# Expected: ~35-40 min, 60-65% macro-F1\\n\n",
        "\n",
        "# ===== Section 3 â€” Config (pooling + R-Drop + LLRD) =====\n",
        "\n",
        "data_path = '/content/adjudications_2025-10-22.csv'\n",
        "CSV_PATH = '/content/adjudications_2025-10-22.csv'\n",
        "\n",
        "\n",
        "TITLE_COL = \"Title\"\n",
        "TEXT_COL  = \"Comment\"\n",
        "SENT_COL  = \"Final Sentiment\"\n",
        "POL_COL   = \"Final Polarization\"\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    \"mbert\": {\"name\": \"bert-base-multilingual-cased\", \"desc\": \"mBERT (104 langs)\"},\n",
        "}\n",
        "MODELS_TO_RUN = [\"mbert\"]  # â† TRAINING ONLY mBERT\n",
        "OUT_DIR = \"./runs_mbert_optimized\"  # â† Separate output directory\n",
        "\n",
        "# ============================================================================\n",
        "# CORE TRAINING - RUN #10-13: SEED ENSEMBLE STRATEGY (4 SEEDS FOR +1-2% BOOST)\n",
        "# Run #9 Result: 62.74% Macro-F1 (âœ… NEW BEST! +0.68% over R4!)\n",
        "# Key Finding: Seed matters! Same hyperparameters, different seed â†’ +0.68% improvement\n",
        "# Run #10-13 Strategy: TRAIN 4 MODELS WITH DIFFERENT SEEDS (42, 43, 44, 45) + ENSEMBLE\n",
        "# Expected Outcome:\n",
        "#   - Each model: 62-63% Macro-F1 (consistent with R9)\n",
        "#   - Ensemble (average predictions): 64-65% Macro-F1 (+1-2% from ensemble diversity)\n",
        "# How to use:\n",
        "#   Run #10: Set SEED = 42 (already done in R9, baseline)\n",
        "#   Run #11: Set SEED = 43, re-run notebook\n",
        "#   Run #12: Set SEED = 44, re-run notebook\n",
        "#   Run #13: Set SEED = 45, re-run notebook\n",
        "#   Then ensemble predictions by averaging logits/probabilities\n",
        "# Expected training time per model: ~93 minutes (same as R9)\n",
        "# Total time for 4 models: ~6 hours\n",
        "# ============================================================================\n",
        "\n",
        "# ðŸŽ¯ SEED CONFIGURATION - CHANGE THIS FOR EACH RUN!\n",
        "# Run #10: SEED = 42 (baseline, already done in R9)\n",
        "# Run #11: SEED = 43\n",
        "# Run #12: SEED = 44\n",
        "# Run #13: SEED = 45\n",
        "SEED = 42  # ðŸ”¥ CHANGE THIS VALUE FOR EACH ENSEMBLE RUN (42, 43, 44, 45)\n",
        "\n",
        "# ============================================================================\n",
        "# CORE HYPERPARAMETERS - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Keep all R9/R4 hyperparameters unchanged - only vary the seed\n",
        "# ============================================================================\n",
        "MAX_LENGTH = 224\n",
        "EPOCHS = 20                 # âœ… R9 PROVEN (from R4)\n",
        "BATCH_SIZE = 16            # âœ… R9 PROVEN (from R4)\n",
        "LR = 2.5e-5               # âœ… R9 PROVEN (from R4)\n",
        "WEIGHT_DECAY = 0.03       # âœ… R9 PROVEN (from R4)\n",
        "WARMUP_RATIO = 0.20       # âœ… R9 PROVEN (from R4)\n",
        "EARLY_STOP_PATIENCE = 8   # âœ… R9 PROVEN (from R4)\n",
        "GRAD_ACCUM_STEPS = 3      # Effective batch: 48\n",
        "\n",
        "# Per-task loss - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "USE_FOCAL_SENTIMENT = True\n",
        "USE_FOCAL_POLARITY  = True\n",
        "FOCAL_GAMMA_SENTIMENT = 2.5   # âœ… R9 PROVEN\n",
        "FOCAL_GAMMA_POLARITY = 3.5    # âœ… R9 PROVEN\n",
        "LABEL_SMOOTH_SENTIMENT = 0.10 # âœ… R9 PROVEN\n",
        "LABEL_SMOOTH_POLARITY = 0.08  # âœ… R9 PROVEN\n",
        "\n",
        "# Task weights - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "TASK_LOSS_WEIGHTS = {\"sentiment\": 1.0, \"polarization\": 1.4}  # âœ… R9 PROVEN\n",
        "\n",
        "# Gradient control - RUN #10-13: R9 CONFIGURATION (task-specific disabled, proven harmful in R7!)\n",
        "USE_TASK_SPECIFIC_GRAD_NORM = False  # âœ… DISABLED (R7 proved this is HARMFUL!)\n",
        "MAX_GRAD_NORM = 0.5          # âœ… R9 PROVEN (from R4)\n",
        "USE_GRADIENT_CHECKPOINTING = True  # Memory efficiency\n",
        "\n",
        "# ============================================================================\n",
        "# AGGRESSIVE CLASS WEIGHTS - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Run #5 showed: 1.30 negative weight WORSENED recall (47.5%â†’40.3%)!\n",
        "# negative: Keep R9's 1.10 (1.30 backfired spectacularly)\n",
        "# neutral: Keep R9's 1.80 (working with oversampling)\n",
        "# objective: Keep R4's 2.50 (working well)\n",
        "# ============================================================================\n",
        "CLASS_WEIGHT_MULT = {\n",
        "    \"sentiment\": {\n",
        "        \"negative\": 1.10,    # âœ… RESTORE R4 from 1.30 (1.30 made recall WORSE!)\n",
        "        \"neutral\":  1.80,    # âœ… RESTORE R4 (working with oversampling)\n",
        "        \"positive\": 1.30     # âœ… RESTORE R4\n",
        "    },\n",
        "    \"polarization\": {\n",
        "        \"non_polarized\": 1.20,  # âœ… RESTORE R4\n",
        "        \"objective\":     2.50,  # âœ… RESTORE R4 (working well)\n",
        "        \"partisan\":      0.95   # âœ… RESTORE R4\n",
        "    }\n",
        "}\n",
        "\n",
        "# Cap maximum class weight to prevent instability\n",
        "MAX_CLASS_WEIGHT = 10.0  # ðŸ”¥ INCREASED (was 6.0) - Allow stronger weighting for weak classes\n",
        "\n",
        "# ============================================================================\n",
        "# SELECTIVE OVERSAMPLING - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Run #5 showed: 10x objective + 3x neutral = DISASTER (non-polarized -8.2%!)\n",
        "# Run #4's 8.5x/3.5x balance was OPTIMAL - proven stable in R9\n",
        "# Goal: Keep R9 configuration, only vary seed for ensemble\n",
        "# ============================================================================\n",
        "USE_OVERSAMPLING = True\n",
        "USE_JOINT_OVERSAMPLING = True\n",
        "USE_SMART_OVERSAMPLING = True\n",
        "JOINT_ALPHA = 0.70              # âœ… RESTORE R4 (was effective)\n",
        "JOINT_OVERSAMPLING_MAX_MULT = 8.0  # âœ… RESTORE R4\n",
        "OBJECTIVE_BOOST_MULT = 8.5      # âœ… RESTORE R4 from 10.0 (10x destroyed non-polarized!)\n",
        "NEUTRAL_BOOST_MULT = 3.5        # âœ… RESTORE R4 from 3.0 (3x removed critical signal!)\n",
        "\n",
        "# ============================================================================\n",
        "# ARCHITECTURE - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# Larger model can learn more complex multi-task representations\n",
        "# ============================================================================\n",
        "HEAD_HIDDEN = 768            # âœ… R9 PROVEN (from R4)\n",
        "HEAD_DROPOUT = 0.25          # âœ… R9 PROVEN (from R4)\n",
        "REP_POOLING = \"last4_mean\"   # âœ… R9 PROVEN (from R4)\n",
        "HEAD_LAYERS = 3              # âœ… R9 PROVEN (from R4)\n",
        "\n",
        "# ============================================================================\n",
        "# REGULARIZATION - RUN #10-13: R9 CONFIGURATION (PROVEN OPTIMAL)\n",
        "# ============================================================================\n",
        "USE_RDROP = True\n",
        "RDROP_ALPHA = 0.6           # âœ… R9 PROVEN (from R4)\n",
        "RDROP_WARMUP_EPOCHS = 2     # âœ… R9 PROVEN (from R4)\n",
        "\n",
        "# LLRD (layer-wise learning-rate decay) - RUN #10-13: R9 CONFIGURATION\n",
        "USE_LLRD = True\n",
        "LLRD_DECAY = 0.90            # âœ… R9 PROVEN (from R4)\n",
        "HEAD_LR_MULT = 3.0           # âœ… R9 PROVEN (from R4)\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION SUMMARY\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(f\"ðŸŽ¯ mBERT TRAINING - RUN #10-13: SEED ENSEMBLE STRATEGY (SEED = {SEED})\")\n",
        "print(\"=\"*80)\n",
        "print(f\"ðŸ“Š Run History: R1â†’R8: 58.5%-61.99% â†’ R9: 62.74% ðŸ† NEW BEST!\")\n",
        "print(f\"   Run #9 Result: 62.74% Macro-F1 (+0.68% vs R4, +0.75% vs R8)\")\n",
        "print(f\"   Key Finding: Seed matters! Same hyperparameters, different seed â†’ +0.68% improvement\")\n",
        "print(f\"   Run #10-13 Strategy: SEED ENSEMBLE (train 4 models with seeds 42, 43, 44, 45)\")\n",
        "print(f\"\")\n",
        "print(f\"ðŸŽ² Current Seed: {SEED}\")\n",
        "print(f\"   â”œâ”€ Run #10: SEED = 42 (baseline, already done in R9)\")\n",
        "print(f\"   â”œâ”€ Run #11: SEED = 43\")\n",
        "print(f\"   â”œâ”€ Run #12: SEED = 44\")\n",
        "print(f\"   â””â”€ Run #13: SEED = 45\")\n",
        "print(f\"\")\n",
        "print(f\"ðŸŽ¯ Expected Outcome:\")\n",
        "print(f\"   â”œâ”€ Each model: 62-63% Macro-F1 (consistent with R9)\")\n",
        "print(f\"   â””â”€ Ensemble (average predictions): 64-65% Macro-F1 (+1-2% from diversity)\")\n",
        "print(f\"\")\n",
        "print(f\"âœ… Bug Fixes Applied (from R9):\")\n",
        "print(f\"   â”œâ”€ transformers.set_seed({SEED}) - eliminates 0-17% per-class variance\")\n",
        "print(f\"   â””â”€ Robust calibration loading - checks multiple weight file formats\")\n",
        "print()\n",
        "print(f\"â±ï¸  Training Configuration (R9 PROVEN - ZERO CHANGES, ONLY SEED VARIES):\")\n",
        "print(f\"   â”œâ”€ Epochs: {EPOCHS} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Batch Size: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM_STEPS}) âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Learning Rate: {LR} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Weight Decay: {WEIGHT_DECAY} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Early Stop Patience: {EARLY_STOP_PATIENCE} âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ Estimated Time: ~93 minutes (same as R9)\")\n",
        "print()\n",
        "print(f\"ðŸ—ï¸  Architecture (R9 PROVEN):\")\n",
        "print(f\"   â”œâ”€ Head Hidden: {HEAD_HIDDEN} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Head Layers: {HEAD_LAYERS} âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ Head Dropout: {HEAD_DROPOUT} âœ… R9 PROVEN\")\n",
        "print()\n",
        "print(f\"âš–ï¸  Critical Class Weights (R9 PROVEN):\")\n",
        "print(f\"   â”œâ”€ Negative:  {CLASS_WEIGHT_MULT['sentiment']['negative']}x âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Neutral:   {CLASS_WEIGHT_MULT['sentiment']['neutral']}x âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Objective: {CLASS_WEIGHT_MULT['polarization']['objective']}x âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ Max Weight Cap: {MAX_CLASS_WEIGHT} âœ… R9 PROVEN\")\n",
        "print()\n",
        "print(f\"ðŸ“Š Oversampling Strategy (R9 PROVEN):\")\n",
        "print(f\"   â”œâ”€ Joint Alpha: {JOINT_ALPHA} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Max Multiplier: {JOINT_OVERSAMPLING_MAX_MULT}x âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Objective Boost: {OBJECTIVE_BOOST_MULT}x âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ Neutral Boost: {NEUTRAL_BOOST_MULT}x âœ… R9 PROVEN\")\n",
        "print()\n",
        "print(f\"âŒ TASK-SPECIFIC GRADIENT CONTROL: DISABLED (R7 proved this is HARMFUL!):\")\n",
        "print(f\"   â”œâ”€ Feature Enabled: {USE_TASK_SPECIFIC_GRAD_NORM} âœ… DISABLED\")\n",
        "print(f\"   â”œâ”€ Global MAX_GRAD_NORM: {MAX_GRAD_NORM} âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ R7 Lesson: Task-specific gradients caused -7.91% regression (worst run ever)\")\n",
        "print()\n",
        "print(f\"ðŸ”¥ Advanced Techniques (R9 PROVEN - ALL PARAMETERS FROM BEST RUN):\")\n",
        "print(f\"   â”œâ”€ Focal Loss Gamma (Sent/Pol): {FOCAL_GAMMA_SENTIMENT}/{FOCAL_GAMMA_POLARITY} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Label Smoothing (Sent/Pol): {LABEL_SMOOTH_SENTIMENT}/{LABEL_SMOOTH_POLARITY} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ Task Weights (Sent/Pol): {TASK_LOSS_WEIGHTS['sentiment']}/{TASK_LOSS_WEIGHTS['polarization']} âœ… R9 PROVEN\")\n",
        "print(f\"   â”œâ”€ R-Drop Alpha: {RDROP_ALPHA} âœ… R9 PROVEN\")\n",
        "print(f\"   â””â”€ LLRD Decay: {LLRD_DECAY} âœ… R9 PROVEN\")\n",
        "print()\n",
        "print(f\"ðŸŽ¯ Seed Ensemble Expected Results:\")\n",
        "print(f\"   â”œâ”€ Each Model: 62-63% Macro-F1 (consistent with R9's 62.74%)\")\n",
        "print(f\"   â”œâ”€ Ensemble (4 models): 64-65% Macro-F1 (+1-2% from diversity)\")\n",
        "print(f\"   â”œâ”€ Strategy: Train 4 seeds, average predictions for robustness\")\n",
        "print(f\"   â””â”€ Long-term Target: 75% Macro-F1 (still 10-11% gap to close)\")\n",
        "print()\n",
        "print(f\"ðŸ“ Output: {OUT_DIR}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ðŸŽ² Apply the configured seed (overrides the default seed_all(42) from Cell 6)\n",
        "seed_all(SEED)\n",
        "print(f\"âœ… Seed {SEED} applied successfully!\")\n",
        "print()\n",
        "\n",
        "# End timing for section 3\n",
        "timer.end_section(\"SECTION 3: Configuration Setup\")\n",
        "timer.start_section(\"SECTION 4: Data Loading & Preprocessing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKtHe-Ezb-id"
      },
      "source": [
        "## SECTION 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4fHWCOWW19j",
        "outputId": "4c8989a9-f438-406d-bb2d-0a60de4410ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment classes: {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
            "Polarization classes: {0: 'non_polarized', 1: 'objective', 2: 'partisan'}\n",
            "Train size: 6975 Val size: 1495 Test size: 1495\n",
            "Final sentiment class weights (capped): {'negative': 0.6187999248504639, 'neutral': 2.2331910133361816, 'positive': 3.1224172115325928}\n",
            "Final polarization class weights (capped): {'non_polarized': 1.436663269996643, 'objective': 10.0, 'partisan': 0.47725799679756165}\n",
            "Class weights were capped at maximum: 10.0\n",
            "âœ… SECTION 4: Data Loading & Preprocessing completed in 1.2m 11s\n",
            "ðŸ•’ Total runtime so far: 1.5m 33s\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸš€ Starting SECTION 5-9: Model Architecture & Training Setup...\n"
          ]
        }
      ],
      "source": [
        "# ===== Section 4 â€” Load & Prepare Data (updated for multipliers) =====\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "required = [TITLE_COL, TEXT_COL, SENT_COL, POL_COL]\n",
        "missing = [c for c in required if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing expected columns: {missing}. Found: {list(df.columns)}\")\n",
        "\n",
        "df = df.dropna(subset=[TITLE_COL, TEXT_COL, SENT_COL, POL_COL]).reset_index(drop=True)\n",
        "\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "sent_le = LabelEncoder().fit(df[SENT_COL])\n",
        "pol_le  = LabelEncoder().fit(df[POL_COL])\n",
        "\n",
        "df[\"sent_y\"] = sent_le.transform(df[SENT_COL])\n",
        "df[\"pol_y\"]  = pol_le.transform(df[POL_COL])\n",
        "\n",
        "num_sent_classes = len(sent_le.classes_)\n",
        "num_pol_classes  = len(pol_le.classes_)\n",
        "\n",
        "print(\"Sentiment classes:\", dict(enumerate(sent_le.classes_)))\n",
        "print(\"Polarization classes:\", dict(enumerate(pol_le.classes_)))\n",
        "\n",
        "# Splits (stratify by sentiment)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df[[TITLE_COL, TEXT_COL]].copy()\n",
        "y_sent = df[\"sent_y\"].values\n",
        "y_pol  = df[\"pol_y\"].values\n",
        "\n",
        "X_train, X_tmp, ysent_train, ysent_tmp, ypol_train, ypol_tmp = train_test_split(\n",
        "    X, y_sent, y_pol, test_size=0.3, random_state=42, stratify=y_sent\n",
        ")\n",
        "X_val, X_test, ysent_val, ysent_test, ypol_val, ypol_test = train_test_split(\n",
        "    X_tmp, ysent_tmp, ypol_tmp, test_size=0.5, random_state=42, stratify=ysent_tmp\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train), \"Val size:\", len(X_val), \"Test size:\", len(X_test))\n",
        "\n",
        "# Balanced class weights from TRAIN only\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np, json, os\n",
        "\n",
        "def safe_class_weights(y, n_classes):\n",
        "    classes = np.arange(n_classes)\n",
        "    counts = np.bincount(y, minlength=n_classes)\n",
        "    if np.any(counts == 0):\n",
        "        return np.ones(n_classes, dtype=np.float32)\n",
        "    return compute_class_weight(\"balanced\", classes=classes, y=y).astype(np.float32)\n",
        "\n",
        "sent_weights_np = safe_class_weights(ysent_train, num_sent_classes)\n",
        "pol_weights_np  = safe_class_weights(ypol_train,  num_pol_classes)\n",
        "\n",
        "# Apply user multipliers by class name\n",
        "sent_name_to_idx = {name: i for i, name in enumerate(sent_le.classes_)}\n",
        "pol_name_to_idx  = {name: i for i, name in enumerate(pol_le.classes_)}\n",
        "\n",
        "for cname, mult in CLASS_WEIGHT_MULT[\"sentiment\"].items():\n",
        "    if cname in sent_name_to_idx:\n",
        "        sent_weights_np[sent_name_to_idx[cname]] *= float(mult)\n",
        "\n",
        "for cname, mult in CLASS_WEIGHT_MULT[\"polarization\"].items():\n",
        "    if cname in pol_name_to_idx:\n",
        "        pol_weights_np[pol_name_to_idx[cname]] *= float(mult)\n",
        "\n",
        "# Apply class weight caps to prevent training instability\n",
        "sent_weights_np = np.clip(sent_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
        "pol_weights_np = np.clip(pol_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
        "\n",
        "print(\"Final sentiment class weights (capped):\", {sent_le.classes_[i]: float(w) for i, w in enumerate(sent_weights_np)})\n",
        "print(\"Final polarization class weights (capped):\", {pol_le.classes_[i]: float(w) for i, w in enumerate(pol_weights_np)})\n",
        "print(f\"Class weights were capped at maximum: {MAX_CLASS_WEIGHT}\")\n",
        "\n",
        "# Save label maps\n",
        "with open(os.path.join(OUT_DIR, \"label_map_sentiment.json\"), \"w\") as f:\n",
        "    json.dump({int(k): v for k, v in dict(enumerate(sent_le.classes_)).items()}, f, indent=2)\n",
        "with open(os.path.join(OUT_DIR, \"label_map_polarization.json\"), \"w\") as f:\n",
        "    json.dump({int(k): v for k, v in dict(enumerate(pol_le.classes_)).items()}, f, indent=2)\n",
        "\n",
        "# End timing for section 4\n",
        "timer.end_section(\"SECTION 4: Data Loading & Preprocessing\")\n",
        "timer.start_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0x3VSqAb8V9"
      },
      "source": [
        "## SECTION 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YJkJpNWiX5oT"
      },
      "outputs": [],
      "source": [
        "# ===== Section 5 â€” Dataset & Collator (proper text-pair encoding) =====\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TaglishDataset(Dataset):\n",
        "    def __init__(self, titles, texts, y_sent, y_pol, tokenizer, max_length=224):\n",
        "        self.titles = list(titles)\n",
        "        self.texts  = list(texts)\n",
        "        self.y_sent = np.array(y_sent)\n",
        "        self.y_pol  = np.array(y_pol)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "        # mBERT has token_type_ids; XLM-R/RemBERT don't, and that's fine.\n",
        "        self.use_token_type = \"token_type_ids\" in tokenizer.model_input_names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pass title as text, comment as text_pair so the tokenizer inserts the correct separators.\n",
        "        # We also bias truncation to the comment since titles are short.\n",
        "        enc = self.tok(\n",
        "            text=str(self.titles[idx]),\n",
        "            text_pair=str(self.texts[idx]),\n",
        "            truncation=\"only_second\",     # keep the title intact; trim the comment if needed\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=self.use_token_type,\n",
        "        )\n",
        "        item = {\n",
        "            \"input_ids\": enc[\"input_ids\"],\n",
        "            \"attention_mask\": enc[\"attention_mask\"],\n",
        "            \"sentiment_labels\": torch.tensor(self.y_sent[idx], dtype=torch.long),\n",
        "            \"polarization_labels\": torch.tensor(self.y_pol[idx], dtype=torch.long),\n",
        "        }\n",
        "        if self.use_token_type and \"token_type_ids\" in enc:\n",
        "            item[\"token_type_ids\"] = enc[\"token_type_ids\"]\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BpY_PhNb6M9"
      },
      "source": [
        "## SECTION 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aBI8mY8zX9bh"
      },
      "outputs": [],
      "source": [
        "# ===== Section 6 â€” Multi-Task Model (pooling + MLP heads) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel\n",
        "\n",
        "def mean_pooling(token_embeddings, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    summed = (token_embeddings * mask).sum(dim=1)\n",
        "    denom = mask.sum(dim=1).clamp(min=1e-9)\n",
        "    return summed / denom\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, base_model_name: str, num_sent: int, num_pol: int, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(base_model_name)\n",
        "        self.hidden = self.encoder.config.hidden_size\n",
        "\n",
        "        # Enhanced trunk with better architecture\n",
        "        self.trunk = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(self.hidden, HEAD_HIDDEN),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(HEAD_HIDDEN),\n",
        "            nn.Dropout(HEAD_DROPOUT),\n",
        "        )\n",
        "\n",
        "        # Enhanced multi-layer heads for better task-specific learning\n",
        "        if HEAD_LAYERS == 2:\n",
        "            self.head_sent = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_sent)\n",
        "            )\n",
        "            self.head_pol = nn.Sequential(\n",
        "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
        "                nn.GELU(),\n",
        "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
        "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
        "                nn.Linear(HEAD_HIDDEN // 2, num_pol)\n",
        "            )\n",
        "        else:\n",
        "            self.head_sent = nn.Linear(HEAD_HIDDEN, num_sent)\n",
        "            self.head_pol  = nn.Linear(HEAD_HIDDEN, num_pol)\n",
        "\n",
        "        # Enable gradient checkpointing if configured\n",
        "        if USE_GRADIENT_CHECKPOINTING:\n",
        "            self.encoder.gradient_checkpointing_enable()\n",
        "\n",
        "    def _pool(self, outputs, attention_mask):\n",
        "        # Flexible representation pooling\n",
        "        if REP_POOLING == \"pooler\" and hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
        "            return outputs.pooler_output\n",
        "        if REP_POOLING == \"cls\":\n",
        "            return outputs.last_hidden_state[:, 0]\n",
        "        # default: last4_mean\n",
        "        hs = outputs.hidden_states  # tuple of [layer0..last]\n",
        "        last4 = torch.stack(hs[-4:]).mean(dim=0)       # [B, T, H]\n",
        "        return mean_pooling(last4, attention_mask)     # [B, H]\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids=None,\n",
        "                attention_mask=None,\n",
        "                token_type_ids=None,\n",
        "                sentiment_labels=None,\n",
        "                polarization_labels=None):\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids if token_type_ids is not None else None,\n",
        "            output_hidden_states=(REP_POOLING != \"pooler\")  # needed for last4_mean/cls\n",
        "        )\n",
        "        pooled = self._pool(outputs, attention_mask)\n",
        "        z = self.trunk(pooled)\n",
        "        return {\"logits\": (self.head_sent(z), self.head_pol(z))}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9qlyf0bb4Fr"
      },
      "source": [
        "## SECTION 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sw_XB5CqX_uB"
      },
      "outputs": [],
      "source": [
        "# SECTION 7\n",
        "\n",
        "def compute_metrics_multi(eval_pred):\n",
        "    (sent_logits, pol_logits) = eval_pred.predictions\n",
        "    (y_sent, y_pol) = eval_pred.label_ids\n",
        "\n",
        "    ps = np.argmax(sent_logits, axis=1)\n",
        "    pp = np.argmax(pol_logits, axis=1)\n",
        "\n",
        "    # Macro metrics\n",
        "    sent_report = classification_report(y_sent, ps, output_dict=True, zero_division=0)\n",
        "    pol_report  = classification_report(y_pol,  pp, output_dict=True, zero_division=0)\n",
        "\n",
        "    sent_f1 = sent_report[\"macro avg\"][\"f1-score\"]\n",
        "    pol_f1  = pol_report[\"macro avg\"][\"f1-score\"]\n",
        "    macro_f1_avg = (sent_f1 + pol_f1) / 2.0\n",
        "\n",
        "    return {\n",
        "        \"sent_acc\": sent_report[\"accuracy\"],\n",
        "        \"sent_prec\": sent_report[\"macro avg\"][\"precision\"],\n",
        "        \"sent_rec\": sent_report[\"macro avg\"][\"recall\"],\n",
        "        \"sent_f1\": sent_f1,\n",
        "\n",
        "        \"pol_acc\": pol_report[\"accuracy\"],\n",
        "        \"pol_prec\": pol_report[\"macro avg\"][\"precision\"],\n",
        "        \"pol_rec\": pol_report[\"macro avg\"][\"recall\"],\n",
        "        \"pol_f1\": pol_f1,\n",
        "\n",
        "        \"macro_f1_avg\": macro_f1_avg\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SStXGWDuZXHq"
      },
      "source": [
        "## SECTION 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nr4WH-IAYRd3"
      },
      "outputs": [],
      "source": [
        "# ===== Section 8 â€” Custom Trainer (R-Drop + LLRD + safe prediction_step) =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import Trainer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=2.0, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, target):\n",
        "        logp = F.log_softmax(logits, dim=1)\n",
        "        p = torch.exp(logp)\n",
        "        loss = F.nll_loss((1 - p) ** self.gamma * logp, target, weight=self.weight, reduction=\"none\")\n",
        "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
        "\n",
        "def _sym_kl_with_logits(logits1, logits2):\n",
        "    p = F.log_softmax(logits1, dim=-1);  q = F.log_softmax(logits2, dim=-1)\n",
        "    p_exp, q_exp = p.exp(), q.exp()\n",
        "    return 0.5 * (F.kl_div(p, q_exp, reduction=\"batchmean\") + F.kl_div(q, p_exp, reduction=\"batchmean\"))\n",
        "\n",
        "class MultiTaskTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, task_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights or {}\n",
        "        self.task_weights  = task_weights or {\"sentiment\": 1.0, \"polarization\": 1.0}\n",
        "        self._custom_train_sampler = None\n",
        "\n",
        "    # ----- LLRD optimizer -----\n",
        "    def create_optimizer(self):\n",
        "        if self.optimizer is not None:\n",
        "            return self.optimizer\n",
        "        if not USE_LLRD:\n",
        "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "            return self.optimizer\n",
        "\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
        "        encoder = self.model.encoder\n",
        "        n_layers = getattr(encoder.config, \"num_hidden_layers\", 12)\n",
        "        # Try to access sequential layers\n",
        "        layers = getattr(getattr(encoder, \"encoder\", encoder), \"layer\", None)\n",
        "        if layers is None:\n",
        "            # Fallback: no LLRD if we can't find layers\n",
        "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "            return self.optimizer\n",
        "\n",
        "        param_groups = []\n",
        "\n",
        "        # Embeddings (lowest lr)\n",
        "        emb = getattr(encoder, \"embeddings\", None)\n",
        "        if emb is not None:\n",
        "            lr_emb = LR * (LLRD_DECAY ** n_layers)\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in emb.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_emb, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_emb, \"weight_decay\": 0.0})\n",
        "\n",
        "        # Encoder blocks (increasing LR toward the top)\n",
        "        for i in range(n_layers):\n",
        "            block = layers[i]\n",
        "            lr_i = LR * (LLRD_DECAY ** (n_layers - 1 - i))\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in block.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_i, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_i, \"weight_decay\": 0.0})\n",
        "\n",
        "        # Pooler (if any)\n",
        "        pooler = getattr(encoder, \"pooler\", None)\n",
        "        if pooler is not None:\n",
        "            decay, nodecay = [], []\n",
        "            for n, p in pooler.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "            if decay:   param_groups.append({\"params\": decay,   \"lr\": LR, \"weight_decay\": WEIGHT_DECAY})\n",
        "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": LR, \"weight_decay\": 0.0})\n",
        "\n",
        "        # Heads/trunk (highest LR)\n",
        "        head_lr = LR * HEAD_LR_MULT\n",
        "        head_modules = [self.model.trunk, self.model.head_sent, self.model.head_pol]\n",
        "        decay, nodecay = [], []\n",
        "        for m in head_modules:\n",
        "            for n, p in m.named_parameters():\n",
        "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
        "        if decay:   param_groups.append({\"params\": decay,   \"lr\": head_lr, \"weight_decay\": WEIGHT_DECAY})\n",
        "        if nodecay: param_groups.append({\"params\": nodecay, \"lr\": head_lr, \"weight_decay\": 0.0})\n",
        "\n",
        "        self.optimizer = AdamW(param_groups, lr=LR)  # lr here is ignored per-group\n",
        "        return self.optimizer\n",
        "\n",
        "    def set_train_sampler(self, sampler):\n",
        "        self._custom_train_sampler = sampler\n",
        "\n",
        "    def get_train_dataloader(self):\n",
        "        if self.train_dataset is None:\n",
        "            return None\n",
        "        if self._custom_train_sampler is not None:\n",
        "            return DataLoader(\n",
        "                self.train_dataset,\n",
        "                batch_size=self.args.train_batch_size,\n",
        "                sampler=self._custom_train_sampler,\n",
        "                collate_fn=self.data_collator,\n",
        "                drop_last=self.args.dataloader_drop_last,\n",
        "                num_workers=self.args.dataloader_num_workers,\n",
        "                pin_memory=self.args.dataloader_pin_memory,\n",
        "            )\n",
        "        return super().get_train_dataloader()\n",
        "\n",
        "    def _sent_loss_fn(self, weight, logits, target):\n",
        "        if USE_FOCAL_SENTIMENT:\n",
        "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_SENTIMENT)(logits, target)\n",
        "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_SENTIMENT))(logits, target)\n",
        "\n",
        "    def _pol_loss_fn(self, weight, logits, target):\n",
        "        if USE_FOCAL_POLARITY:\n",
        "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_POLARITY)(logits, target)\n",
        "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_POLARITY))(logits, target)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        y_sent = inputs.pop(\"sentiment_labels\")\n",
        "        y_pol  = inputs.pop(\"polarization_labels\")\n",
        "\n",
        "        # R-Drop with warmup: two forward passes with dropout\n",
        "        current_epoch = getattr(self.state, 'epoch', 0) if hasattr(self, 'state') else 0\n",
        "        use_rdrop_now = USE_RDROP and model.training and current_epoch >= RDROP_WARMUP_EPOCHS\n",
        "\n",
        "        if use_rdrop_now:\n",
        "            outputs1 = model(**inputs)\n",
        "            outputs2 = model(**inputs)\n",
        "            s1, p1 = outputs1[\"logits\"]\n",
        "            s2, p2 = outputs2[\"logits\"]\n",
        "\n",
        "            ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s1.device) if ws is not None else None\n",
        "            wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p1.device) if wp is not None else None\n",
        "\n",
        "            ce_s = 0.5 * (self._sent_loss_fn(ws, s1, y_sent) + self._sent_loss_fn(ws, s2, y_sent))\n",
        "            ce_p = 0.5 * (self._pol_loss_fn(wp,  p1, y_pol)  + self._pol_loss_fn(wp,  p2, y_pol))\n",
        "            kl_s = _sym_kl_with_logits(s1, s2)\n",
        "            kl_p = _sym_kl_with_logits(p1, p2)\n",
        "\n",
        "            w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
        "            w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
        "\n",
        "            # Gradual R-Drop alpha rampup for stability\n",
        "            rdrop_factor = min(1.0, (current_epoch - RDROP_WARMUP_EPOCHS + 1) / 2.0)\n",
        "            loss = w_s * ce_s + w_p * ce_p + (RDROP_ALPHA * rdrop_factor) * (kl_s + kl_p)\n",
        "            if return_outputs:\n",
        "                return loss, {\"logits\": (s1, p1)}\n",
        "            return loss\n",
        "\n",
        "        # Standard single forward\n",
        "        outputs = model(**inputs)\n",
        "        s, p = outputs[\"logits\"]\n",
        "\n",
        "        ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s.device) if ws is not None else None\n",
        "        wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p.device) if wp is not None else None\n",
        "\n",
        "        loss_s = self._sent_loss_fn(ws, s, y_sent)\n",
        "        loss_p = self._pol_loss_fn(wp, p, y_pol)\n",
        "\n",
        "        w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
        "        w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
        "        loss = w_s * loss_s + w_p * loss_p\n",
        "\n",
        "        if return_outputs:\n",
        "            outputs = dict(outputs); outputs[\"labels\"] = (y_sent, y_pol)\n",
        "            return loss, outputs\n",
        "        return loss\n",
        "\n",
        "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
        "        # Safe for inference (no labels provided)\n",
        "        y_sent = inputs.get(\"sentiment_labels\", None)\n",
        "        y_pol  = inputs.get(\"polarization_labels\", None)\n",
        "\n",
        "        model_inputs = {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"]}\n",
        "        if \"token_type_ids\" in inputs:\n",
        "            model_inputs[\"token_type_ids\"] = inputs[\"token_type_ids\"]\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**model_inputs)\n",
        "            s, p = outputs[\"logits\"]\n",
        "\n",
        "        loss = None\n",
        "        logits = (s.detach(), p.detach())\n",
        "        labels = (y_sent, y_pol) if isinstance(y_sent, torch.Tensor) and isinstance(y_pol, torch.Tensor) else None\n",
        "        return (loss, logits, labels)\n",
        "\n",
        "# ðŸ”´ RUN #8: Custom training_step REMOVED (R7 proved it's harmful!)\n",
        "# Task-specific gradient control caused -7.91% regression (worst run ever)\n",
        "# Restoring default Trainer behavior for gradient clipping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mcQwt92ZfGI"
      },
      "source": [
        "## SECTION 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV78nGSQYV3a",
        "outputId": "c816749b-8a2f-43db-f0e7-d3d1d4217f73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… SECTION 5-9: Model Architecture & Training Setup completed in 53.2s\n",
            "ðŸ•’ Total runtime so far: 2.8h 46m\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ===== Section 9 â€” Train/Evaluate One Model (with grad accumulation) =====\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "import math, json, numpy as np, pandas as pd, os\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "from collections import Counter\n",
        "\n",
        "def train_eval_one_model(model_key: str,\n",
        "                         X_tr: pd.DataFrame, X_v: pd.DataFrame, X_te: pd.DataFrame,\n",
        "                         ysent_tr: np.ndarray, ysent_v: np.ndarray, ysent_te: np.ndarray,\n",
        "                         ypol_tr: np.ndarray,  ypol_v: np.ndarray,  ypol_te: np.ndarray,\n",
        "                         sent_w_np: np.ndarray, pol_w_np: np.ndarray):\n",
        "    base_name = MODEL_CONFIGS[model_key][\"name\"]\n",
        "    run_dir = os.path.join(OUT_DIR, f\"{model_key}\")\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "\n",
        "    tr_titles, tr_texts = X_tr[TITLE_COL].values, X_tr[TEXT_COL].values\n",
        "    v_titles,  v_texts  = X_v[TITLE_COL].values, X_v[TEXT_COL].values\n",
        "    te_titles, te_texts = X_te[TITLE_COL].values, X_te[TEXT_COL].values\n",
        "\n",
        "    train_ds = TaglishDataset(tr_titles, tr_texts, ysent_tr, ypol_tr, tokenizer, max_length=MAX_LENGTH)\n",
        "    val_ds   = TaglishDataset(v_titles,  v_texts,  ysent_v,  ypol_v,  tokenizer, max_length=MAX_LENGTH)\n",
        "    test_ds  = TaglishDataset(te_titles, te_texts, ysent_te, ypol_te, tokenizer, max_length=MAX_LENGTH)\n",
        "\n",
        "    model = MultiTaskModel(base_name, num_sent_classes, num_pol_classes).to(device)\n",
        "\n",
        "    sent_w = torch.tensor(sent_w_np, dtype=torch.float32)\n",
        "    pol_w  = torch.tensor(pol_w_np,  dtype=torch.float32)\n",
        "\n",
        "    args = make_training_args_compat(\n",
        "        output_dir=run_dir,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        learning_rate=LR,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        warmup_ratio=WARMUP_RATIO,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"macro_f1_avg\",\n",
        "        greater_is_better=True,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        logging_dir=os.path.join(run_dir, \"logs\"),\n",
        "        logging_steps=25,                    # More frequent logging\n",
        "        logging_first_step=True,             # Log first step for debugging\n",
        "        save_steps=500,                      # Save checkpoints more often\n",
        "        eval_steps=None,                     # Eval at end of each epoch\n",
        "        report_to=\"none\",\n",
        "        seed=42,\n",
        "        remove_unused_columns=False,\n",
        "        eval_accumulation_steps=1,\n",
        "        gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
        "        dataloader_pin_memory=True,          # Performance optimization\n",
        "        max_grad_norm=MAX_GRAD_NORM,         # âœ… R4 EXACT (global gradient clipping restored)\n",
        "        label_smoothing_factor=0.0,          # We handle this in loss functions\n",
        "        save_total_limit=5,                  # âœ… R4 EXACT\n",
        "        prediction_loss_only=False           # Log all metrics\n",
        "    )\n",
        "\n",
        "    callbacks = get_early_stopping_callbacks(EARLY_STOP_PATIENCE)\n",
        "\n",
        "    trainer = MultiTaskTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        data_collator=collator,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics_multi,\n",
        "        callbacks=callbacks,\n",
        "        class_weights={\"sentiment\": sent_w, \"polarization\": pol_w},\n",
        "        task_weights=TASK_LOSS_WEIGHTS\n",
        "    )\n",
        "\n",
        "    # ----- ENHANCED JOINT oversampling with objective boost -----\n",
        "    if USE_OVERSAMPLING and USE_JOINT_OVERSAMPLING:\n",
        "        pair_counts = Counter(zip(ysent_tr.tolist(), ypol_tr.tolist()))\n",
        "        counts = np.array(list(pair_counts.values()), dtype=np.float32)\n",
        "        med = float(np.median(counts)) if len(counts) else 1.0\n",
        "\n",
        "        # Find objective class index (polarization)\n",
        "        obj_idx = np.where(pol_le.classes_ == \"objective\")[0][0] if \"objective\" in pol_le.classes_ else 1\n",
        "\n",
        "        # ðŸ”¥ NEW: Find neutral class index (sentiment)\n",
        "        neutral_idx = np.where(sent_le.classes_ == \"neutral\")[0][0] if \"neutral\" in sent_le.classes_ else 1\n",
        "\n",
        "        def inv_mult(c):\n",
        "            if c <= 0: return JOINT_OVERSAMPLING_MAX_MULT\n",
        "            return float(np.clip(med / float(c), 1.0, JOINT_OVERSAMPLING_MAX_MULT))\n",
        "\n",
        "        inv_by_pair = {k: inv_mult(v) for k, v in pair_counts.items()}\n",
        "        sample_weights = []\n",
        "\n",
        "        for ys, yp in zip(ysent_tr, ypol_tr):\n",
        "            inv = inv_by_pair.get((int(ys), int(yp)), 1.0)\n",
        "            w = (1.0 - JOINT_ALPHA) * 1.0 + JOINT_ALPHA * inv\n",
        "\n",
        "            # Smart oversampling: extra boost for objective class (polarization)\n",
        "            if USE_SMART_OVERSAMPLING and int(yp) == obj_idx:\n",
        "                w *= OBJECTIVE_BOOST_MULT\n",
        "\n",
        "            # ðŸ”¥ NEW: Also boost neutral class (sentiment) - Fixes 49% F1!\n",
        "            if USE_SMART_OVERSAMPLING and int(ys) == neutral_idx:\n",
        "                w *= NEUTRAL_BOOST_MULT\n",
        "\n",
        "            sample_weights.append(w)\n",
        "\n",
        "        obj_boost_count = sum(1 for i, yp in enumerate(ypol_tr) if int(yp) == obj_idx and sample_weights[i] > 2.0)\n",
        "        neutral_boost_count = sum(1 for i, ys in enumerate(ysent_tr) if int(ys) == neutral_idx and sample_weights[i] > 2.0)\n",
        "        print(f\"ðŸ”¥ Enhanced Oversampling: min={min(sample_weights):.2f}, max={max(sample_weights):.2f}\")\n",
        "        print(f\"   â”œâ”€ Objective boosted samples: {obj_boost_count} (target: weak class at 40% F1)\")\n",
        "        print(f\"   â””â”€ Neutral boosted samples: {neutral_boost_count} (target: weak class at 49% F1)\")\n",
        "        trainer.set_train_sampler(WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True))\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    # Test\n",
        "    test_out = trainer.predict(test_ds)\n",
        "    metrics = {f\"test_{k}\": float(v) for k, v in test_out.metrics.items()}\n",
        "    trainer.save_model(run_dir)\n",
        "    tokenizer.save_pretrained(run_dir)\n",
        "    with open(os.path.join(run_dir, \"metrics_test.json\"), \"w\") as f:\n",
        "        json.dump(metrics, f, indent=2)\n",
        "\n",
        "    sent_logits, pol_logits = test_out.predictions\n",
        "    ysent_pred = np.argmax(sent_logits, axis=1)\n",
        "    ypol_pred  = np.argmax(pol_logits,  axis=1)\n",
        "\n",
        "    cm_sent = confusion_matrix(ysent_te, ysent_pred, labels=list(range(num_sent_classes)))\n",
        "    cm_pol  = confusion_matrix(ypol_te,  ypol_pred,  labels=list(range(num_pol_classes)))\n",
        "    np.save(os.path.join(run_dir, \"cm_sent.npy\"), cm_sent)\n",
        "    np.save(os.path.join(run_dir, \"cm_pol.npy\"),  cm_pol)\n",
        "\n",
        "    def plot_cm(cm, labels, title, path_png):\n",
        "        fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "        im = ax.imshow(cm, interpolation=\"nearest\")\n",
        "        ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "        ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n",
        "        ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "        fig.colorbar(im, ax=ax, fraction=0.046); plt.tight_layout(); plt.savefig(path_png, dpi=160); plt.close(fig)\n",
        "\n",
        "    plot_cm(cm_sent, sent_le.classes_, \"Sentiment Confusion\", os.path.join(run_dir, \"cm_sent.png\"))\n",
        "    plot_cm(cm_pol,  pol_le.classes_,  \"Polarization Confusion\", os.path.join(run_dir, \"cm_pol.png\"))\n",
        "\n",
        "    rep_sent = classification_report(ysent_te, ysent_pred, target_names=sent_le.classes_, digits=4, zero_division=0)\n",
        "    rep_pol  = classification_report(ypol_te,  ypol_pred,  target_names=pol_le.classes_,  digits=4, zero_division=0)\n",
        "    with open(os.path.join(run_dir, \"report_sentiment.txt\"), \"w\") as f: f.write(rep_sent)\n",
        "    with open(os.path.join(run_dir, \"report_polarization.txt\"), \"w\") as f: f.write(rep_pol)\n",
        "\n",
        "    return {\"model_key\": model_key, \"base_name\": base_name, **metrics}, (ysent_pred, ypol_pred)\n",
        "\n",
        "# End timing for architecture setup\n",
        "timer.end_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKEIn9Gebyw-"
      },
      "source": [
        "## SECTION 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "24dStZjrYaW7",
        "outputId": "449cef09-a564-4ca1-d560-ffcf99c8a2df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸš€ Starting SECTION 10: Model Training Execution...\n",
            "\n",
            "=== Running mbert -> bert-base-multilingual-cased ===\n",
            "ðŸ”¥ Enhanced Oversampling: min=1.00, max=68.28\n",
            "   â”œâ”€ Objective boosted samples: 405 (target: weak class at 40% F1)\n",
            "   â””â”€ Neutral boosted samples: 1874 (target: weak class at 49% F1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2900' max='2900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2900/2900 1:32:23, Epoch 19/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Sent Acc</th>\n",
              "      <th>Sent Prec</th>\n",
              "      <th>Sent Rec</th>\n",
              "      <th>Sent F1</th>\n",
              "      <th>Pol Acc</th>\n",
              "      <th>Pol Prec</th>\n",
              "      <th>Pol Rec</th>\n",
              "      <th>Pol F1</th>\n",
              "      <th>Macro F1 Avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.978500</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.286288</td>\n",
              "      <td>0.295020</td>\n",
              "      <td>0.384575</td>\n",
              "      <td>0.235865</td>\n",
              "      <td>0.063545</td>\n",
              "      <td>0.087542</td>\n",
              "      <td>0.335025</td>\n",
              "      <td>0.042591</td>\n",
              "      <td>0.139228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.686600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.408027</td>\n",
              "      <td>0.568599</td>\n",
              "      <td>0.535749</td>\n",
              "      <td>0.429385</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.504489</td>\n",
              "      <td>0.380462</td>\n",
              "      <td>0.128457</td>\n",
              "      <td>0.278921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.348100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.436789</td>\n",
              "      <td>0.609988</td>\n",
              "      <td>0.556253</td>\n",
              "      <td>0.469144</td>\n",
              "      <td>0.408027</td>\n",
              "      <td>0.492556</td>\n",
              "      <td>0.585776</td>\n",
              "      <td>0.389987</td>\n",
              "      <td>0.429566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.201300</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.440134</td>\n",
              "      <td>0.639412</td>\n",
              "      <td>0.573974</td>\n",
              "      <td>0.484345</td>\n",
              "      <td>0.525084</td>\n",
              "      <td>0.517824</td>\n",
              "      <td>0.618648</td>\n",
              "      <td>0.491264</td>\n",
              "      <td>0.487804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.162400</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.456856</td>\n",
              "      <td>0.652119</td>\n",
              "      <td>0.588316</td>\n",
              "      <td>0.506130</td>\n",
              "      <td>0.690301</td>\n",
              "      <td>0.572208</td>\n",
              "      <td>0.625466</td>\n",
              "      <td>0.587083</td>\n",
              "      <td>0.546606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.147900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.521070</td>\n",
              "      <td>0.636830</td>\n",
              "      <td>0.637712</td>\n",
              "      <td>0.559552</td>\n",
              "      <td>0.520401</td>\n",
              "      <td>0.539794</td>\n",
              "      <td>0.543464</td>\n",
              "      <td>0.469669</td>\n",
              "      <td>0.514610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.147900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.497659</td>\n",
              "      <td>0.652758</td>\n",
              "      <td>0.619451</td>\n",
              "      <td>0.540052</td>\n",
              "      <td>0.634783</td>\n",
              "      <td>0.566497</td>\n",
              "      <td>0.619309</td>\n",
              "      <td>0.562384</td>\n",
              "      <td>0.551218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.529766</td>\n",
              "      <td>0.593383</td>\n",
              "      <td>0.642339</td>\n",
              "      <td>0.553542</td>\n",
              "      <td>0.686288</td>\n",
              "      <td>0.583226</td>\n",
              "      <td>0.600030</td>\n",
              "      <td>0.580209</td>\n",
              "      <td>0.566876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.089000</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.589967</td>\n",
              "      <td>0.655455</td>\n",
              "      <td>0.645144</td>\n",
              "      <td>0.614435</td>\n",
              "      <td>0.723077</td>\n",
              "      <td>0.588657</td>\n",
              "      <td>0.604466</td>\n",
              "      <td>0.594788</td>\n",
              "      <td>0.604612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.555184</td>\n",
              "      <td>0.651734</td>\n",
              "      <td>0.647886</td>\n",
              "      <td>0.592412</td>\n",
              "      <td>0.639465</td>\n",
              "      <td>0.578209</td>\n",
              "      <td>0.583451</td>\n",
              "      <td>0.549948</td>\n",
              "      <td>0.571180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.076600</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.579933</td>\n",
              "      <td>0.630295</td>\n",
              "      <td>0.649655</td>\n",
              "      <td>0.605247</td>\n",
              "      <td>0.655518</td>\n",
              "      <td>0.575054</td>\n",
              "      <td>0.585042</td>\n",
              "      <td>0.554509</td>\n",
              "      <td>0.579878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.529097</td>\n",
              "      <td>0.645829</td>\n",
              "      <td>0.629761</td>\n",
              "      <td>0.569192</td>\n",
              "      <td>0.570569</td>\n",
              "      <td>0.580890</td>\n",
              "      <td>0.542429</td>\n",
              "      <td>0.491855</td>\n",
              "      <td>0.530523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.083900</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.656167</td>\n",
              "      <td>0.656833</td>\n",
              "      <td>0.624036</td>\n",
              "      <td>0.661538</td>\n",
              "      <td>0.576098</td>\n",
              "      <td>0.573458</td>\n",
              "      <td>0.549717</td>\n",
              "      <td>0.586877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.072700</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.581940</td>\n",
              "      <td>0.650051</td>\n",
              "      <td>0.652189</td>\n",
              "      <td>0.611749</td>\n",
              "      <td>0.664883</td>\n",
              "      <td>0.577950</td>\n",
              "      <td>0.573565</td>\n",
              "      <td>0.551861</td>\n",
              "      <td>0.581805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… SECTION 10: Model Training Execution completed in 1.6h 33m\n",
            "ðŸ•’ Total runtime so far: 4.3h 19m\n",
            "------------------------------------------------------------\n",
            "\n",
            "ðŸš€ Starting SECTION 11+: Evaluation & Calibration...\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mbert\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bert-base-multilingual-cased\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6120401337792643,\n        \"max\": 0.6120401337792643,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6120401337792643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6617714807053042,\n        \"max\": 0.6617714807053042,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6617714807053042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6577629604145566,\n        \"max\": 0.6577629604145566,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6577629604145566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6294147190116138,\n        \"max\": 0.6294147190116138,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6294147190116138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7337792642140468,\n        \"max\": 0.7337792642140468,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7337792642140468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6201360414233713,\n        \"max\": 0.6201360414233713,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6201360414233713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6335426788324051,\n        \"max\": 0.6335426788324051,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6335426788324051\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6254070004070004,\n        \"max\": 0.6254070004070004,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6254070004070004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_macro_f1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6274108597093071,\n        \"max\": 0.6274108597093071,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6274108597093071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.4729,\n        \"max\": 4.4729,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.4729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 334.234,\n        \"max\": 334.234,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          334.234\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 21.015,\n        \"max\": 21.015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          21.015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-be33689a-1e83-4fd6-b904-dd10287dec05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_key</th>\n",
              "      <th>base_name</th>\n",
              "      <th>test_test_sent_acc</th>\n",
              "      <th>test_test_sent_prec</th>\n",
              "      <th>test_test_sent_rec</th>\n",
              "      <th>test_test_sent_f1</th>\n",
              "      <th>test_test_pol_acc</th>\n",
              "      <th>test_test_pol_prec</th>\n",
              "      <th>test_test_pol_rec</th>\n",
              "      <th>test_test_pol_f1</th>\n",
              "      <th>test_test_macro_f1_avg</th>\n",
              "      <th>test_test_runtime</th>\n",
              "      <th>test_test_samples_per_second</th>\n",
              "      <th>test_test_steps_per_second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mbert</td>\n",
              "      <td>bert-base-multilingual-cased</td>\n",
              "      <td>0.61204</td>\n",
              "      <td>0.661771</td>\n",
              "      <td>0.657763</td>\n",
              "      <td>0.629415</td>\n",
              "      <td>0.733779</td>\n",
              "      <td>0.620136</td>\n",
              "      <td>0.633543</td>\n",
              "      <td>0.625407</td>\n",
              "      <td>0.627411</td>\n",
              "      <td>4.4729</td>\n",
              "      <td>334.234</td>\n",
              "      <td>21.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be33689a-1e83-4fd6-b904-dd10287dec05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be33689a-1e83-4fd6-b904-dd10287dec05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be33689a-1e83-4fd6-b904-dd10287dec05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_06194ec4-0541-4234-95e5-3f648d2814a0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06194ec4-0541-4234-95e5-3f648d2814a0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  model_key                     base_name  test_test_sent_acc  \\\n",
              "0     mbert  bert-base-multilingual-cased             0.61204   \n",
              "\n",
              "   test_test_sent_prec  test_test_sent_rec  test_test_sent_f1  \\\n",
              "0             0.661771            0.657763           0.629415   \n",
              "\n",
              "   test_test_pol_acc  test_test_pol_prec  test_test_pol_rec  test_test_pol_f1  \\\n",
              "0           0.733779            0.620136           0.633543          0.625407   \n",
              "\n",
              "   test_test_macro_f1_avg  test_test_runtime  test_test_samples_per_second  \\\n",
              "0                0.627411             4.4729                       334.234   \n",
              "\n",
              "   test_test_steps_per_second  \n",
              "0                      21.015  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SECTION 10\n",
        "\n",
        "timer.start_section(\"SECTION 10: Model Training Execution\")\n",
        "\n",
        "results = []\n",
        "pred_cache = {}\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\n=== Running {key} -> {MODEL_CONFIGS[key]['name']} ===\")\n",
        "    row, preds = train_eval_one_model(\n",
        "        key,\n",
        "        X_train, X_val, X_test,\n",
        "        ysent_train, ysent_val, ysent_test,\n",
        "        ypol_train,  ypol_val,  ypol_test,\n",
        "        sent_weights_np, pol_weights_np\n",
        "    )\n",
        "    results.append(row)\n",
        "    pred_cache[key] = preds\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(os.path.join(OUT_DIR, \"summary_results.csv\"), index=False)\n",
        "\n",
        "# End timing for training execution\n",
        "timer.end_section(\"SECTION 10: Model Training Execution\")\n",
        "timer.start_section(\"SECTION 11+: Evaluation & Calibration\")\n",
        "\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSS37GWDbBw2"
      },
      "source": [
        "### SECTION 10A\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QlNuczl4bDPJ"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SECTION 10A â€” VERIFY ARTIFACTS & RESOLVE TOKENIZER + WEIGHTS (v2)\n",
        "# Builds maps for: tokenizer_dir (usually run root) and weights_dir (checkpoint or run root).\n",
        "# Run AFTER Section 10 (training) and BEFORE 11B/11C.\n",
        "# ============================================================================\n",
        "\n",
        "import os, re, json\n",
        "from typing import Optional, Dict\n",
        "\n",
        "def _has_weights(path: str) -> bool:\n",
        "    return os.path.isfile(os.path.join(path, \"pytorch_model.bin\")) or os.path.isfile(os.path.join(path, \"model.safetensors\"))\n",
        "\n",
        "def _has_tokenizer(path: str) -> bool:\n",
        "    # Minimal tokenizer files\n",
        "    return (\n",
        "        os.path.isfile(os.path.join(path, \"tokenizer.json\")) or\n",
        "        os.path.isfile(os.path.join(path, \"vocab.txt\")) or\n",
        "        os.path.isfile(os.path.join(path, \"spiece.model\"))\n",
        "    )\n",
        "\n",
        "def _list_checkpoints(run_dir: str):\n",
        "    if not os.path.isdir(run_dir): return []\n",
        "    chks = []\n",
        "    for name in os.listdir(run_dir):\n",
        "        p = os.path.join(run_dir, name)\n",
        "        if os.path.isdir(p) and re.match(r\"^checkpoint-\\d+$\", name):\n",
        "            chks.append(p)\n",
        "    # sort by gl\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JZdHWRfbvzP"
      },
      "source": [
        "## SECTION 11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "t1I1V0MJbyH2",
        "outputId": "59865083-a89d-4873-c994-3f7a7e73d42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Detailed breakdowns for mbert ===\n",
            "\n",
            "Sentiment â€” per class (precision/recall/F1/support):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sent_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2214806318509924,\n        \"min\": 0.41310160427807485,\n        \"max\": 0.8378378378378378,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8378378378378378,\n          0.41310160427807485,\n          0.734375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12410096629228276,\n        \"min\": 0.5248306997742663,\n        \"max\": 0.770573566084788,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5248306997742663,\n          0.770573566084788,\n          0.6778846153846154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08470725350286676,\n        \"min\": 0.5378590078328982,\n        \"max\": 0.705,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6453851492019431,\n          0.5378590078328982,\n          0.705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349,\n        \"min\": 208,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          401,\n          208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sent_per_class"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c9779ed9-c963-4681-9dd2-4b5772658a3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>0.837838</td>\n",
              "      <td>0.524831</td>\n",
              "      <td>0.645385</td>\n",
              "      <td>886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>0.413102</td>\n",
              "      <td>0.770574</td>\n",
              "      <td>0.537859</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>0.734375</td>\n",
              "      <td>0.677885</td>\n",
              "      <td>0.705000</td>\n",
              "      <td>208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9779ed9-c963-4681-9dd2-4b5772658a3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9779ed9-c963-4681-9dd2-4b5772658a3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9779ed9-c963-4681-9dd2-4b5772658a3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9eba42ce-0f25-4950-8e57-e82e728840c4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9eba42ce-0f25-4950-8e57-e82e728840c4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9eba42ce-0f25-4950-8e57-e82e728840c4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_57b97926-35cd-4622-be1d-b9550fc0cc79\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_per_class')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_57b97926-35cd-4622-be1d-b9550fc0cc79 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sent_per_class');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      class  precision    recall        f1  support\n",
              "0  negative   0.837838  0.524831  0.645385      886\n",
              "1   neutral   0.413102  0.770574  0.537859      401\n",
              "2  positive   0.734375  0.677885  0.705000      208"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Polarization â€” per class (precision/recall/F1/support):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pol_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"non_polarized\",\n          \"objective\",\n          \"partisan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2112133485649948,\n        \"min\": 0.42391304347826086,\n        \"max\": 0.843680709534368,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.592814371257485,\n          0.42391304347826086,\n          0.843680709534368\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18070002615025405,\n        \"min\": 0.43333333333333335,\n        \"max\": 0.7845360824742268,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6827586206896552,\n          0.43333333333333335,\n          0.7845360824742268\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19239672322632426,\n        \"min\": 0.42857142857142855,\n        \"max\": 0.813034188034188,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6346153846153846,\n          0.42857142857142855,\n          0.813034188034188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 443,\n        \"min\": 90,\n        \"max\": 970,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          435,\n          90,\n          970\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pol_per_class"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1792c857-ee8f-49e5-a14b-27604023c67e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>non_polarized</td>\n",
              "      <td>0.592814</td>\n",
              "      <td>0.682759</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>objective</td>\n",
              "      <td>0.423913</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>partisan</td>\n",
              "      <td>0.843681</td>\n",
              "      <td>0.784536</td>\n",
              "      <td>0.813034</td>\n",
              "      <td>970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1792c857-ee8f-49e5-a14b-27604023c67e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1792c857-ee8f-49e5-a14b-27604023c67e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1792c857-ee8f-49e5-a14b-27604023c67e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a499e9e0-028e-4cb5-9490-55e998a76b0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a499e9e0-028e-4cb5-9490-55e998a76b0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a499e9e0-028e-4cb5-9490-55e998a76b0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_39ecc12a-a296-4c7f-8f0b-b568878774a1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_per_class')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_39ecc12a-a296-4c7f-8f0b-b568878774a1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pol_per_class');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           class  precision    recall        f1  support\n",
              "0  non_polarized   0.592814  0.682759  0.634615      435\n",
              "1      objective   0.423913  0.433333  0.428571       90\n",
              "2       partisan   0.843681  0.784536  0.813034      970"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Polarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pol_given_sent\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 349,\n        \"min\": 208,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          401,\n          208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08034993244154987,\n        \"min\": 0.628428927680798,\n        \"max\": 0.7889390519187359,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7889390519187359,\n          0.628428927680798,\n          0.7019230769230769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004611803572460783,\n        \"min\": 0.5889846743295019,\n        \"max\": 0.5976977170124531,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5907204396776259,\n          0.5976977170124531,\n          0.5889846743295019\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_non_polarized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05614314142015687,\n        \"min\": 0.5760869565217391,\n        \"max\": 0.675,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5760869565217391,\n          0.6715686274509803,\n          0.675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_objective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10676556770709202,\n        \"min\": 0.32786885245901637,\n        \"max\": 0.5154639175257731,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.32786885245901637,\n          0.5154639175257731,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_partisan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13165824613782834,\n        \"min\": 0.6060606060606061,\n        \"max\": 0.8682055100521221,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8682055100521221,\n          0.6060606060606061,\n          0.7586206896551724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pol_given_sent"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-46ac8d4d-8220-4421-b98f-680187195667\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice</th>\n",
              "      <th>support</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>f1_non_polarized</th>\n",
              "      <th>f1_objective</th>\n",
              "      <th>f1_partisan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>886</td>\n",
              "      <td>0.788939</td>\n",
              "      <td>0.590720</td>\n",
              "      <td>0.576087</td>\n",
              "      <td>0.327869</td>\n",
              "      <td>0.868206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>401</td>\n",
              "      <td>0.628429</td>\n",
              "      <td>0.597698</td>\n",
              "      <td>0.671569</td>\n",
              "      <td>0.515464</td>\n",
              "      <td>0.606061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>208</td>\n",
              "      <td>0.701923</td>\n",
              "      <td>0.588985</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.758621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46ac8d4d-8220-4421-b98f-680187195667')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46ac8d4d-8220-4421-b98f-680187195667 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46ac8d4d-8220-4421-b98f-680187195667');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-58e5ced8-df65-4423-ace7-f1e10d73071d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58e5ced8-df65-4423-ace7-f1e10d73071d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-58e5ced8-df65-4423-ace7-f1e10d73071d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1b1dc9b5-b743-461e-856c-27af901331a5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_given_sent')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1b1dc9b5-b743-461e-856c-27af901331a5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pol_given_sent');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      slice  support  accuracy  macro_f1  f1_non_polarized  f1_objective  \\\n",
              "0  negative      886  0.788939  0.590720          0.576087      0.327869   \n",
              "1   neutral      401  0.628429  0.597698          0.671569      0.515464   \n",
              "2  positive      208  0.701923  0.588985          0.675000      0.333333   \n",
              "\n",
              "   f1_partisan  \n",
              "0     0.868206  \n",
              "1     0.606061  \n",
              "2     0.758621  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sent_given_pol\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"partisan\",\n          \"non_polarized\",\n          \"objective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 443,\n        \"min\": 90,\n        \"max\": 970,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          970,\n          435,\n          90\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0354624079524563,\n        \"min\": 0.6,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6123711340206186,\n          0.6,\n          0.6666666666666666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018015996231452357,\n        \"min\": 0.5881186988820116,\n        \"max\": 0.6206603853662677,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.590991507148614,\n          0.5881186988820116,\n          0.6206603853662677\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_negative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17752728906175885,\n        \"min\": 0.35398230088495575,\n        \"max\": 0.7057808455565142,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7057808455565142,\n          0.35398230088495575,\n          0.5714285714285714\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20292555296276885,\n        \"min\": 0.36363636363636365,\n        \"max\": 0.7450980392156863,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.36363636363636365,\n          0.674373795761079,\n          0.7450980392156863\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10194490595864417,\n        \"min\": 0.5454545454545454,\n        \"max\": 0.736,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7035573122529645,\n          0.736,\n          0.5454545454545454\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sent_given_pol"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-6defe5c9-d899-4984-845e-4408bc055842\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice</th>\n",
              "      <th>support</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro_f1</th>\n",
              "      <th>f1_negative</th>\n",
              "      <th>f1_neutral</th>\n",
              "      <th>f1_positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>partisan</td>\n",
              "      <td>970</td>\n",
              "      <td>0.612371</td>\n",
              "      <td>0.590992</td>\n",
              "      <td>0.705781</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.703557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>non_polarized</td>\n",
              "      <td>435</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.588119</td>\n",
              "      <td>0.353982</td>\n",
              "      <td>0.674374</td>\n",
              "      <td>0.736000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>objective</td>\n",
              "      <td>90</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.620660</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6defe5c9-d899-4984-845e-4408bc055842')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6defe5c9-d899-4984-845e-4408bc055842 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6defe5c9-d899-4984-845e-4408bc055842');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3f15ec8a-1b90-4919-81c4-3a5224149885\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f15ec8a-1b90-4919-81c4-3a5224149885')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3f15ec8a-1b90-4919-81c4-3a5224149885 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_49823f65-ea41-4c36-b49b-16dffdf6ae4e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_given_pol')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_49823f65-ea41-4c36-b49b-16dffdf6ae4e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sent_given_pol');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           slice  support  accuracy  macro_f1  f1_negative  f1_neutral  \\\n",
              "0       partisan      970  0.612371  0.590992     0.705781    0.363636   \n",
              "1  non_polarized      435  0.600000  0.588119     0.353982    0.674374   \n",
              "2      objective       90  0.666667  0.620660     0.571429    0.745098   \n",
              "\n",
              "   f1_positive  \n",
              "0     0.703557  \n",
              "1     0.736000  \n",
              "2     0.545455  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved detailed breakdowns to: ./runs_mbert_optimized/details\n"
          ]
        }
      ],
      "source": [
        "# ===== Section 11 â€” Detailed Breakdown Reports (per-class + cross-slices) =====\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "\n",
        "def per_class_breakdown(y_true, y_pred, class_names):\n",
        "    rep = classification_report(\n",
        "        y_true, y_pred,\n",
        "        target_names=list(class_names),\n",
        "        output_dict=True, zero_division=0\n",
        "    )\n",
        "    # Keep only the class rows in the given order\n",
        "    rows = []\n",
        "    for cname in class_names:\n",
        "        if cname in rep:\n",
        "            rows.append({\n",
        "                \"class\": cname,\n",
        "                \"precision\": rep[cname][\"precision\"],\n",
        "                \"recall\":    rep[cname][\"recall\"],\n",
        "                \"f1\":        rep[cname][\"f1-score\"],\n",
        "                \"support\":   int(rep[cname][\"support\"]),\n",
        "            })\n",
        "        else:\n",
        "            rows.append({\"class\": cname, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"support\": 0})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def cross_slice_breakdown(\n",
        "    slice_true,  # array of ints for the slicing label (e.g., true sentiment indices)\n",
        "    slice_names, # names of the slicing label classes (e.g., sentiment class names)\n",
        "    task_true,   # array of ints for the task we evaluate (e.g., true polarity indices)\n",
        "    task_pred,   # array of ints for the task predictions (e.g., predicted polarity indices)\n",
        "    task_names,  # names of the task classes (e.g., polarity class names)\n",
        "    slice_label  # string for the slice axis name, e.g., \"sentiment\" or \"polarity\"\n",
        "):\n",
        "    \"\"\"\n",
        "    For each class s in slice_true, evaluate the task predictions on the subset where slice_true == s.\n",
        "    Returns one row per slice value, including macro-F1, accuracy, and per-class F1 for the task.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for idx, sname in enumerate(slice_names):\n",
        "        mask = (slice_true == idx)\n",
        "        n = int(mask.sum())\n",
        "        if n == 0:\n",
        "            # No samples for this slice in test set\n",
        "            row = {\"slice\": sname, \"support\": 0, \"accuracy\": np.nan, \"macro_f1\": np.nan}\n",
        "            for tname in task_names:\n",
        "                row[f\"f1_{tname}\"] = np.nan\n",
        "            rows.append(row)\n",
        "            continue\n",
        "\n",
        "        rep = classification_report(\n",
        "            task_true[mask], task_pred[mask],\n",
        "            target_names=list(task_names),\n",
        "            output_dict=True, zero_division=0\n",
        "        )\n",
        "        row = {\n",
        "            \"slice\": sname,\n",
        "            \"support\": n,\n",
        "            \"accuracy\": rep[\"accuracy\"],\n",
        "            \"macro_f1\": rep[\"macro avg\"][\"f1-score\"],\n",
        "        }\n",
        "        for tname in task_names:\n",
        "            row[f\"f1_{tname}\"] = rep[tname][\"f1-score\"]\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    # Sort slices by support (desc) for readability\n",
        "    df = df.sort_values(by=\"support\", ascending=False).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# Where to save things\n",
        "DETAILS_DIR = os.path.join(OUT_DIR, \"details\")\n",
        "os.makedirs(DETAILS_DIR, exist_ok=True)\n",
        "\n",
        "all_breakdowns = {}\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\n=== Detailed breakdowns for {key} ===\")\n",
        "    ysent_pred, ypol_pred = pred_cache[key]\n",
        "\n",
        "    # ---- Per-class reports on the full test set\n",
        "    sent_per_class = per_class_breakdown(ysent_test, ysent_pred, sent_le.classes_)\n",
        "    pol_per_class  = per_class_breakdown(ypol_test,  ypol_pred,  pol_le.classes_)\n",
        "\n",
        "    # Save + show\n",
        "    sent_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_per_class.csv\")\n",
        "    pol_csv  = os.path.join(DETAILS_DIR, f\"{key}_polarization_per_class.csv\")\n",
        "    sent_per_class.to_csv(sent_csv, index=False)\n",
        "    pol_per_class.to_csv(pol_csv, index=False)\n",
        "\n",
        "    print(\"\\nSentiment â€” per class (precision/recall/F1/support):\")\n",
        "    display(sent_per_class)\n",
        "\n",
        "    print(\"\\nPolarization â€” per class (precision/recall/F1/support):\")\n",
        "    display(pol_per_class)\n",
        "\n",
        "    # ---- Cross-slice reports\n",
        "    # Polarity performance within each (true) sentiment slice\n",
        "    pol_given_sent = cross_slice_breakdown(\n",
        "        slice_true=ysent_test, slice_names=sent_le.classes_,\n",
        "        task_true=ypol_test,   task_pred=ypol_pred, task_names=pol_le.classes_,\n",
        "        slice_label=\"sentiment\"\n",
        "    )\n",
        "    pol_given_sent_csv = os.path.join(DETAILS_DIR, f\"{key}_polarity_given_sentiment.csv\")\n",
        "    pol_given_sent.to_csv(pol_given_sent_csv, index=False)\n",
        "\n",
        "    print(\"\\nPolarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\")\n",
        "    display(pol_given_sent)\n",
        "\n",
        "    # Sentiment performance within each (true) polarity slice\n",
        "    sent_given_pol = cross_slice_breakdown(\n",
        "        slice_true=ypol_test,  slice_names=pol_le.classes_,\n",
        "        task_true=ysent_test,  task_pred=ysent_pred, task_names=sent_le.classes_,\n",
        "        slice_label=\"polarity\"\n",
        "    )\n",
        "    sent_given_pol_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_given_polarity.csv\")\n",
        "    sent_given_pol.to_csv(sent_given_pol_csv, index=False)\n",
        "\n",
        "    print(\"\\nSentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\")\n",
        "    display(sent_given_pol)\n",
        "\n",
        "    # Keep for a single JSON bundle if you like\n",
        "    all_breakdowns[key] = {\n",
        "        \"sentiment_per_class_csv\": sent_csv,\n",
        "        \"polarization_per_class_csv\": pol_csv,\n",
        "        \"polarity_given_sentiment_csv\": pol_given_sent_csv,\n",
        "        \"sentiment_given_polarity_csv\": sent_given_pol_csv\n",
        "    }\n",
        "\n",
        "# Optional: write an index JSON pointing to all CSVs\n",
        "with open(os.path.join(DETAILS_DIR, \"index.json\"), \"w\") as f:\n",
        "    json.dump(all_breakdowns, f, indent=2)\n",
        "print(\"\\nSaved detailed breakdowns to:\", DETAILS_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q7YNE1ga4-c"
      },
      "source": [
        "\n",
        "### SECTION 11A\n",
        "Changed from 11C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "r9m5OlPQkFZ6",
        "outputId": "b3ab3b0f-a36a-4984-abac-a9d1c2b8f5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¯ MULTICLASS CALIBRATION - Optimize prediction biases for better performance\n",
            "======================================================================\n",
            "\n",
            "ðŸ”§ Calibrating mbert (bert-base-multilingual-cased)...\n",
            "ðŸ“Š Step 1: Extracting polarization logits from trained model...\n",
            "   Loading model from: ./runs_mbert_optimized/mbert\n",
            "   âœ“ Loading weights from: ./runs_mbert_optimized/mbert/model.safetensors\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Loading model from: ./runs_mbert_optimized/mbert\n",
            "   âœ“ Loading weights from: ./runs_mbert_optimized/mbert/model.safetensors\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ“ Validation logits shape: (1495, 3)\n",
            "   âœ“ Test logits shape: (1495, 3)\n",
            "ðŸ” Step 2: Searching for optimal bias vector (coordinate search)...\n",
            "   âœ“ Optimal bias vector found (VAL macro-F1=0.606):\n",
            "      â€¢ non_polarized: -0.20\n",
            "      â€¢     objective: -0.30\n",
            "      â€¢      partisan: +0.00\n",
            "ðŸ“ˆ Step 3: Evaluating calibration impact on test set...\n",
            "\n",
            "   ðŸ“Š TEST MACRO-F1: 0.625 â†’ 0.622 (-0.004)\n",
            "\n",
            "   Per-class breakdown:\n",
            "   ðŸ“‰ non_polarized: P=0.593 R=0.683 F1=0.635 (n=435)  â†’  P=0.688 R=0.508 F1=0.585 (-0.050)\n",
            "   ðŸ“ˆ     objective: P=0.424 R=0.433 F1=0.429 (n=90)  â†’  P=0.448 R=0.433 F1=0.441 (+0.012)\n",
            "   ðŸ“ˆ      partisan: P=0.844 R=0.785 F1=0.813 (n=970)  â†’  P=0.795 R=0.891 F1=0.840 (+0.027)\n",
            "\n",
            "âœ… Calibration complete! Bias vector saved to:\n",
            "   ./runs_mbert_optimized/calibration_vector/mbert_bias_vector.json\n",
            "\n",
            "======================================================================\n",
            "ðŸŽ‰ CALIBRATION FINISHED - All models optimized!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SECTION 11C â€” MULTICLASS POLARITY CALIBRATION (v2)\n",
        "# ============================================================================\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np, json, os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer, TrainingArguments, DataCollatorWithPadding\n",
        "\n",
        "# ============================================================================\n",
        "# Helper Functions for Calibration\n",
        "# ============================================================================\n",
        "\n",
        "class _PlainPairDS(Dataset):\n",
        "    \"\"\"Simple dataset for inference-only (no labels needed)\"\"\"\n",
        "    def __init__(self, titles, texts, tokenizer, max_length=224):\n",
        "        self.titles, self.texts = list(titles), list(texts)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.use_tt = \"token_type_ids\" in tokenizer.model_input_names\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tok(\n",
        "            text=str(self.titles[idx]),\n",
        "            text_pair=str(self.texts[idx]),\n",
        "            truncation=\"only_second\",\n",
        "            max_length=self.max_length,\n",
        "            return_token_type_ids=self.use_tt\n",
        "        )\n",
        "\n",
        "def _get_pol_logits(model_key, titles, texts):\n",
        "    \"\"\"Get polarization logits from trained model\"\"\"\n",
        "    # Load tokenizer and model\n",
        "    run_dir = os.path.join(OUT_DIR, model_key)\n",
        "    model_name = MODEL_CONFIGS[model_key][\"name\"]\n",
        "\n",
        "    print(f\"   Loading model from: {run_dir}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(run_dir if os.path.exists(os.path.join(run_dir, \"tokenizer.json\")) else model_name)\n",
        "\n",
        "    # Rebuild model and load weights\n",
        "    model = MultiTaskModel(model_name, num_sent_classes, num_pol_classes)\n",
        "\n",
        "    # ðŸ”§ RUN #9 FIX: Robust model loading - check multiple possible weight file formats\n",
        "    # Modern Transformers saves in different formats (pytorch_model.bin, model.safetensors, checkpoint-*/pytorch_model.bin)\n",
        "    weights_loaded = False\n",
        "\n",
        "    # Try 1: pytorch_model.bin in root\n",
        "    model_file = os.path.join(run_dir, \"pytorch_model.bin\")\n",
        "    if os.path.exists(model_file):\n",
        "        print(f\"   âœ“ Loading weights from: {model_file}\")\n",
        "        model.load_state_dict(torch.load(model_file, map_location=device), strict=False)\n",
        "        weights_loaded = True\n",
        "\n",
        "    # Try 2: model.safetensors in root\n",
        "    if not weights_loaded:\n",
        "        model_file = os.path.join(run_dir, \"model.safetensors\")\n",
        "        if os.path.exists(model_file):\n",
        "            print(f\"   âœ“ Loading weights from: {model_file}\")\n",
        "            from safetensors.torch import load_file\n",
        "            state_dict = load_file(model_file)\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "            weights_loaded = True\n",
        "\n",
        "    # Try 3: Latest checkpoint subdirectory (checkpoint-XXXX/pytorch_model.bin)\n",
        "    if not weights_loaded:\n",
        "        checkpoints = [d for d in os.listdir(run_dir) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(run_dir, d))]\n",
        "        if checkpoints:\n",
        "            # Get the latest checkpoint by number\n",
        "            latest_checkpoint = sorted(checkpoints, key=lambda x: int(x.split('-')[1]))[-1]\n",
        "            checkpoint_dir = os.path.join(run_dir, latest_checkpoint)\n",
        "            model_file = os.path.join(checkpoint_dir, \"pytorch_model.bin\")\n",
        "            if os.path.exists(model_file):\n",
        "                print(f\"   âœ“ Loading weights from checkpoint: {checkpoint_dir}\")\n",
        "                model.load_state_dict(torch.load(model_file, map_location=device), strict=False)\n",
        "                weights_loaded = True\n",
        "\n",
        "    if not weights_loaded:\n",
        "        print(f\"   âš ï¸ WARNING: No trained weights found in {run_dir}\")\n",
        "        print(f\"      Checked: pytorch_model.bin, model.safetensors, checkpoint-*/pytorch_model.bin\")\n",
        "        print(f\"      Using UNTRAINED model - calibration will be ineffective!\")\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Create dataset and trainer\n",
        "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
        "    args = TrainingArguments(\n",
        "        output_dir=os.path.join(run_dir, \"calib_tmp\"),\n",
        "        per_device_eval_batch_size=64,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    dummy_trainer = MultiTaskTrainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        data_collator=collator,\n",
        "        class_weights=None,\n",
        "        task_weights=None\n",
        "    )\n",
        "\n",
        "    ds = _PlainPairDS(titles, texts, tokenizer, MAX_LENGTH)\n",
        "    out = dummy_trainer.predict(ds)\n",
        "    _, pol_logits = out.predictions\n",
        "\n",
        "    return pol_logits\n",
        "\n",
        "# ============================================================================\n",
        "# Calibration Functions\n",
        "# ============================================================================\n",
        "\n",
        "def coord_search_biases(pol_logits_val, y_val, class_names, passes=2, grid=(-0.8, 0.8, 0.1)):\n",
        "    lo, hi, step = grid\n",
        "    C = pol_logits_val.shape[1]\n",
        "    b = np.zeros(C, dtype=np.float32)\n",
        "\n",
        "    def macro_f1_with(bias_vec):\n",
        "        y_pred = np.argmax(pol_logits_val + bias_vec.reshape(1, -1), axis=1)\n",
        "        rep = classification_report(y_val, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
        "        return rep[\"macro avg\"][\"f1-score\"]\n",
        "\n",
        "    best = macro_f1_with(b)\n",
        "    for _ in range(passes):\n",
        "        improved = False\n",
        "        for c in range(C):\n",
        "            best_b_c, best_score_c = b[c], best\n",
        "            for val in np.arange(lo, hi + 1e-9, step):\n",
        "                b_try = b.copy()\n",
        "                b_try[c] = val\n",
        "                score = macro_f1_with(b_try)\n",
        "                if score > best_score_c + 1e-6:\n",
        "                    best_score_c, best_b_c = score, val\n",
        "            if best_b_c != b[c]:\n",
        "                b[c] = best_b_c\n",
        "                best = best_score_c\n",
        "                improved = True\n",
        "        if not improved:\n",
        "            break\n",
        "    return b, float(best)\n",
        "\n",
        "CALIB_DIR2 = os.path.join(OUT_DIR, \"calibration_vector\")\n",
        "os.makedirs(CALIB_DIR2, exist_ok=True)\n",
        "\n",
        "print(\"ðŸŽ¯ MULTICLASS CALIBRATION - Optimize prediction biases for better performance\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    print(f\"\\nðŸ”§ Calibrating {key} ({MODEL_CONFIGS[key]['name']})...\")\n",
        "\n",
        "    print(f\"ðŸ“Š Step 1: Extracting polarization logits from trained model...\")\n",
        "    pol_val_logits = _get_pol_logits(key, X_val[TITLE_COL].values,  X_val[TEXT_COL].values)\n",
        "    pol_tst_logits = _get_pol_logits(key, X_test[TITLE_COL].values, X_test[TEXT_COL].values)\n",
        "    print(f\"   âœ“ Validation logits shape: {pol_val_logits.shape}\")\n",
        "    print(f\"   âœ“ Test logits shape: {pol_tst_logits.shape}\")\n",
        "\n",
        "    y_val = ypol_val\n",
        "    y_tst = ypol_test\n",
        "    class_names = list(pol_le.classes_)\n",
        "\n",
        "    print(f\"ðŸ” Step 2: Searching for optimal bias vector (coordinate search)...\")\n",
        "    b_vec, val_macro = coord_search_biases(pol_val_logits, y_val, class_names, passes=3, grid=(-0.8, 0.8, 0.1))\n",
        "    print(f\"   âœ“ Optimal bias vector found (VAL macro-F1={val_macro:.3f}):\")\n",
        "    for cname, bias_val in zip(class_names, b_vec):\n",
        "        print(f\"      â€¢ {cname:>13}: {bias_val:+.2f}\")\n",
        "\n",
        "    # Test before/after\n",
        "    print(f\"ðŸ“ˆ Step 3: Evaluating calibration impact on test set...\")\n",
        "    y_before = np.argmax(pol_tst_logits, axis=1)\n",
        "    rep_before = classification_report(y_tst, y_before, target_names=class_names, output_dict=True, zero_division=0)\n",
        "\n",
        "    y_after = np.argmax(pol_tst_logits + b_vec.reshape(1, -1), axis=1)\n",
        "    rep_after  = classification_report(y_tst, y_after, target_names=class_names, output_dict=True, zero_division=0)\n",
        "\n",
        "    improvement = rep_after['macro avg']['f1-score'] - rep_before['macro avg']['f1-score']\n",
        "    print(f\"\\n   ðŸ“Š TEST MACRO-F1: {rep_before['macro avg']['f1-score']:.3f} â†’ {rep_after['macro avg']['f1-score']:.3f} ({improvement:+.3f})\\n\")\n",
        "    print(\"   Per-class breakdown:\")\n",
        "    for cname in class_names:\n",
        "        b = rep_before[cname]; a = rep_after[cname]\n",
        "        f1_change = a['f1-score'] - b['f1-score']\n",
        "        emoji = \"ðŸ“ˆ\" if f1_change > 0 else \"ðŸ“‰\" if f1_change < 0 else \"âž¡ï¸\"\n",
        "        print(f\"   {emoji} {cname:>13}: P={b['precision']:.3f} R={b['recall']:.3f} F1={b['f1-score']:.3f} (n={int(b['support'])})\"\n",
        "              f\"  â†’  P={a['precision']:.3f} R={a['recall']:.3f} F1={a['f1-score']:.3f} ({f1_change:+.3f})\")\n",
        "\n",
        "    # Save calibration results\n",
        "    calib_file = os.path.join(CALIB_DIR2, f\"{key}_bias_vector.json\")\n",
        "    with open(calib_file, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"bias_vector\": {class_names[i]: float(b_vec[i]) for i in range(len(class_names))},\n",
        "            \"val_macro_f1\": val_macro,\n",
        "            \"test_macro_f1_before\": float(rep_before[\"macro avg\"][\"f1-score\"]),\n",
        "            \"test_macro_f1_after\":  float(rep_after[\"macro avg\"][\"f1-score\"])\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"\\nâœ… Calibration complete! Bias vector saved to:\")\n",
        "    print(f\"   {calib_file}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"ðŸŽ‰ CALIBRATION FINISHED - All models optimized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCGT3gEDcN9X"
      },
      "source": [
        "## SECTION 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhPV4I6TcP53",
        "outputId": "b49f252e-a913-4ed3-f6cb-beae2ee7368c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[mbert] bert-base-multilingual-cased\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token length stats: {'mean': 109.174, 'p50': 97.0, 'p90': 179.0, 'p95': 194.0, 'p99': 226.02000000000044, 'max': 916}\n",
            "âœ… SECTION 11+: Evaluation & Calibration completed in 14.5s\n",
            "ðŸ•’ Total runtime so far: 4.3h 20m\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "â±ï¸  EXECUTION TIME SUMMARY\n",
            "============================================================\n",
            "SECTION 2: Environment & Imports         : 9.2s\n",
            "SECTION 3: Configuration Setup           : 15.8m 49s\n",
            "SECTION 4: Data Loading & Preprocessing  : 1.2m 11s\n",
            "SECTION 5-9: Model Architecture & Training Setup : 53.2s\n",
            "SECTION 10: Model Training Execution     : 1.6h 33m\n",
            "SECTION 11+: Evaluation & Calibration    : 14.5s\n",
            "======================================== : ==========\n",
            "TOTAL EXECUTION TIME                     : 4.3h 20m\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===== Section 12 â€” Length Diagnostics (clean) =====\n",
        "import warnings\n",
        "\n",
        "def token_lengths_summary(texts, titles, tokenizer, n=5000):\n",
        "    # Random sample (or full if dataset is small)\n",
        "    n = min(n, len(texts))\n",
        "    idx = np.random.choice(len(texts), size=n, replace=False) if len(texts) > n else np.arange(len(texts))\n",
        "\n",
        "    lengths = []\n",
        "    # Silence the \"sequence > 512\" warnings emitted by some tokenizers for inspection\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", message=\"Token indices sequence length is longer.*\")\n",
        "        for i in idx:\n",
        "            s = f\"{titles[i]} [SEP] {texts[i]}\"\n",
        "            # We want raw length pre-truncation to choose MAX_LENGTH wisely\n",
        "            ids = tokenizer.encode(s, add_special_tokens=True, truncation=False)\n",
        "            lengths.append(len(ids))\n",
        "\n",
        "    arr = np.array(lengths)\n",
        "    stats = {\n",
        "        \"mean\": float(arr.mean()),\n",
        "        \"p50\":  float(np.percentile(arr, 50)),\n",
        "        \"p90\":  float(np.percentile(arr, 90)),\n",
        "        \"p95\":  float(np.percentile(arr, 95)),\n",
        "        \"p99\":  float(np.percentile(arr, 99)),\n",
        "        \"max\":  int(arr.max())\n",
        "    }\n",
        "    print(\"Token length stats:\", stats)\n",
        "    return stats\n",
        "\n",
        "for key in MODELS_TO_RUN:\n",
        "    name = MODEL_CONFIGS[key][\"name\"]\n",
        "    tok = AutoTokenizer.from_pretrained(name)\n",
        "    print(f\"\\n[{key}] {name}\")\n",
        "    token_lengths_summary(\n",
        "        texts=X_train[TEXT_COL].values,\n",
        "        titles=X_train[TITLE_COL].values,\n",
        "        tokenizer=tok,\n",
        "        n=5000\n",
        "    )\n",
        "\n",
        "# Tip:\n",
        "# If p95 is comfortably < 192, you're fine. If you see p95 > 192, consider MAX_LENGTH=224\n",
        "# (Update in Section 3 if you decide to bump it.)\n",
        "\n",
        "# Final timing summary\n",
        "timer.end_section(\"SECTION 11+: Evaluation & Calibration\")\n",
        "timer.get_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SECTION 13: SEED ENSEMBLE INSTRUCTIONS ðŸŽ²\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“š **How to Create a Seed Ensemble (Runs #10-13)**\n",
        "\n",
        "This section provides instructions for creating a seed ensemble to boost performance from **62.74%** (R9) to **64-65%** (expected).\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 1: Train 4 Models with Different Seeds**\n",
        "\n",
        "Run this notebook **4 times** with different seeds:\n",
        "\n",
        "1. **Run #10**: Set `SEED = 42` in Cell 8 (already done in R9, can reuse R9 results)\n",
        "2. **Run #11**: Set `SEED = 43` in Cell 8, run entire notebook\n",
        "3. **Run #12**: Set `SEED = 44` in Cell 8, run entire notebook  \n",
        "4. **Run #13**: Set `SEED = 45` in Cell 8, run entire notebook\n",
        "\n",
        "**â° Total training time**: ~6 hours (4 runs Ã— 93 minutes each)\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 2: Save Model Predictions**\n",
        "\n",
        "After each run completes, save the test set predictions:\n",
        "\n",
        "```python\n",
        "# After Section 10 completes, save predictions\n",
        "import pickle\n",
        "\n",
        "# Save raw logits for ensembling\n",
        "predictions = {\n",
        "    'sentiment_logits': sentiment_test_logits,  # Shape: (n_samples, 3)\n",
        "    'polarization_logits': polarization_test_logits,  # Shape: (n_samples, 3)\n",
        "    'sentiment_labels': y_test_sentiment,\n",
        "    'polarization_labels': y_test_polarization\n",
        "}\n",
        "\n",
        "# Save to file (change seed number for each run)\n",
        "with open(f'predictions_seed_{SEED}.pkl', 'wb') as f:\n",
        "    pickle.dump(predictions, f)\n",
        "    \n",
        "print(f\"âœ… Predictions saved for SEED={SEED}\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Step 3: Ensemble Predictions**\n",
        "\n",
        "After all 4 runs complete, average the predictions:\n",
        "\n",
        "```python\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load all 4 model predictions\n",
        "seeds = [42, 43, 44, 45]\n",
        "all_preds = []\n",
        "\n",
        "for seed in seeds:\n",
        "    with open(f'predictions_seed_{seed}.pkl', 'rb') as f:\n",
        "        preds = pickle.load(f)\n",
        "        all_preds.append(preds)\n",
        "\n",
        "# Average logits across all models\n",
        "sentiment_logits_avg = np.mean([p['sentiment_logits'] for p in all_preds], axis=0)\n",
        "polarization_logits_avg = np.mean([p['polarization_logits'] for p in all_preds], axis=0)\n",
        "\n",
        "# Get ensemble predictions\n",
        "sentiment_preds = np.argmax(sentiment_logits_avg, axis=1)\n",
        "polarization_preds = np.argmax(polarization_logits_avg, axis=1)\n",
        "\n",
        "# Evaluate ensemble\n",
        "y_test_sentiment = all_preds[0]['sentiment_labels']\n",
        "y_test_polarization = all_preds[0]['polarization_labels']\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ðŸŽ¯ SEED ENSEMBLE RESULTS (4 models: seeds 42, 43, 44, 45)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sentiment results\n",
        "print(\"\\nðŸ“Š SENTIMENT CLASSIFICATION:\")\n",
        "print(classification_report(y_test_sentiment, sentiment_preds, \n",
        "                          target_names=['negative', 'neutral', 'positive'], digits=4))\n",
        "\n",
        "# Polarization results\n",
        "print(\"\\nðŸ“Š POLARIZATION CLASSIFICATION:\")\n",
        "print(classification_report(y_test_polarization, polarization_preds,\n",
        "                          target_names=['non_polarized', 'objective', 'partisan'], digits=4))\n",
        "\n",
        "# Calculate overall macro-F1\n",
        "from sklearn.metrics import f1_score\n",
        "sentiment_f1 = f1_score(y_test_sentiment, sentiment_preds, average='macro')\n",
        "polarization_f1 = f1_score(y_test_polarization, polarization_preds, average='macro')\n",
        "overall_f1 = (sentiment_f1 + polarization_f1) / 2\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(f\"ðŸ† ENSEMBLE OVERALL MACRO-F1: {overall_f1:.4f}\")\n",
        "print(f\"   â”œâ”€ Sentiment F1: {sentiment_f1:.4f}\")\n",
        "print(f\"   â””â”€ Polarization F1: {polarization_f1:.4f}\")\n",
        "print(f\"   Expected: 64-65% (R9 was 62.74%, ensemble should add +1-2%)\")\n",
        "print(\"=\"*80)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Expected Results:**\n",
        "\n",
        "| Model          | Macro-F1 | Improvement |\n",
        "| -------------- | -------- | ----------- |\n",
        "| R9 (seed=42)   | 62.74%   | baseline    |\n",
        "| Ensemble (4)   | 64-65%   | **+1-2%** âœ…|\n",
        "\n",
        "---\n",
        "\n",
        "### **Why Seed Ensemble Works:**\n",
        "\n",
        "1. **Different random initializations** â†’ Different local minima\n",
        "2. **Diversity in predictions** â†’ Ensemble reduces variance\n",
        "3. **Low risk, proven technique** â†’ Standard ML practice\n",
        "4. **No code changes needed** â†’ Just run same notebook 4 times\n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps After Ensemble:**\n",
        "\n",
        "- If ensemble reaches **64-65%**: Consider XLM-RoBERTa (larger model)\n",
        "- If ensemble reaches **66%+**: Consider architectural changes (multi-stage training, data augmentation)\n",
        "- If ensemble < 64%: Re-evaluate strategy, may need different approaches\n",
        "\n",
        "---\n",
        "\n",
        "**ðŸ’¡ Recommendation:** Start with seed ensemble before trying more complex changes. This is the lowest-effort, lowest-risk path to improvement!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
