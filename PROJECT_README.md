# NotebookRuns - Model Training & Comparison Project

Research project for training and comparing multilingual transformer models (mBERT, XLM-RoBERTa, RemBERT) for sentiment analysis and polarization detection tasks.

## ğŸ“ Project Structure

```
NotebookRuns/
â”œâ”€â”€ venv/                              # Python virtual environment
â”‚
â”œâ”€â”€ Model-Comparison-Analysis/         # ğŸ“Š Model comparison tools and results
â”‚   â”œâ”€â”€ model_comparison.py           # Main analysis script
â”‚   â”œâ”€â”€ quick_stats.py                # Quick stats viewer
â”‚   â”œâ”€â”€ model_comparison_analysis.ipynb # Interactive notebook
â”‚   â”œâ”€â”€ requirements.txt              # Package dependencies
â”‚   â”œâ”€â”€ *.png                         # Generated visualizations
â”‚   â””â”€â”€ README.md                     # Detailed documentation
â”‚
â”œâ”€â”€ [M]-MBERT/                        # ğŸ¤– mBERT model training
â”‚   â”œâ”€â”€ MBERT_TRAINING.ipynb
â”‚   â”œâ”€â”€ run-data.md
â”‚   â””â”€â”€ runs/                         # Training run history
â”‚
â”œâ”€â”€ [M]-XLMR/                         # ğŸ¤– XLM-RoBERTa model training
â”‚   â”œâ”€â”€ XLM_ROBERTA_TRAINING.ipynb
â”‚   â”œâ”€â”€ run-data.md
â”‚   â””â”€â”€ runs/                         # Training run history
â”‚
â”œâ”€â”€ [M]-REMBERT/                      # ğŸ¤– RemBERT model training
â”‚   â”œâ”€â”€ REMBERT_TRAINING.ipynb
â”‚   â””â”€â”€ run-data.md
â”‚
â”œâ”€â”€ [M]-DATA_AUGMENTATION-XLMR/       # ğŸ“ˆ Data augmentation experiments
â”‚   â””â”€â”€ FILIPINO_DATA_AUGMENTATION_COLAB.ipynb
â”‚
â”œâ”€â”€ Runs/                             # ğŸ—‚ï¸ Historical training runs
â”‚   â””â”€â”€ *.ipynb
â”‚
â”œâ”€â”€ archive/                          # ğŸ“¦ Archived files
â”‚   â””â”€â”€ Various configuration and guide files
â”‚
â””â”€â”€ llm/                              # ğŸ¤– LLM prompts and documentation
    â””â”€â”€ cursor_*.md
```

## ğŸš€ Quick Start

### 1. Activate Virtual Environment

```powershell
# PowerShell
.\venv\Scripts\Activate.ps1
```

### 2. View Model Comparison

```powershell
cd Model-Comparison-Analysis
python quick_stats.py
```

### 3. Generate Full Analysis

```powershell
python model_comparison.py
```

### 4. Interactive Analysis

```powershell
jupyter notebook model_comparison_analysis.ipynb
```

## ğŸ“Š Model Performance Summary

| Model   | Sentiment F1 | Polarization F1 | Macro F1 | Training Time |
|---------|--------------|-----------------|----------|---------------|
| mBERT   | 98.51%       | 84.64%          | 91.58%   | 1.9h          |
| XLM-R   | 97.18%       | 86.61%          | 91.89%   | 2.5h          |
| RemBERT | 97.91%       | 85.73%          | 91.72%   | 9.5h          |

**Winner:** XLM-R achieves the highest overall performance (91.89%) with moderate training time, making it the most balanced choice.

## ğŸ› ï¸ Technologies Used

- **Models:** mBERT, XLM-RoBERTa, RemBERT
- **Framework:** PyTorch, Transformers (HuggingFace)
- **Analysis:** Python, Pandas, Matplotlib, Seaborn
- **Environment:** Jupyter Notebooks, VS Code

## ğŸ“ Key Files

- **Training Notebooks:** Located in `[M]-{MODEL}` directories
- **Run Data:** Each model folder contains `run-data.md` with detailed metrics
- **Comparison Tools:** All analysis scripts in `Model-Comparison-Analysis/`
- **Data:** CSV files for augmented adjudications and comments

## ğŸ¯ Research Focus

This project focuses on:
1. **Sentiment Analysis** - Classifying text sentiment (negative, neutral, positive)
2. **Polarization Detection** - Identifying political polarization (non-polarized, objective, partisan)
3. **Multilingual Models** - Comparing performance across different transformer architectures
4. **Data Augmentation** - Enhancing training data for better model performance

## ğŸ“– Documentation

- Full comparison analysis: See `Model-Comparison-Analysis/README.md`
- Individual model documentation: Check `model-mdver.md` files in model directories
- Training strategies: Review `archive/` for various implementation guides

## ğŸ”— Related Projects

- Model training runs: `[M]-MBERT`, `[M]-XLMR`, `[M]-REMBERT`
- Data augmentation: `[M]-DATA_AUGMENTATION-XLMR`
- Historical runs: `Runs/` directory

---

**Last Updated:** October 29, 2025
