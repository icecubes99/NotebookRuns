{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PEK4ueScFxe"
   },
   "source": [
    "## SECTION 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDy5SBFWV910",
    "outputId": "bcd4e596-b34b-4643-cf87-bc2cb20ca947"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Installing pinned, compatible versions â€¦\n",
      "NumPy: 2.1.1\n",
      "\n",
      "=== VERSION CHECK ===\n",
      "torch          : 2.9.0+cu128\n",
      "transformers   : 4.44.2\n",
      "accelerate     : 0.34.2\n",
      "datasets       : 2.21.0\n",
      "scikit-learn   : 1.5.2\n",
      "pandas         : 2.2.3\n",
      "numpy          : 2.1.1\n",
      "matplotlib     : 3.9.2\n",
      "\n",
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "Current CUDA Device: NVIDIA L4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: ENVIRONMENT SETUP (ROBUST, PY3.12-FRIENDLY)\n",
    "# ============================================================================\n",
    "\n",
    "import sys, subprocess, importlib, os\n",
    "\n",
    "def pipi(*pkgs):\n",
    "    # Force reinstall + no cache to avoid stale wheels\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"--force-reinstall\", \"--no-cache-dir\", *pkgs])\n",
    "\n",
    "print(\"Installing pinned, compatible versions â€¦\")\n",
    "# Torch: keep your existing CUDA build. If you don't have torch yet, uncomment the torch trio below.\n",
    "# pipi(\"torch==2.2.2\", \"torchaudio==2.2.2\", \"torchvision==0.17.2\")\n",
    "\n",
    "# Pin NumPy 2.x and libs that are built against it\n",
    "pipi(\n",
    "    \"numpy==2.1.1\",\n",
    "    \"pandas==2.2.3\",\n",
    "    \"scikit-learn==1.5.2\",\n",
    "    \"matplotlib==3.9.2\",\n",
    "    \"transformers==4.44.2\",\n",
    "    \"accelerate==0.34.2\",\n",
    "    \"datasets==2.21.0\",\n",
    ")\n",
    "\n",
    "# --- Import order matters; import numpy FIRST to catch ABI issues clearly\n",
    "import numpy as np\n",
    "print(\"NumPy:\", np.__version__)\n",
    "\n",
    "# Now the rest\n",
    "import torch, transformers, datasets, sklearn, pandas as pd, matplotlib, importlib\n",
    "\n",
    "print(\"\\n=== VERSION CHECK ===\")\n",
    "print(\"torch          :\", getattr(torch, \"__version__\", \"n/a\"))\n",
    "print(\"transformers   :\", transformers.__version__)\n",
    "print(\"accelerate     :\", importlib.import_module(\"accelerate\").__version__)\n",
    "print(\"datasets       :\", datasets.__version__)\n",
    "print(\"scikit-learn   :\", sklearn.__version__)\n",
    "print(\"pandas         :\", pd.__version__)\n",
    "print(\"numpy          :\", np.__version__)\n",
    "print(\"matplotlib     :\", matplotlib.__version__)\n",
    "\n",
    "# Sanity for TrainingArguments modern kwargs\n",
    "from packaging import version\n",
    "assert version.parse(transformers.__version__) >= version.parse(\"4.26.0\"), \\\n",
    "    \"Transformers too old for `evaluation_strategy`.\"\n",
    "\n",
    "# If NumPy was previously imported in this session, you may still have stale .soâ€™s in memory.\n",
    "# Simple guard: if you see an ABI error above, Restart runtime and run this cell again first.\n",
    "print(\"\\nCUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "    print(\"Current CUDA Device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YTTcGb6L7tv"
   },
   "source": [
    "### SECTION 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oBBJ_lPL7VW",
    "outputId": "5f607a79-1c10-46c5-d3c8-4d87b5382e63"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transformers version loaded in memory: 4.44.2\n",
      "Sample of supported TrainingArguments kwargs: ['accelerator_config', 'adafactor', 'adam_beta1', 'adam_beta2', 'adam_epsilon', 'auto_find_batch_size', 'batch_eval_metrics', 'bf16', 'bf16_full_eval', 'data_seed', 'dataloader_drop_last', 'dataloader_num_workers'] ...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1.5: VERSION CHECK + TRAININGARGUMENTS COMPATIBILITY SHIM\n",
    "# ============================================================================\n",
    "\n",
    "import inspect, importlib, sys\n",
    "import transformers as _tf\n",
    "\n",
    "print(\"Transformers version loaded in memory:\", _tf.__version__)\n",
    "\n",
    "def _supported_kwargs_of_training_args():\n",
    "    # Build the set of supported __init__ kwargs for the loaded TrainingArguments\n",
    "    try:\n",
    "        from transformers import TrainingArguments\n",
    "        sig = inspect.signature(TrainingArguments.__init__)\n",
    "        return set(sig.parameters.keys())\n",
    "    except Exception as e:\n",
    "        print(\"[Compat] Could not inspect TrainingArguments:\", e)\n",
    "        return set()\n",
    "\n",
    "_SUPPORTED_TA_KEYS = _supported_kwargs_of_training_args()\n",
    "print(\"Sample of supported TrainingArguments kwargs:\", sorted(list(_SUPPORTED_TA_KEYS))[:12], \"...\")\n",
    "\n",
    "def make_training_args_compat(**kwargs):\n",
    "    \"\"\"\n",
    "    Create TrainingArguments while dropping any kwargs unsupported by the loaded transformers version.\n",
    "    Prints what was ignored so you know if your runtime is old.\n",
    "    \"\"\"\n",
    "    from transformers import TrainingArguments\n",
    "    filtered = {k: v for k, v in kwargs.items() if k in _SUPPORTED_TA_KEYS}\n",
    "    ignored = [k for k in kwargs.keys() if k not in _SUPPORTED_TA_KEYS]\n",
    "    if ignored:\n",
    "        print(\"[Compat] Ignored unsupported TrainingArguments keys:\", ignored)\n",
    "    return TrainingArguments(**filtered)\n",
    "\n",
    "def get_early_stopping_callbacks(patience: int):\n",
    "    \"\"\"Return EarlyStoppingCallback if available; otherwise return [].\"\"\"\n",
    "    try:\n",
    "        from transformers import EarlyStoppingCallback\n",
    "        return [EarlyStoppingCallback(early_stopping_patience=patience)]\n",
    "    except Exception as e:\n",
    "        print(\"[Compat] EarlyStoppingCallback unavailable:\", e)\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG7la9p-cDKM"
   },
   "source": [
    "## SECTION 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSVM6xD6WkaF",
    "outputId": "0a8231b0-2d99-4285-e09b-97cba09791ef"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "ðŸš€ Starting SECTION 2: Environment & Imports...\n",
      "âœ… SECTION 2: Environment & Imports completed in 5.0s\n",
      "ðŸ•’ Total runtime so far: 5.0s\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Starting SECTION 3: Configuration Setup...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: IMPORTS AND BASIC SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# ============================================================================\n",
    "# TIMING UTILITY - Track execution time for each section\n",
    "# ============================================================================\n",
    "class SectionTimer:\n",
    "    def __init__(self):\n",
    "        self.section_times = {}\n",
    "        self.start_time = None\n",
    "        self.total_start = time.time()\n",
    "\n",
    "    def start_section(self, section_name):\n",
    "        \"\"\"Start timing a section\"\"\"\n",
    "        self.start_time = time.time()\n",
    "        print(f\"\\nðŸš€ Starting {section_name}...\")\n",
    "\n",
    "    def end_section(self, section_name):\n",
    "        \"\"\"End timing and display results\"\"\"\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "\n",
    "        elapsed = time.time() - self.start_time\n",
    "        self.section_times[section_name] = elapsed\n",
    "\n",
    "        # Format time nicely\n",
    "        if elapsed < 60:\n",
    "            time_str = f\"{elapsed:.1f}s\"\n",
    "        elif elapsed < 3600:\n",
    "            time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
    "        else:\n",
    "            time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
    "\n",
    "        total_elapsed = time.time() - self.total_start\n",
    "        if total_elapsed < 60:\n",
    "            total_str = f\"{total_elapsed:.1f}s\"\n",
    "        elif total_elapsed < 3600:\n",
    "            total_str = f\"{total_elapsed/60:.1f}m {total_elapsed%60:.0f}s\"\n",
    "        else:\n",
    "            total_str = f\"{total_elapsed/3600:.1f}h {(total_elapsed%3600)/60:.0f}m\"\n",
    "\n",
    "        print(f\"âœ… {section_name} completed in {time_str}\")\n",
    "        print(f\"ðŸ•’ Total runtime so far: {total_str}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    def get_summary(self):\n",
    "        \"\"\"Get timing summary\"\"\"\n",
    "        total = time.time() - self.total_start\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"â±ï¸  EXECUTION TIME SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        for section, elapsed in self.section_times.items():\n",
    "            if elapsed < 60:\n",
    "                time_str = f\"{elapsed:.1f}s\"\n",
    "            elif elapsed < 3600:\n",
    "                time_str = f\"{elapsed/60:.1f}m {elapsed%60:.0f}s\"\n",
    "            else:\n",
    "                time_str = f\"{elapsed/3600:.1f}h {(elapsed%3600)/60:.0f}m\"\n",
    "            print(f\"{section:<40} : {time_str}\")\n",
    "\n",
    "        if total < 60:\n",
    "            total_str = f\"{total:.1f}s\"\n",
    "        elif total < 3600:\n",
    "            total_str = f\"{total/60:.1f}m {total%60:.0f}s\"\n",
    "        else:\n",
    "            total_str = f\"{total/3600:.1f}h {(total%3600)/60:.0f}m\"\n",
    "\n",
    "        print(f\"{'='*40} : {'='*10}\")\n",
    "        print(f\"{'TOTAL EXECUTION TIME':<40} : {total_str}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# Initialize global timer\n",
    "timer = SectionTimer()\n",
    "timer.start_section(\"SECTION 2: Environment & Imports\")\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# End timing for section 2\n",
    "timer.end_section(\"SECTION 2: Environment & Imports\")\n",
    "timer.start_section(\"SECTION 3: Configuration Setup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYH7gi4mWNTj",
    "outputId": "0bbca4ad-78f2-4048-be82-16c631095b82"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import os, random, json, math\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, TrainingArguments, Trainer,\n",
    "    DataCollatorWithPadding, EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5jkDOC6cAXz"
   },
   "source": [
    "## SECTION 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bDchgs1WPUm",
    "outputId": "c99cc64a-882c-4adb-e7e1-1dee2894c742"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸ“Š XLM-RoBERTa RUN #13 POLARITY RECOVERY - TARGET: â‰¥72% MACRO-F1\n",
      "âš ï¸ Run #12 Result: 67.48% macro-F1 (Neutral breakthrough, partisan/negative regression)\n",
      "âœ… Dataset: 13,063 samples (+31%): Objective 588â†’1,423, Neutral 2,677â†’5,775\n",
      "ðŸ”§ Run #13 Strategy: Rebalance weights/oversampling, soften focal gamma, longer warmup\n",
      "ðŸŽ¯ Focus: Recover partisan & negative precision while keeping neutral >70% F1\n",
      "======================================================================\n",
      "ðŸ“Š Training Settings:\n",
      "   Epochs: 18 | Batch: 20 | Grad Accum: 3 (Effective: 60)\n",
      "   LR: 3.0e-05 | LR Schedule: cosine (cycles=0.5) | Warmup: 24%\n",
      "   Weight Decay: 0.04 | Early Stop: 6 | Max Grad Norm: 1.0\n",
      "\n",
      "ðŸŽ¯ Loss Functions:\n",
      "   Focal Gamma (Sent/Pol): 2.5 / 2.8\n",
      "   Label Smoothing (Sent/Pol): 0.1 / 0.08\n",
      "   Task Weights: Sent=1.0, Pol=1.4\n",
      "\n",
      "âš–ï¸ Class Rebalancing:\n",
      "   Sentiment Multipliers: {'negative': 1.15, 'neutral': 1.15, 'positive': 1.4}\n",
      "   Polarization Multipliers: {'non_polarized': 1.2, 'objective': 1.95, 'partisan': 1.05}\n",
      "   Max Class Weight Cap: 8.0\n",
      "\n",
      "ðŸ“ˆ Oversampling (â¬‡ï¸ RUN #12 REDUCED - Augmented data provides natural balance!):\n",
      "   Joint Alpha: 0.65 | Max Mult: 4.5x (expected: ~8-10)\n",
      "   Objective Boost: 1.7x (â¬‡ï¸ REDUCED from 3.5x - now have 1,423 samples!)\n",
      "   Neutral Boost: 0.8x (â¬†ï¸ INCREASED from 0.3x - natural distribution now!)\n",
      "\n",
      "ðŸ—ï¸ Architecture:\n",
      "   Head Hidden: 768 | Layers: 3 | Dropout: 0.24\n",
      "   Pooling: last4_mean\n",
      "\n",
      "ðŸ›¡ï¸ Regularization:\n",
      "   R-Drop: Î±=0.6, Warmup=2 epochs\n",
      "   LLRD: Decay=0.88, Head LR Mult=3.5x\n",
      "\n",
      "ðŸ’¾ Output: ./runs_xlm_roberta_run13\n",
      "======================================================================\n",
      "âœ… SECTION 3: Configuration Setup completed in 0.0s\n",
      "ðŸ•’ Total runtime so far: 5.0s\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Starting SECTION 4: Data Loading & Preprocessing...\n"
     ]
    }
   ],
   "source": [
    "# ðŸ¤– TRAINING ONLY: XLM-RoBERTa (xlm-roberta-base)\n# Expected: ~35-40 min, 65-70% macro-F1\n# ===== Section 3 â€” Config (pooling + R-Drop + LLRD) =====\n\ndata_path = '/content/augmented_adjudications_2025-10-22.csv'\nCSV_PATH = '/content/augmented_adjudications_2025-10-22.csv'\n\n\nTITLE_COL = \"Title\"\nTEXT_COL  = \"Comment\"\nSENT_COL  = \"Final Sentiment\"\nPOL_COL   = \"Final Polarization\"\n\nMODEL_CONFIGS = {\n    \"xlm_roberta\": {\"name\": \"xlm-roberta-base\", \"desc\": \"XLM-RoBERTa base (100 langs)\"},\n}\nMODELS_TO_RUN = [\"xlm_roberta\"]  # â† TRAINING ONLY XLM-RoBERTa\n\n# ============================================================================\n# CORE TRAINING - RUN #14 NEUTRAL-PARTISAN BALANCE (TARGET â‰¥72% MACRO-F1)\n# Run #13 Result: 67.80% macro-F1 (Partisan back on track, neutral slipped)\n# Run #14 Goal: Recover neutral recall without giving back partisan gains\n# Strategy: Lift neutral weighting slightly, push objective cues, guarantee checkpoints\n# Dataset: augmented_adjudications_2025-10-22.csv (13,063 rows; same split 9,144 / 1,959 / 1,960)\n# ============================================================================\nMAX_LENGTH = 224\nEPOCHS = 18                # âœ… KEEP - convergence sweet spot with more data\nBATCH_SIZE = 20           # âœ… KEEP - fits memory with grad accumulation\nLR = 3.0e-5              # âœ… KEEP (proven optimal)\nWEIGHT_DECAY = 0.04      # âœ… KEEP (proven optimal)\nWARMUP_RATIO = 0.25      # â¬†ï¸ SLIGHTLY LONGER (0.24 â†’ 0.25) - softer ramp for re-weighted classes\nEARLY_STOP_PATIENCE = 6  # âœ… KEEP (proven optimal)\nGRAD_ACCUM_STEPS = 3     # Effective batch: 60\n\n# Per-task loss - RUN #14 ADJUSTMENTS\nUSE_FOCAL_SENTIMENT = True\nUSE_FOCAL_POLARITY  = True\nFOCAL_GAMMA_SENTIMENT = 2.5   # âœ… KEEP\nFOCAL_GAMMA_POLARITY = 2.8    # âœ… KEEP - maintains partisan recovery while easing penalties\nLABEL_SMOOTH_SENTIMENT = 0.10 # âœ… KEEP\nLABEL_SMOOTH_POLARITY = 0.08  # âœ… KEEP\n\n# Task weights - BALANCED\nTASK_LOSS_WEIGHTS = {\"sentiment\": 1.0, \"polarization\": 1.4}\n\n# Additional stability parameters\nMAX_GRAD_NORM = 1.0          # ðŸ”¥ RELAXED (Run #1: 0.7 â†’ 1.0) - Allow bigger updates with high LR\nUSE_GRADIENT_CHECKPOINTING = True  # Memory efficiency\n\n# Learning Rate Scheduling - KEEP PROVEN CONFIG\nLR_SCHEDULER_TYPE = \"cosine\"  # ðŸ”¥ Cosine annealing with warmup for smooth decay\nNUM_CYCLES = 0.5              # âœ… KEEP (proven optimal - smooth convergence!)\n\n# ============================================================================\n# CLASS WEIGHTS - RUN #14 REBALANCING\n# Neutral regained 70%+ F1 but slipped in Run #13; lift neutrals slightly while keeping partisan boost\n# Objective still the bottleneck â†’ modest additional emphasis\n# ============================================================================\nCLASS_WEIGHT_MULT = {\n    \"sentiment\": {\n        \"negative\": 1.15,    # âœ… KEEP - maintains recovered negative precision\n        \"neutral\":  1.20,    # â¬†ï¸ SLIGHT (1.15 â†’ 1.20) - regain neutral recall/precision balance\n        \"positive\": 1.40     # âœ… KEEP - smallest class support\n    },\n    \"polarization\": {\n        \"non_polarized\": 1.20,  # âœ… KEEP - balanced macro-F1 anchor\n        \"objective\":     2.05,  # â¬†ï¸ SLIGHT (1.95 â†’ 2.05) - nudge toward 60% F1 target\n        \"partisan\":      1.05   # âœ… KEEP - retains partisan gains\n    }\n}\n\n# Cap maximum class weight to prevent instability\nMAX_CLASS_WEIGHT = 8.0  # âœ… KEEP - avoids extreme logits\n\n# ============================================================================\n# OVERSAMPLING - RUN #14 CONTROLLED BOOSTS\n# Maintain objective cushion, ease neutral down only slightly to guard precision\n# ============================================================================\nUSE_OVERSAMPLING = True\nUSE_JOINT_OVERSAMPLING = True\nUSE_SMART_OVERSAMPLING = True\nJOINT_ALPHA = 0.65              # âœ… KEEP (proven optimal)\nJOINT_OVERSAMPLING_MAX_MULT = 4.6  # â¬†ï¸ SLIGHT (4.5 â†’ 4.6) - tiny flexibility for minority pairs\nOBJECTIVE_BOOST_MULT = 1.75      # â¬†ï¸ SLIGHT (1.7 â†’ 1.75) - stabilize objective predictions\nNEUTRAL_BOOST_MULT = 0.90        # â¬†ï¸ SLIGHT (0.8 â†’ 0.9) - recover neutral coverage without overshoot\n\n# ============================================================================\n# ARCHITECTURE - RUN #14 (STILL 768 HIDDEN, EXTRA DROPOUT)\n# 768 hidden remains best trade-off; keep dropout raised for minority stability\n# ============================================================================\nHEAD_HIDDEN = 768\nHEAD_DROPOUT = 0.24          # âœ… KEEP - helps partisan precision\nREP_POOLING = \"last4_mean\"\nHEAD_LAYERS = 3\n\n# ============================================================================\n# REGULARIZATION - RUN #14\n# Continue moderate R-Drop + LLRD\n# ============================================================================\nUSE_RDROP = True\nRDROP_ALPHA = 0.6\nRDROP_WARMUP_EPOCHS = 2\n\n# LLRD (layer-wise learning-rate decay)\nUSE_LLRD = True\nLLRD_DECAY = 0.88\nHEAD_LR_MULT = 3.5\n\nOUT_DIR = \"./runs_xlm_roberta_run14\"  # Run-specific output directory to avoid calibration conflicts\nos.makedirs(OUT_DIR, exist_ok=True)\n\n# ============================================================================\n# CONFIGURATION SUMMARY - RUN #14 NEUTRAL-PARTISAN BALANCE\n# ============================================================================\nprint(\"ðŸ“Š XLM-RoBERTa RUN #14 NEUTRAL-PARTISAN BALANCE - TARGET: â‰¥72% MACRO-F1\")\nprint(\"âš ï¸ Run #13 Result: 67.80% macro-F1 (Partisan recovered, neutral slipped)\")\nprint(\"âœ… Dataset: 13,063 samples (+31%): Objective 588â†’1,423, Neutral 2,677â†’5,775\")\nprint(\"ðŸ”§ Run #14 Strategy: Lift neutral weighting, push objective cues, ensure checkpoints exist\")\nprint(\"ðŸŽ¯ Focus: Keep partisan â‰¥75% F1 while restoring neutral â‰¥74%\")\nprint(\"=\"*70)\nprint(f\"ðŸ“Š Training Settings:\")\nprint(f\"   Epochs: {EPOCHS} | Batch: {BATCH_SIZE} | Grad Accum: {GRAD_ACCUM_STEPS} (Effective: {BATCH_SIZE*GRAD_ACCUM_STEPS})\")\nprint(f\"   LR: {LR:.1e} | LR Schedule: {LR_SCHEDULER_TYPE} (cycles={NUM_CYCLES}) | Warmup: {WARMUP_RATIO:.0%}\")\nprint(f\"   Weight Decay: {WEIGHT_DECAY} | Early Stop: {EARLY_STOP_PATIENCE} | Max Grad Norm: {MAX_GRAD_NORM}\")\nprint(f\"\nðŸŽ¯ Loss Functions:\")\nprint(f\"   Focal Gamma (Sent/Pol): {FOCAL_GAMMA_SENTIMENT} / {FOCAL_GAMMA_POLARITY}\")\nprint(f\"   Label Smoothing (Sent/Pol): {LABEL_SMOOTH_SENTIMENT} / {LABEL_SMOOTH_POLARITY}\")\nprint(f\"   Task Weights: Sent={TASK_LOSS_WEIGHTS['sentiment']}, Pol={TASK_LOSS_WEIGHTS['polarization']}\")\nprint(f\"\nâš–ï¸ Class Rebalancing:\")\nprint(f\"   Sentiment Multipliers: {CLASS_WEIGHT_MULT['sentiment']}\")\nprint(f\"   Polarization Multipliers: {CLASS_WEIGHT_MULT['polarization']}\")\nprint(f\"   Max Class Weight Cap: {MAX_CLASS_WEIGHT}\")\nprint(f\"\nðŸ“ˆ Oversampling (Run #14 balanced boosts):\")\nprint(f\"   Joint Alpha: {JOINT_ALPHA} | Max Mult: {JOINT_OVERSAMPLING_MAX_MULT}x (expected: ~8-9)\")\nprint(f\"   Objective Boost: {OBJECTIVE_BOOST_MULT}x (keeps objective stable)\")\nprint(f\"   Neutral Boost: {NEUTRAL_BOOST_MULT}x (restores neutral coverage without overfitting)\")\nprint(f\"\nðŸ—ï¸ Architecture:\")\nprint(f\"   Head Hidden: {HEAD_HIDDEN} | Layers: {HEAD_LAYERS} | Dropout: {HEAD_DROPOUT}\")\nprint(f\"   Pooling: {REP_POOLING}\")\nprint(f\"\nðŸ›¡ï¸ Regularization:\")\nprint(f\"   R-Drop: Î±={RDROP_ALPHA}, Warmup={RDROP_WARMUP_EPOCHS} epochs\")\nprint(f\"   LLRD: Decay={LLRD_DECAY}, Head LR Mult={HEAD_LR_MULT}x\")\nprint(f\"\nðŸ’¾ Output: {OUT_DIR}\")\nprint(\"=\"*70)\n\n# End timing for section 3\ntimer.end_section(\"SECTION 3: Configuration Setup\")\ntimer.start_section(\"SECTION 4: Data Loading & Preprocessing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKtHe-Ezb-id"
   },
   "source": [
    "## SECTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4fHWCOWW19j",
    "outputId": "c9f76168-5c38-405a-f2d1-3220e9896243"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentiment classes: {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
      "Polarization classes: {0: 'non_polarized', 1: 'objective', 2: 'partisan'}\n",
      "Train size: 9144 Val size: 1959 Test size: 1960\n",
      "Final sentiment class weights (capped): {'negative': 0.8481006622314453, 'neutral': 0.8669799566268921, 'positive': 4.40826416015625}\n",
      "Final polarization class weights (capped): {'non_polarized': 1.2815698385238647, 'objective': 5.873122692108154, 'partisan': 0.606365978717804}\n",
      "Class weights were capped at maximum: 8.0\n",
      "âœ… SECTION 4: Data Loading & Preprocessing completed in 40.8s\n",
      "ðŸ•’ Total runtime so far: 45.8s\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Starting SECTION 5-9: Model Architecture & Training Setup...\n"
     ]
    }
   ],
   "source": [
    "# ===== Section 4 â€” Load & Prepare Data (updated for multipliers) =====\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "required = [TITLE_COL, TEXT_COL, SENT_COL, POL_COL]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "df = df.dropna(subset=[TITLE_COL, TEXT_COL, SENT_COL, POL_COL]).reset_index(drop=True)\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "sent_le = LabelEncoder().fit(df[SENT_COL])\n",
    "pol_le  = LabelEncoder().fit(df[POL_COL])\n",
    "\n",
    "df[\"sent_y\"] = sent_le.transform(df[SENT_COL])\n",
    "df[\"pol_y\"]  = pol_le.transform(df[POL_COL])\n",
    "\n",
    "num_sent_classes = len(sent_le.classes_)\n",
    "num_pol_classes  = len(pol_le.classes_)\n",
    "\n",
    "print(\"Sentiment classes:\", dict(enumerate(sent_le.classes_)))\n",
    "print(\"Polarization classes:\", dict(enumerate(pol_le.classes_)))\n",
    "\n",
    "# Splits (stratify by sentiment)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[[TITLE_COL, TEXT_COL]].copy()\n",
    "y_sent = df[\"sent_y\"].values\n",
    "y_pol  = df[\"pol_y\"].values\n",
    "\n",
    "X_train, X_tmp, ysent_train, ysent_tmp, ypol_train, ypol_tmp = train_test_split(\n",
    "    X, y_sent, y_pol, test_size=0.3, random_state=42, stratify=y_sent\n",
    ")\n",
    "X_val, X_test, ysent_val, ysent_test, ypol_val, ypol_test = train_test_split(\n",
    "    X_tmp, ysent_tmp, ypol_tmp, test_size=0.5, random_state=42, stratify=ysent_tmp\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Val size:\", len(X_val), \"Test size:\", len(X_test))\n",
    "\n",
    "# Balanced class weights from TRAIN only\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np, json, os\n",
    "\n",
    "def safe_class_weights(y, n_classes):\n",
    "    classes = np.arange(n_classes)\n",
    "    counts = np.bincount(y, minlength=n_classes)\n",
    "    if np.any(counts == 0):\n",
    "        return np.ones(n_classes, dtype=np.float32)\n",
    "    return compute_class_weight(\"balanced\", classes=classes, y=y).astype(np.float32)\n",
    "\n",
    "sent_weights_np = safe_class_weights(ysent_train, num_sent_classes)\n",
    "pol_weights_np  = safe_class_weights(ypol_train,  num_pol_classes)\n",
    "\n",
    "# Apply user multipliers by class name\n",
    "sent_name_to_idx = {name: i for i, name in enumerate(sent_le.classes_)}\n",
    "pol_name_to_idx  = {name: i for i, name in enumerate(pol_le.classes_)}\n",
    "\n",
    "for cname, mult in CLASS_WEIGHT_MULT[\"sentiment\"].items():\n",
    "    if cname in sent_name_to_idx:\n",
    "        sent_weights_np[sent_name_to_idx[cname]] *= float(mult)\n",
    "\n",
    "for cname, mult in CLASS_WEIGHT_MULT[\"polarization\"].items():\n",
    "    if cname in pol_name_to_idx:\n",
    "        pol_weights_np[pol_name_to_idx[cname]] *= float(mult)\n",
    "\n",
    "# Apply class weight caps to prevent training instability\n",
    "sent_weights_np = np.clip(sent_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
    "pol_weights_np = np.clip(pol_weights_np, 0.1, MAX_CLASS_WEIGHT)\n",
    "\n",
    "print(\"Final sentiment class weights (capped):\", {sent_le.classes_[i]: float(w) for i, w in enumerate(sent_weights_np)})\n",
    "print(\"Final polarization class weights (capped):\", {pol_le.classes_[i]: float(w) for i, w in enumerate(pol_weights_np)})\n",
    "print(f\"Class weights were capped at maximum: {MAX_CLASS_WEIGHT}\")\n",
    "\n",
    "# Save label maps\n",
    "with open(os.path.join(OUT_DIR, \"label_map_sentiment.json\"), \"w\") as f:\n",
    "    json.dump({int(k): v for k, v in dict(enumerate(sent_le.classes_)).items()}, f, indent=2)\n",
    "with open(os.path.join(OUT_DIR, \"label_map_polarization.json\"), \"w\") as f:\n",
    "    json.dump({int(k): v for k, v in dict(enumerate(pol_le.classes_)).items()}, f, indent=2)\n",
    "\n",
    "# End timing for section 4\n",
    "timer.end_section(\"SECTION 4: Data Loading & Preprocessing\")\n",
    "timer.start_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0x3VSqAb8V9"
   },
   "source": [
    "## SECTION 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YJkJpNWiX5oT"
   },
   "outputs": [],
   "source": [
    "# ===== Section 5 â€” Dataset & Collator (proper text-pair encoding) =====\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TaglishDataset(Dataset):\n",
    "    def __init__(self, titles, texts, y_sent, y_pol, tokenizer, max_length=224):\n",
    "        self.titles = list(titles)\n",
    "        self.texts  = list(texts)\n",
    "        self.y_sent = np.array(y_sent)\n",
    "        self.y_pol  = np.array(y_pol)\n",
    "        self.tok = tokenizer\n",
    "        self.max_length = max_length\n",
    "        # XLM-RoBERTa doesn't use token_type_ids (unlike BERT models)\n",
    "        self.use_token_type = \"token_type_ids\" in tokenizer.model_input_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Pass title as text, comment as text_pair so the tokenizer inserts the correct separators.\n",
    "        # We also bias truncation to the comment since titles are short.\n",
    "        enc = self.tok(\n",
    "            text=str(self.titles[idx]),\n",
    "            text_pair=str(self.texts[idx]),\n",
    "            truncation=\"only_second\",     # keep the title intact; trim the comment if needed\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=self.use_token_type,\n",
    "        )\n",
    "        item = {\n",
    "            \"input_ids\": enc[\"input_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"sentiment_labels\": torch.tensor(self.y_sent[idx], dtype=torch.long),\n",
    "            \"polarization_labels\": torch.tensor(self.y_pol[idx], dtype=torch.long),\n",
    "        }\n",
    "        if self.use_token_type and \"token_type_ids\" in enc:\n",
    "            item[\"token_type_ids\"] = enc[\"token_type_ids\"]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BpY_PhNb6M9"
   },
   "source": [
    "## SECTION 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aBI8mY8zX9bh"
   },
   "outputs": [],
   "source": [
    "# ===== Section 6 â€” Multi-Task Model (pooling + MLP heads) =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    mask = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    summed = (token_embeddings * mask).sum(dim=1)\n",
    "    denom = mask.sum(dim=1).clamp(min=1e-9)\n",
    "    return summed / denom\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, base_model_name: str, num_sent: int, num_pol: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(base_model_name)\n",
    "        self.hidden = self.encoder.config.hidden_size\n",
    "\n",
    "        # Enhanced trunk with better architecture\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden, HEAD_HIDDEN),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(HEAD_HIDDEN),\n",
    "            nn.Dropout(HEAD_DROPOUT),\n",
    "        )\n",
    "\n",
    "        # Enhanced multi-layer heads for better task-specific learning\n",
    "        if HEAD_LAYERS == 2:\n",
    "            self.head_sent = nn.Sequential(\n",
    "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
    "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
    "                nn.Linear(HEAD_HIDDEN // 2, num_sent)\n",
    "            )\n",
    "            self.head_pol = nn.Sequential(\n",
    "                nn.Linear(HEAD_HIDDEN, HEAD_HIDDEN // 2),\n",
    "                nn.GELU(),\n",
    "                nn.LayerNorm(HEAD_HIDDEN // 2),\n",
    "                nn.Dropout(HEAD_DROPOUT * 0.8),\n",
    "                nn.Linear(HEAD_HIDDEN // 2, num_pol)\n",
    "            )\n",
    "        else:\n",
    "            self.head_sent = nn.Linear(HEAD_HIDDEN, num_sent)\n",
    "            self.head_pol  = nn.Linear(HEAD_HIDDEN, num_pol)\n",
    "\n",
    "        # Enable gradient checkpointing if configured\n",
    "        if USE_GRADIENT_CHECKPOINTING:\n",
    "            self.encoder.gradient_checkpointing_enable()\n",
    "\n",
    "    def _pool(self, outputs, attention_mask):\n",
    "        # Flexible representation pooling\n",
    "        if REP_POOLING == \"pooler\" and hasattr(outputs, \"pooler_output\") and outputs.pooler_output is not None:\n",
    "            return outputs.pooler_output\n",
    "        if REP_POOLING == \"cls\":\n",
    "            return outputs.last_hidden_state[:, 0]\n",
    "        # default: last4_mean\n",
    "        hs = outputs.hidden_states  # tuple of [layer0..last]\n",
    "        last4 = torch.stack(hs[-4:]).mean(dim=0)       # [B, T, H]\n",
    "        return mean_pooling(last4, attention_mask)     # [B, H]\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids=None,\n",
    "                attention_mask=None,\n",
    "                token_type_ids=None,\n",
    "                sentiment_labels=None,\n",
    "                polarization_labels=None):\n",
    "        outputs = self.encoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids if token_type_ids is not None else None,\n",
    "            output_hidden_states=(REP_POOLING != \"pooler\")  # needed for last4_mean/cls\n",
    "        )\n",
    "        pooled = self._pool(outputs, attention_mask)\n",
    "        z = self.trunk(pooled)\n",
    "        return {\"logits\": (self.head_sent(z), self.head_pol(z))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9qlyf0bb4Fr"
   },
   "source": [
    "## SECTION 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sw_XB5CqX_uB"
   },
   "outputs": [],
   "source": [
    "# SECTION 7\n",
    "\n",
    "def compute_metrics_multi(eval_pred):\n",
    "    (sent_logits, pol_logits) = eval_pred.predictions\n",
    "    (y_sent, y_pol) = eval_pred.label_ids\n",
    "\n",
    "    ps = np.argmax(sent_logits, axis=1)\n",
    "    pp = np.argmax(pol_logits, axis=1)\n",
    "\n",
    "    # Macro metrics\n",
    "    sent_report = classification_report(y_sent, ps, output_dict=True, zero_division=0)\n",
    "    pol_report  = classification_report(y_pol,  pp, output_dict=True, zero_division=0)\n",
    "\n",
    "    sent_f1 = sent_report[\"macro avg\"][\"f1-score\"]\n",
    "    pol_f1  = pol_report[\"macro avg\"][\"f1-score\"]\n",
    "    macro_f1_avg = (sent_f1 + pol_f1) / 2.0\n",
    "\n",
    "    return {\n",
    "        \"sent_acc\": sent_report[\"accuracy\"],\n",
    "        \"sent_prec\": sent_report[\"macro avg\"][\"precision\"],\n",
    "        \"sent_rec\": sent_report[\"macro avg\"][\"recall\"],\n",
    "        \"sent_f1\": sent_f1,\n",
    "\n",
    "        \"pol_acc\": pol_report[\"accuracy\"],\n",
    "        \"pol_prec\": pol_report[\"macro avg\"][\"precision\"],\n",
    "        \"pol_rec\": pol_report[\"macro avg\"][\"recall\"],\n",
    "        \"pol_f1\": pol_f1,\n",
    "\n",
    "        \"macro_f1_avg\": macro_f1_avg\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SStXGWDuZXHq"
   },
   "source": [
    "## SECTION 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nr4WH-IAYRd3"
   },
   "outputs": [],
   "source": [
    "# ===== Section 8 â€” Custom Trainer (R-Drop + LLRD + safe prediction_step) =====\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0, reduction=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    def forward(self, logits, target):\n",
    "        logp = F.log_softmax(logits, dim=1)\n",
    "        p = torch.exp(logp)\n",
    "        loss = F.nll_loss((1 - p) ** self.gamma * logp, target, weight=self.weight, reduction=\"none\")\n",
    "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
    "\n",
    "def _sym_kl_with_logits(logits1, logits2):\n",
    "    p = F.log_softmax(logits1, dim=-1);  q = F.log_softmax(logits2, dim=-1)\n",
    "    p_exp, q_exp = p.exp(), q.exp()\n",
    "    return 0.5 * (F.kl_div(p, q_exp, reduction=\"batchmean\") + F.kl_div(q, p_exp, reduction=\"batchmean\"))\n",
    "\n",
    "class MultiTaskTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, task_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights or {}\n",
    "        self.task_weights  = task_weights or {\"sentiment\": 1.0, \"polarization\": 1.0}\n",
    "        self._custom_train_sampler = None\n",
    "\n",
    "    # ----- LLRD optimizer -----\n",
    "    def create_optimizer(self):\n",
    "        if self.optimizer is not None:\n",
    "            return self.optimizer\n",
    "        if not USE_LLRD:\n",
    "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "            return self.optimizer\n",
    "\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\", \"LayerNorm.bias\"]\n",
    "        encoder = self.model.encoder\n",
    "        n_layers = getattr(encoder.config, \"num_hidden_layers\", 12)\n",
    "        # Try to access sequential layers\n",
    "        layers = getattr(getattr(encoder, \"encoder\", encoder), \"layer\", None)\n",
    "        if layers is None:\n",
    "            # Fallback: no LLRD if we can't find layers\n",
    "            self.optimizer = AdamW(self.get_decay_parameter_groups(self.model), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "            return self.optimizer\n",
    "\n",
    "        param_groups = []\n",
    "\n",
    "        # Embeddings (lowest lr)\n",
    "        emb = getattr(encoder, \"embeddings\", None)\n",
    "        if emb is not None:\n",
    "            lr_emb = LR * (LLRD_DECAY ** n_layers)\n",
    "            decay, nodecay = [], []\n",
    "            for n, p in emb.named_parameters():\n",
    "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
    "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_emb, \"weight_decay\": WEIGHT_DECAY})\n",
    "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_emb, \"weight_decay\": 0.0})\n",
    "\n",
    "        # Encoder blocks (increasing LR toward the top)\n",
    "        for i in range(n_layers):\n",
    "            block = layers[i]\n",
    "            lr_i = LR * (LLRD_DECAY ** (n_layers - 1 - i))\n",
    "            decay, nodecay = [], []\n",
    "            for n, p in block.named_parameters():\n",
    "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
    "            if decay:   param_groups.append({\"params\": decay,   \"lr\": lr_i, \"weight_decay\": WEIGHT_DECAY})\n",
    "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": lr_i, \"weight_decay\": 0.0})\n",
    "\n",
    "        # Pooler (if any)\n",
    "        pooler = getattr(encoder, \"pooler\", None)\n",
    "        if pooler is not None:\n",
    "            decay, nodecay = [], []\n",
    "            for n, p in pooler.named_parameters():\n",
    "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
    "            if decay:   param_groups.append({\"params\": decay,   \"lr\": LR, \"weight_decay\": WEIGHT_DECAY})\n",
    "            if nodecay: param_groups.append({\"params\": nodecay, \"lr\": LR, \"weight_decay\": 0.0})\n",
    "\n",
    "        # Heads/trunk (highest LR)\n",
    "        head_lr = LR * HEAD_LR_MULT\n",
    "        head_modules = [self.model.trunk, self.model.head_sent, self.model.head_pol]\n",
    "        decay, nodecay = [], []\n",
    "        for m in head_modules:\n",
    "            for n, p in m.named_parameters():\n",
    "                (nodecay if any(nd in n for nd in no_decay) else decay).append(p)\n",
    "        if decay:   param_groups.append({\"params\": decay,   \"lr\": head_lr, \"weight_decay\": WEIGHT_DECAY})\n",
    "        if nodecay: param_groups.append({\"params\": nodecay, \"lr\": head_lr, \"weight_decay\": 0.0})\n",
    "\n",
    "        self.optimizer = AdamW(param_groups, lr=LR)  # lr here is ignored per-group\n",
    "        return self.optimizer\n",
    "\n",
    "    def set_train_sampler(self, sampler):\n",
    "        self._custom_train_sampler = sampler\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        if self.train_dataset is None:\n",
    "            return None\n",
    "        if self._custom_train_sampler is not None:\n",
    "            return DataLoader(\n",
    "                self.train_dataset,\n",
    "                batch_size=self.args.train_batch_size,\n",
    "                sampler=self._custom_train_sampler,\n",
    "                collate_fn=self.data_collator,\n",
    "                drop_last=self.args.dataloader_drop_last,\n",
    "                num_workers=self.args.dataloader_num_workers,\n",
    "                pin_memory=self.args.dataloader_pin_memory,\n",
    "            )\n",
    "        return super().get_train_dataloader()\n",
    "\n",
    "    def _sent_loss_fn(self, weight, logits, target):\n",
    "        if USE_FOCAL_SENTIMENT:\n",
    "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_SENTIMENT)(logits, target)\n",
    "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_SENTIMENT))(logits, target)\n",
    "\n",
    "    def _pol_loss_fn(self, weight, logits, target):\n",
    "        if USE_FOCAL_POLARITY:\n",
    "            return FocalLoss(weight=weight, gamma=FOCAL_GAMMA_POLARITY)(logits, target)\n",
    "        return nn.CrossEntropyLoss(weight=weight, label_smoothing=float(LABEL_SMOOTH_POLARITY))(logits, target)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        y_sent = inputs.pop(\"sentiment_labels\")\n",
    "        y_pol  = inputs.pop(\"polarization_labels\")\n",
    "\n",
    "        # R-Drop with warmup: two forward passes with dropout\n",
    "        current_epoch = getattr(self.state, 'epoch', 0) if hasattr(self, 'state') else 0\n",
    "        use_rdrop_now = USE_RDROP and model.training and current_epoch >= RDROP_WARMUP_EPOCHS\n",
    "\n",
    "        if use_rdrop_now:\n",
    "            outputs1 = model(**inputs)\n",
    "            outputs2 = model(**inputs)\n",
    "            s1, p1 = outputs1[\"logits\"]\n",
    "            s2, p2 = outputs2[\"logits\"]\n",
    "\n",
    "            ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s1.device) if ws is not None else None\n",
    "            wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p1.device) if wp is not None else None\n",
    "\n",
    "            ce_s = 0.5 * (self._sent_loss_fn(ws, s1, y_sent) + self._sent_loss_fn(ws, s2, y_sent))\n",
    "            ce_p = 0.5 * (self._pol_loss_fn(wp,  p1, y_pol)  + self._pol_loss_fn(wp,  p2, y_pol))\n",
    "            kl_s = _sym_kl_with_logits(s1, s2)\n",
    "            kl_p = _sym_kl_with_logits(p1, p2)\n",
    "\n",
    "            w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
    "            w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
    "\n",
    "            # Gradual R-Drop alpha rampup for stability\n",
    "            rdrop_factor = min(1.0, (current_epoch - RDROP_WARMUP_EPOCHS + 1) / 2.0)\n",
    "            loss = w_s * ce_s + w_p * ce_p + (RDROP_ALPHA * rdrop_factor) * (kl_s + kl_p)\n",
    "            if return_outputs:\n",
    "                return loss, {\"logits\": (s1, p1)}\n",
    "            return loss\n",
    "\n",
    "        # Standard single forward\n",
    "        outputs = model(**inputs)\n",
    "        s, p = outputs[\"logits\"]\n",
    "\n",
    "        ws = self.class_weights.get(\"sentiment\", None); ws = ws.to(s.device) if ws is not None else None\n",
    "        wp = self.class_weights.get(\"polarization\", None); wp = wp.to(p.device) if wp is not None else None\n",
    "\n",
    "        loss_s = self._sent_loss_fn(ws, s, y_sent)\n",
    "        loss_p = self._pol_loss_fn(wp, p, y_pol)\n",
    "\n",
    "        w_s = float(self.task_weights.get(\"sentiment\", 1.0))\n",
    "        w_p = float(self.task_weights.get(\"polarization\", 1.0))\n",
    "        loss = w_s * loss_s + w_p * loss_p\n",
    "\n",
    "        if return_outputs:\n",
    "            outputs = dict(outputs); outputs[\"labels\"] = (y_sent, y_pol)\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        # Safe for inference (no labels provided)\n",
    "        y_sent = inputs.get(\"sentiment_labels\", None)\n",
    "        y_pol  = inputs.get(\"polarization_labels\", None)\n",
    "\n",
    "        model_inputs = {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"]}\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            model_inputs[\"token_type_ids\"] = inputs[\"token_type_ids\"]\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**model_inputs)\n",
    "            s, p = outputs[\"logits\"]\n",
    "\n",
    "        loss = None\n",
    "        logits = (s.detach(), p.detach())\n",
    "        labels = (y_sent, y_pol) if isinstance(y_sent, torch.Tensor) and isinstance(y_pol, torch.Tensor) else None\n",
    "        return (loss, logits, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mcQwt92ZfGI"
   },
   "source": [
    "## SECTION 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bV78nGSQYV3a",
    "outputId": "eff94926-1b0c-4734-91b8-f9e749300a43"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… SECTION 5-9: Model Architecture & Training Setup completed in 10.7s\n",
      "ðŸ•’ Total runtime so far: 56.5s\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ===== Section 9 â€” Train/Evaluate One Model (with grad accumulation) =====\nfrom transformers import AutoTokenizer, DataCollatorWithPadding\nimport math, json, numpy as np, pandas as pd, os\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import WeightedRandomSampler\nfrom collections import Counter\n\ndef train_eval_one_model(model_key: str,\n                         X_tr: pd.DataFrame, X_v: pd.DataFrame, X_te: pd.DataFrame,\n                         ysent_tr: np.ndarray, ysent_v: np.ndarray, ysent_te: np.ndarray,\n                         ypol_tr: np.ndarray,  ypol_v: np.ndarray,  ypol_te: np.ndarray,\n                         sent_w_np: np.ndarray, pol_w_np: np.ndarray):\n    base_name = MODEL_CONFIGS[model_key][\"name\"]\n    run_dir = os.path.join(OUT_DIR, f\"{model_key}\")\n    os.makedirs(run_dir, exist_ok=True)\n\n    tokenizer = AutoTokenizer.from_pretrained(base_name)\n    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n\n    tr_titles, tr_texts = X_tr[TITLE_COL].values, X_tr[TEXT_COL].values\n    v_titles,  v_texts  = X_v[TITLE_COL].values, X_v[TEXT_COL].values\n    te_titles, te_texts = X_te[TITLE_COL].values, X_te[TEXT_COL].values\n\n    train_ds = TaglishDataset(tr_titles, tr_texts, ysent_tr, ypol_tr, tokenizer, max_length=MAX_LENGTH)\n    val_ds   = TaglishDataset(v_titles,  v_texts,  ysent_v,  ypol_v,  tokenizer, max_length=MAX_LENGTH)\n    test_ds  = TaglishDataset(te_titles, te_texts, ysent_te, ypol_te, tokenizer, max_length=MAX_LENGTH)\n\n    model = MultiTaskModel(base_name, num_sent_classes, num_pol_classes).to(device)\n\n    sent_w = torch.tensor(sent_w_np, dtype=torch.float32)\n    pol_w  = torch.tensor(pol_w_np,  dtype=torch.float32)\n\n    args = make_training_args_compat(\n        output_dir=run_dir,\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE,\n        learning_rate=LR,\n        weight_decay=WEIGHT_DECAY,\n        warmup_ratio=WARMUP_RATIO,\n        lr_scheduler_type=LR_SCHEDULER_TYPE,  # ðŸ”¥ NEW FOR RUN #3 - Cosine annealing\n        lr_scheduler_kwargs={\"num_cycles\": NUM_CYCLES},  # Half-cosine decay\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"macro_f1_avg\",\n        greater_is_better=True,\n        fp16=torch.cuda.is_available(),\n        logging_dir=os.path.join(run_dir, \"logs\"),\n        logging_steps=25,                    # More frequent logging\n        logging_first_step=True,             # Log first step for debugging\n        save_steps=500,                      # Save checkpoints more often\n        eval_steps=None,                     # Eval at end of each epoch\n        report_to=\"none\",\n        seed=42,\n        remove_unused_columns=False,\n        eval_accumulation_steps=1,\n        gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n        dataloader_pin_memory=True,          # Performance optimization\n        max_grad_norm=MAX_GRAD_NORM,         # Built-in gradient clipping\n        label_smoothing_factor=0.0,          # We handle this in loss functions\n        save_total_limit=3,                  # Keep only 3 best checkpoints\n        prediction_loss_only=False           # Log all metrics\n    )\n\n    callbacks = get_early_stopping_callbacks(EARLY_STOP_PATIENCE)\n\n    trainer = MultiTaskTrainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        data_collator=collator,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics_multi,\n        callbacks=callbacks,\n        class_weights={\"sentiment\": sent_w, \"polarization\": pol_w},\n        task_weights=TASK_LOSS_WEIGHTS\n    )\n\n    # ----- ENHANCED JOINT oversampling with objective + neutral boost -----\n    if USE_OVERSAMPLING and USE_JOINT_OVERSAMPLING:\n        pair_counts = Counter(zip(ysent_tr.tolist(), ypol_tr.tolist()))\n        counts = np.array(list(pair_counts.values()), dtype=np.float32)\n        med = float(np.median(counts)) if len(counts) else 1.0\n\n        # Find objective class index (polarization)\n        obj_idx = np.where(pol_le.classes_ == \"objective\")[0][0] if \"objective\" in pol_le.classes_ else 1\n\n        # ðŸ”¥ NEW: Find neutral class index (sentiment)\n        neutral_idx = np.where(sent_le.classes_ == \"neutral\")[0][0] if \"neutral\" in sent_le.classes_ else 1\n\n        def inv_mult(c):\n            if c <= 0: return JOINT_OVERSAMPLING_MAX_MULT\n            return float(np.clip(med / float(c), 1.0, JOINT_OVERSAMPLING_MAX_MULT))\n\n        inv_by_pair = {k: inv_mult(v) for k, v in pair_counts.items()}\n        sample_weights = []\n\n        for ys, yp in zip(ysent_tr, ypol_tr):\n            inv = inv_by_pair.get((int(ys), int(yp)), 1.0)\n            w = (1.0 - JOINT_ALPHA) * 1.0 + JOINT_ALPHA * inv\n\n            # Smart oversampling: extra boost for objective class (polarization)\n            if USE_SMART_OVERSAMPLING and int(yp) == obj_idx:\n                w *= OBJECTIVE_BOOST_MULT\n\n            # ðŸ”¥ NEW: Also boost neutral class (sentiment) - Fixes 49% F1!\n            if USE_SMART_OVERSAMPLING and int(ys) == neutral_idx:\n                w *= NEUTRAL_BOOST_MULT\n\n            sample_weights.append(w)\n\n        obj_boost_count = sum(1 for i, yp in enumerate(ypol_tr) if int(yp) == obj_idx and sample_weights[i] > 2.0)\n        neutral_boost_count = sum(1 for i, ys in enumerate(ysent_tr) if int(ys) == neutral_idx and sample_weights[i] > 2.0)\n        print(f\"ðŸ”¥ Enhanced Oversampling: min={min(sample_weights):.2f}, max={max(sample_weights):.2f}\")\n        print(f\"   â”œâ”€ Objective boosted samples: {obj_boost_count} (target: stabilize objective ~52% F1)\")\n        print(f\"   â””â”€ Neutral boosted samples: {neutral_boost_count} (target: keep neutral â‰¥74% F1)\")\n        trainer.set_train_sampler(WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True))\n\n    trainer.train()\n\n    # Test\n    test_out = trainer.predict(test_ds)\n    metrics = {f\"test_{k}\": float(v) for k, v in test_out.metrics.items()}\n    trainer.save_model()\n    # Fallback: ensure weights exist for calibration even if HF skip saving\n    model_path = os.path.join(run_dir, \"pytorch_model.bin\")\n    if not os.path.exists(model_path):\n        torch.save(trainer.model.state_dict(), model_path)\n    tokenizer.save_pretrained(run_dir)\n    with open(os.path.join(run_dir, \"metrics_test.json\"), \"w\") as f:\n        json.dump(metrics, f, indent=2)\n\n    sent_logits, pol_logits = test_out.predictions\n    ysent_pred = np.argmax(sent_logits, axis=1)\n    ypol_pred  = np.argmax(pol_logits,  axis=1)\n\n    cm_sent = confusion_matrix(ysent_te, ysent_pred, labels=list(range(num_sent_classes)))\n    cm_pol  = confusion_matrix(ypol_te,  ypol_pred,  labels=list(range(num_pol_classes)))\n    np.save(os.path.join(run_dir, \"cm_sent.npy\"), cm_sent)\n    np.save(os.path.join(run_dir, \"cm_pol.npy\"),  cm_pol)\n\n    def plot_cm(cm, labels, title, path_png):\n        fig, ax = plt.subplots(figsize=(4.5, 4))\n        im = ax.imshow(cm, interpolation=\"nearest\")\n        ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n        ax.set_xticks(range(len(labels))); ax.set_xticklabels(labels, rotation=45, ha=\"right\")\n        ax.set_yticks(range(len(labels))); ax.set_yticklabels(labels)\n        for i in range(cm.shape[0]):\n            for j in range(cm.shape[1]):\n                ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n        fig.colorbar(im, ax=ax, fraction=0.046); plt.tight_layout(); plt.savefig(path_png, dpi=160); plt.close(fig)\n\n    plot_cm(cm_sent, sent_le.classes_, \"Sentiment Confusion\", os.path.join(run_dir, \"cm_sent.png\"))\n    plot_cm(cm_pol,  pol_le.classes_,  \"Polarization Confusion\", os.path.join(run_dir, \"cm_pol.png\"))\n\n    rep_sent = classification_report(ysent_te, ysent_pred, target_names=sent_le.classes_, digits=4, zero_division=0)\n    rep_pol  = classification_report(ypol_te,  ypol_pred,  target_names=pol_le.classes_,  digits=4, zero_division=0)\n    with open(os.path.join(run_dir, \"report_sentiment.txt\"), \"w\") as f: f.write(rep_sent)\n    with open(os.path.join(run_dir, \"report_polarization.txt\"), \"w\") as f: f.write(rep_pol)\n\n    return {\"model_key\": model_key, \"base_name\": base_name, **metrics}, (ysent_pred, ypol_pred)\n\n# End timing for architecture setup\ntimer.end_section(\"SECTION 5-9: Model Architecture & Training Setup\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKEIn9Gebyw-"
   },
   "source": [
    "## SECTION 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ac98b5d3dc1144c09f0f9fb24c789d44",
      "342e71f582ff4a66845b483a11bac671",
      "59fb778f256f444a850f634b1646314d",
      "0175eefc9bf647deae27658864c1f865",
      "2445b9bab3b34857a63a5c9cd90676a5",
      "a58712652de141bca5fc836c014a201e",
      "26734b469d464ee68e56c85549cb182d",
      "e8bbd9bbcf1144109d4dfc61c2d06f37",
      "7df97acc02fe4fb9b951d09bfaa527de",
      "e8e8485a3c4b4a22b3c0847826012d5e",
      "57d43ceae54f4752992836b266341d8a",
      "d18c4daa45984195aaa14c98f4f8c3ae",
      "c6c84ce403764b25a455d0400097ca83",
      "8e39c02a48924536b5252c845a26fb95",
      "e90196b7d3444476aafde2870d2f67ea",
      "1742957ba814493a9650bdc3b2d582f6",
      "f1b6669197b345c4827af28464b424ef",
      "c5a5e22fb5e340a7929e03e9926f30f1",
      "859091769b32452dbcd6165ead4062d7",
      "859f1205c3a74c238519032470ce2104",
      "4a4f67fb284d4431b0afc0b1a38d5f46",
      "48ef93b086154b2d91e91426398aa6ff",
      "50cb9220a0e44eabb44e15a3baba8f82",
      "791c40444fc84dc18716ca8006383a6f",
      "f3fbbbc76f454fd1883b6ac017d8006c",
      "54d3b412dbde40d69e357857184256fc",
      "59a2cea8fe86442da9b31ea111bac610",
      "b4f568cd8e5843ae952f5f79177963c4",
      "91c0b0d7d49b4b188b06cd8e67fda2f2",
      "00a2142c74cd422185a5d398eff22a27",
      "78d74012e21647abac53ccbffa617f68",
      "b14114509df54190a045630f155a5cdb",
      "e18ea15456fa4edb8131e94d1b3f69a4",
      "e31832b374494c88b83dc4aa965d2438",
      "f2f13a6a184d42d5a9af4e30d35e5dd3",
      "5783152de22c425fa3b1784682e3fef9",
      "75382b27edc24f2b9ff8b5d20c4438ac",
      "a7dd8dee3c584dab8f35df96907a6e9d",
      "7ef3e6ba26cb4d06b393ead22b29a311",
      "0dafe1bb25c24009bffd4c0b9d3dcbd4",
      "caef5d45c572400a98552764d6966dc2",
      "ad5cdcd75d6a48ce8cd258716393b3cf",
      "d41e42c58584426a92b573544073a6ca",
      "9c38aa92b909431c9f015707b6b3bbf2",
      "ba7202fa4a9d46da951e5104a0378423",
      "5e3b9f486192429aa1d1ac6f3e3feb96",
      "f1cd618b11704d55a6463e75817212f7",
      "82072ff4bf4a4c32994a360d8f3f6c22",
      "39c0907358fa44ac97d57e36abe602dd",
      "6c3c61a9faa148b0b9d7b23c6bb17b95",
      "04e8057c90de4fa6941bc92fac914900",
      "0ed7000438394f0eb0a9c74adb6a5aa4",
      "fca038edd904435eba922ad7a20ad5e3",
      "2aaffdef901f4b9cb39811e6a0c156fb",
      "d2870ead377f495c9ca51fbbd5b96730"
     ]
    },
    "id": "24dStZjrYaW7",
    "outputId": "e863b514-15f2-471a-f053-445e2bafcf01"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš€ Starting SECTION 10: Model Training Execution...\n",
      "\n",
      "=== Running xlm_roberta -> xlm-roberta-base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac98b5d3dc1144c09f0f9fb24c789d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18c4daa45984195aaa14c98f4f8c3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cb9220a0e44eabb44e15a3baba8f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31832b374494c88b83dc4aa965d2438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7202fa4a9d46da951e5104a0378423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Enhanced Oversampling: min=0.80, max=5.57\n",
      "   â”œâ”€ Objective boosted samples: 168 (target: weak class at 40% F1)\n",
      "   â””â”€ Neutral boosted samples: 0 (target: weak class at 49% F1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1566' max='2736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1566/2736 39:49 < 29:47, 0.65 it/s, Epoch 10.25/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sent Acc</th>\n",
       "      <th>Sent Prec</th>\n",
       "      <th>Sent Rec</th>\n",
       "      <th>Sent F1</th>\n",
       "      <th>Pol Acc</th>\n",
       "      <th>Pol Prec</th>\n",
       "      <th>Pol Rec</th>\n",
       "      <th>Pol F1</th>\n",
       "      <th>Macro F1 Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.279600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367534</td>\n",
       "      <td>0.474515</td>\n",
       "      <td>0.482856</td>\n",
       "      <td>0.339291</td>\n",
       "      <td>0.143951</td>\n",
       "      <td>0.430584</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.123606</td>\n",
       "      <td>0.231449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.035900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559469</td>\n",
       "      <td>0.550479</td>\n",
       "      <td>0.622073</td>\n",
       "      <td>0.525183</td>\n",
       "      <td>0.374170</td>\n",
       "      <td>0.473673</td>\n",
       "      <td>0.487131</td>\n",
       "      <td>0.365398</td>\n",
       "      <td>0.445291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.656457</td>\n",
       "      <td>0.621253</td>\n",
       "      <td>0.704262</td>\n",
       "      <td>0.640881</td>\n",
       "      <td>0.464523</td>\n",
       "      <td>0.499845</td>\n",
       "      <td>0.534101</td>\n",
       "      <td>0.434867</td>\n",
       "      <td>0.537874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.650842</td>\n",
       "      <td>0.617073</td>\n",
       "      <td>0.707545</td>\n",
       "      <td>0.632411</td>\n",
       "      <td>0.503318</td>\n",
       "      <td>0.516408</td>\n",
       "      <td>0.565323</td>\n",
       "      <td>0.468859</td>\n",
       "      <td>0.550635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.668373</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.677682</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.554462</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>0.557105</td>\n",
       "      <td>0.617394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.726672</td>\n",
       "      <td>0.713561</td>\n",
       "      <td>0.643696</td>\n",
       "      <td>0.579091</td>\n",
       "      <td>0.618776</td>\n",
       "      <td>0.592137</td>\n",
       "      <td>0.652849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.727922</td>\n",
       "      <td>0.716016</td>\n",
       "      <td>0.746756</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.630424</td>\n",
       "      <td>0.585796</td>\n",
       "      <td>0.635901</td>\n",
       "      <td>0.597283</td>\n",
       "      <td>0.663410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2736' max='2736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2736/2736 1:20:24, Epoch 17/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sent Acc</th>\n",
       "      <th>Sent Prec</th>\n",
       "      <th>Sent Rec</th>\n",
       "      <th>Sent F1</th>\n",
       "      <th>Pol Acc</th>\n",
       "      <th>Pol Prec</th>\n",
       "      <th>Pol Rec</th>\n",
       "      <th>Pol F1</th>\n",
       "      <th>Macro F1 Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.279600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.367534</td>\n",
       "      <td>0.474515</td>\n",
       "      <td>0.482856</td>\n",
       "      <td>0.339291</td>\n",
       "      <td>0.143951</td>\n",
       "      <td>0.430584</td>\n",
       "      <td>0.353518</td>\n",
       "      <td>0.123606</td>\n",
       "      <td>0.231449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.035900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.559469</td>\n",
       "      <td>0.550479</td>\n",
       "      <td>0.622073</td>\n",
       "      <td>0.525183</td>\n",
       "      <td>0.374170</td>\n",
       "      <td>0.473673</td>\n",
       "      <td>0.487131</td>\n",
       "      <td>0.365398</td>\n",
       "      <td>0.445291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.656457</td>\n",
       "      <td>0.621253</td>\n",
       "      <td>0.704262</td>\n",
       "      <td>0.640881</td>\n",
       "      <td>0.464523</td>\n",
       "      <td>0.499845</td>\n",
       "      <td>0.534101</td>\n",
       "      <td>0.434867</td>\n",
       "      <td>0.537874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.650842</td>\n",
       "      <td>0.617073</td>\n",
       "      <td>0.707545</td>\n",
       "      <td>0.632411</td>\n",
       "      <td>0.503318</td>\n",
       "      <td>0.516408</td>\n",
       "      <td>0.565323</td>\n",
       "      <td>0.468859</td>\n",
       "      <td>0.550635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.668373</td>\n",
       "      <td>0.714469</td>\n",
       "      <td>0.677682</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.554462</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>0.557105</td>\n",
       "      <td>0.617394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.726672</td>\n",
       "      <td>0.713561</td>\n",
       "      <td>0.643696</td>\n",
       "      <td>0.579091</td>\n",
       "      <td>0.618776</td>\n",
       "      <td>0.592137</td>\n",
       "      <td>0.652849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.727922</td>\n",
       "      <td>0.716016</td>\n",
       "      <td>0.746756</td>\n",
       "      <td>0.729537</td>\n",
       "      <td>0.630424</td>\n",
       "      <td>0.585796</td>\n",
       "      <td>0.635901</td>\n",
       "      <td>0.597283</td>\n",
       "      <td>0.663410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.718224</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0.731404</td>\n",
       "      <td>0.723807</td>\n",
       "      <td>0.641143</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.618299</td>\n",
       "      <td>0.593071</td>\n",
       "      <td>0.658439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.729454</td>\n",
       "      <td>0.723231</td>\n",
       "      <td>0.743930</td>\n",
       "      <td>0.732293</td>\n",
       "      <td>0.644717</td>\n",
       "      <td>0.598754</td>\n",
       "      <td>0.633014</td>\n",
       "      <td>0.606822</td>\n",
       "      <td>0.669558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.206000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.726901</td>\n",
       "      <td>0.731850</td>\n",
       "      <td>0.738112</td>\n",
       "      <td>0.733204</td>\n",
       "      <td>0.652884</td>\n",
       "      <td>0.598919</td>\n",
       "      <td>0.631183</td>\n",
       "      <td>0.610456</td>\n",
       "      <td>0.671830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.740684</td>\n",
       "      <td>0.745219</td>\n",
       "      <td>0.748670</td>\n",
       "      <td>0.746687</td>\n",
       "      <td>0.661562</td>\n",
       "      <td>0.610312</td>\n",
       "      <td>0.631037</td>\n",
       "      <td>0.618586</td>\n",
       "      <td>0.682637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.741194</td>\n",
       "      <td>0.746656</td>\n",
       "      <td>0.749003</td>\n",
       "      <td>0.747436</td>\n",
       "      <td>0.658499</td>\n",
       "      <td>0.606849</td>\n",
       "      <td>0.630377</td>\n",
       "      <td>0.615617</td>\n",
       "      <td>0.681526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.741705</td>\n",
       "      <td>0.747055</td>\n",
       "      <td>0.749379</td>\n",
       "      <td>0.747807</td>\n",
       "      <td>0.661052</td>\n",
       "      <td>0.608669</td>\n",
       "      <td>0.633082</td>\n",
       "      <td>0.617962</td>\n",
       "      <td>0.682885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… SECTION 10: Model Training Execution completed in 1.3h 21m\n",
      "ðŸ•’ Total runtime so far: 1.4h 22m\n",
      "------------------------------------------------------------\n",
      "\n",
      "ðŸš€ Starting SECTION 11+: Evaluation & Calibration...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     model_key         base_name  test_test_sent_acc  test_test_sent_prec  \\\n",
       "0  xlm_roberta  xlm-roberta-base            0.737755             0.748172   \n",
       "\n",
       "   test_test_sent_rec  test_test_sent_f1  test_test_pol_acc  \\\n",
       "0            0.722215           0.733459           0.672959   \n",
       "\n",
       "   test_test_pol_prec  test_test_pol_rec  test_test_pol_f1  \\\n",
       "0            0.613639           0.640367          0.622521   \n",
       "\n",
       "   test_test_macro_f1_avg  test_test_runtime  test_test_samples_per_second  \\\n",
       "0                 0.67799             4.2005                       466.615   \n",
       "\n",
       "   test_test_steps_per_second  \n",
       "0                      23.331  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-0ec3e614-ccb0-4073-be6b-3832196bf56a\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_key</th>\n",
       "      <th>base_name</th>\n",
       "      <th>test_test_sent_acc</th>\n",
       "      <th>test_test_sent_prec</th>\n",
       "      <th>test_test_sent_rec</th>\n",
       "      <th>test_test_sent_f1</th>\n",
       "      <th>test_test_pol_acc</th>\n",
       "      <th>test_test_pol_prec</th>\n",
       "      <th>test_test_pol_rec</th>\n",
       "      <th>test_test_pol_f1</th>\n",
       "      <th>test_test_macro_f1_avg</th>\n",
       "      <th>test_test_runtime</th>\n",
       "      <th>test_test_samples_per_second</th>\n",
       "      <th>test_test_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>xlm-roberta-base</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>0.748172</td>\n",
       "      <td>0.722215</td>\n",
       "      <td>0.733459</td>\n",
       "      <td>0.672959</td>\n",
       "      <td>0.613639</td>\n",
       "      <td>0.640367</td>\n",
       "      <td>0.622521</td>\n",
       "      <td>0.67799</td>\n",
       "      <td>4.2005</td>\n",
       "      <td>466.615</td>\n",
       "      <td>23.331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ec3e614-ccb0-4073-be6b-3832196bf56a')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-0ec3e614-ccb0-4073-be6b-3832196bf56a button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-0ec3e614-ccb0-4073-be6b-3832196bf56a');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "  <div id=\"id_031f992b-81c7-4b71-8baa-77d947334eca\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_031f992b-81c7-4b71-8baa-77d947334eca button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('results_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "results_df",
       "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"model_key\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"xlm_roberta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"xlm-roberta-base\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7377551020408163,\n        \"max\": 0.7377551020408163,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7377551020408163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7481724664283004,\n        \"max\": 0.7481724664283004,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7481724664283004\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7222149509667299,\n        \"max\": 0.7222149509667299,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7222149509667299\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_sent_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7334589675275139,\n        \"max\": 0.7334589675275139,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7334589675275139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_acc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6729591836734694,\n        \"max\": 0.6729591836734694,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6729591836734694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_prec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6136389719019296,\n        \"max\": 0.6136389719019296,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6136389719019296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_rec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6403670377329972,\n        \"max\": 0.6403670377329972,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6403670377329972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_pol_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.622520730610202,\n        \"max\": 0.622520730610202,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.622520730610202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_macro_f1_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.677989849068858,\n        \"max\": 0.677989849068858,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.677989849068858\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4.2005,\n        \"max\": 4.2005,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.2005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_samples_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 466.615,\n        \"max\": 466.615,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          466.615\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"test_test_steps_per_second\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 23.331,\n        \"max\": 23.331,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          23.331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# SECTION 10\n",
    "\n",
    "timer.start_section(\"SECTION 10: Model Training Execution\")\n",
    "\n",
    "results = []\n",
    "pred_cache = {}\n",
    "\n",
    "for key in MODELS_TO_RUN:\n",
    "    print(f\"\\n=== Running {key} -> {MODEL_CONFIGS[key]['name']} ===\")\n",
    "    row, preds = train_eval_one_model(\n",
    "        key,\n",
    "        X_train, X_val, X_test,\n",
    "        ysent_train, ysent_val, ysent_test,\n",
    "        ypol_train,  ypol_val,  ypol_test,\n",
    "        sent_weights_np, pol_weights_np\n",
    "    )\n",
    "    results.append(row)\n",
    "    pred_cache[key] = preds\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(OUT_DIR, \"summary_results.csv\"), index=False)\n",
    "\n",
    "# End timing for training execution\n",
    "timer.end_section(\"SECTION 10: Model Training Execution\")\n",
    "timer.start_section(\"SECTION 11+: Evaluation & Calibration\")\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSS37GWDbBw2"
   },
   "source": [
    "### SECTION 10A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "QlNuczl4bDPJ"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 10A â€” VERIFY ARTIFACTS & RESOLVE TOKENIZER + WEIGHTS (v2)\n",
    "# Builds maps for: tokenizer_dir (usually run root) and weights_dir (checkpoint or run root).\n",
    "# Run AFTER Section 10 (training) and BEFORE 11B/11C.\n",
    "# ============================================================================\n",
    "\n",
    "import os, re, json\n",
    "from typing import Optional, Dict\n",
    "\n",
    "def _has_weights(path: str) -> bool:\n",
    "    return os.path.isfile(os.path.join(path, \"pytorch_model.bin\")) or os.path.isfile(os.path.join(path, \"model.safetensors\"))\n",
    "\n",
    "def _has_tokenizer(path: str) -> bool:\n",
    "    # Minimal tokenizer files\n",
    "    return (\n",
    "        os.path.isfile(os.path.join(path, \"tokenizer.json\")) or\n",
    "        os.path.isfile(os.path.join(path, \"vocab.txt\")) or\n",
    "        os.path.isfile(os.path.join(path, \"spiece.model\"))\n",
    "    )\n",
    "\n",
    "def _list_checkpoints(run_dir: str):\n",
    "    if not os.path.isdir(run_dir): return []\n",
    "    chks = []\n",
    "    for name in os.listdir(run_dir):\n",
    "        p = os.path.join(run_dir, name)\n",
    "        if os.path.isdir(p) and re.match(r\"^checkpoint-\\d+$\", name):\n",
    "            chks.append(p)\n",
    "    # sort by gl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JZdHWRfbvzP"
   },
   "source": [
    "## SECTION 11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "id": "t1I1V0MJbyH2",
    "outputId": "844b385b-8d7f-4e7f-d423-a9ea7198b629"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== Detailed breakdowns for xlm_roberta ===\n",
      "\n",
      "Sentiment â€” per class (precision/recall/F1/support):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      class  precision    recall        f1  support\n",
       "0  negative   0.723780  0.786682  0.753921      886\n",
       "1   neutral   0.746012  0.702079  0.723379      866\n",
       "2  positive   0.774725  0.677885  0.723077      208"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-96c5b441-7fac-4e87-b4e4-e8e8f0102d77\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0.723780</td>\n",
       "      <td>0.786682</td>\n",
       "      <td>0.753921</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.746012</td>\n",
       "      <td>0.702079</td>\n",
       "      <td>0.723379</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.774725</td>\n",
       "      <td>0.677885</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96c5b441-7fac-4e87-b4e4-e8e8f0102d77')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-96c5b441-7fac-4e87-b4e4-e8e8f0102d77 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-96c5b441-7fac-4e87-b4e4-e8e8f0102d77');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-1a11afde-39e3-4fbf-806f-d4694dbe4ef8\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a11afde-39e3-4fbf-806f-d4694dbe4ef8')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-1a11afde-39e3-4fbf-806f-d4694dbe4ef8 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_54094dc5-463b-44aa-a921-24dd3a992ab3\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_per_class')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_54094dc5-463b-44aa-a921-24dd3a992ab3 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('sent_per_class');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "sent_per_class",
       "summary": "{\n  \"name\": \"sent_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02554131543316221,\n        \"min\": 0.7237798546209762,\n        \"max\": 0.7747252747252747,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7237798546209762,\n          0.7460122699386503,\n          0.7747252747252747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05712538037471354,\n        \"min\": 0.6778846153846154,\n        \"max\": 0.7866817155756207,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7866817155756207,\n          0.7020785219399538,\n          0.6778846153846154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017721316598632457,\n        \"min\": 0.7230769230769231,\n        \"max\": 0.7539210383991347,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7539210383991347,\n          0.7233789411064843,\n          0.7230769230769231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 385,\n        \"min\": 208,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          866,\n          208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Polarization â€” per class (precision/recall/F1/support):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "           class  precision    recall        f1  support\n",
       "0  non_polarized   0.558862  0.672897  0.610601      642\n",
       "1      objective   0.470852  0.555556  0.509709      189\n",
       "2       partisan   0.811203  0.692648  0.747253     1129"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-09daec74-34cd-4ae4-bea1-47453e84b1be\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non_polarized</td>\n",
       "      <td>0.558862</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.610601</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>objective</td>\n",
       "      <td>0.470852</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>partisan</td>\n",
       "      <td>0.811203</td>\n",
       "      <td>0.692648</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09daec74-34cd-4ae4-bea1-47453e84b1be')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-09daec74-34cd-4ae4-bea1-47453e84b1be button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-09daec74-34cd-4ae4-bea1-47453e84b1be');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-fba15cb4-e174-4f73-818e-abc1a327b2b9\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fba15cb4-e174-4f73-818e-abc1a327b2b9')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-fba15cb4-e174-4f73-818e-abc1a327b2b9 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_f34ac12f-ec53-4dea-bd23-a669568a5d9a\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_per_class')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_f34ac12f-ec53-4dea-bd23-a669568a5d9a button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pol_per_class');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "pol_per_class",
       "summary": "{\n  \"name\": \"pol_per_class\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"non_polarized\",\n          \"objective\",\n          \"partisan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17666401517949626,\n        \"min\": 0.47085201793721976,\n        \"max\": 0.8112033195020747,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5588615782664942,\n          0.47085201793721976,\n          0.8112033195020747\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0741098358030225,\n        \"min\": 0.5555555555555556,\n        \"max\": 0.6926483613817538,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6728971962616822,\n          0.5555555555555556,\n          0.6926483613817538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11921977321895694,\n        \"min\": 0.5097087378640777,\n        \"max\": 0.7472527472527473,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.610600706713781,\n          0.5097087378640777,\n          0.7472527472527473\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 470,\n        \"min\": 189,\n        \"max\": 1129,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          642,\n          189,\n          1129\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Polarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "      slice  support  accuracy  macro_f1  f1_non_polarized  f1_objective  \\\n",
       "0  negative      886  0.790068  0.644438          0.572165      0.492308   \n",
       "1   neutral      866  0.538106  0.518026          0.619266      0.515337   \n",
       "2  positive      208  0.735577  0.647529          0.658065      0.476190   \n",
       "\n",
       "   f1_partisan  \n",
       "0     0.868840  \n",
       "1     0.419476  \n",
       "2     0.808333  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-e69f52cb-0687-446e-ab0d-abb369b7f9ed\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>f1_non_polarized</th>\n",
       "      <th>f1_objective</th>\n",
       "      <th>f1_partisan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>886</td>\n",
       "      <td>0.790068</td>\n",
       "      <td>0.644438</td>\n",
       "      <td>0.572165</td>\n",
       "      <td>0.492308</td>\n",
       "      <td>0.868840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>866</td>\n",
       "      <td>0.538106</td>\n",
       "      <td>0.518026</td>\n",
       "      <td>0.619266</td>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.419476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>208</td>\n",
       "      <td>0.735577</td>\n",
       "      <td>0.647529</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e69f52cb-0687-446e-ab0d-abb369b7f9ed')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e69f52cb-0687-446e-ab0d-abb369b7f9ed button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e69f52cb-0687-446e-ab0d-abb369b7f9ed');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-6d3fb7db-c13d-4abf-8daa-a3fb44235b3f\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d3fb7db-c13d-4abf-8daa-a3fb44235b3f')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-6d3fb7db-c13d-4abf-8daa-a3fb44235b3f button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_1582fd13-1f67-4aec-b7ed-c21c8a976ce7\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pol_given_sent')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_1582fd13-1f67-4aec-b7ed-c21c8a976ce7 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('pol_given_sent');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "pol_given_sent",
       "summary": "{\n  \"name\": \"pol_given_sent\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"neutral\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 385,\n        \"min\": 208,\n        \"max\": 886,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          886,\n          866,\n          208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13256979864021112,\n        \"min\": 0.5381062355658198,\n        \"max\": 0.7900677200902935,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7900677200902935,\n          0.5381062355658198,\n          0.7355769230769231\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07389225210491773,\n        \"min\": 0.5180263779298223,\n        \"max\": 0.6475294418842806,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6444375570291018,\n          0.5180263779298223,\n          0.6475294418842806\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_non_polarized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04301660638920363,\n        \"min\": 0.5721649484536082,\n        \"max\": 0.6580645161290323,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5721649484536082,\n          0.6192660550458715,\n          0.6580645161290323\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_objective\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019674927507469443,\n        \"min\": 0.47619047619047616,\n        \"max\": 0.5153374233128835,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.49230769230769234,\n          0.5153374233128835,\n          0.47619047619047616\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_partisan\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24385777804211323,\n        \"min\": 0.41947565543071164,\n        \"max\": 0.8688400303260045,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8688400303260045,\n          0.41947565543071164,\n          0.8083333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Sentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "           slice  support  accuracy  macro_f1  f1_negative  f1_neutral  \\\n",
       "0       partisan     1129  0.775022  0.745098     0.833807    0.649351   \n",
       "1  non_polarized      642  0.697819  0.670177     0.528409    0.770000   \n",
       "2      objective      189  0.650794  0.545580     0.382022    0.754717   \n",
       "\n",
       "   f1_positive  \n",
       "0     0.752137  \n",
       "1     0.712121  \n",
       "2     0.500000  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-f8d9f886-323d-4182-8c6a-afb93b0563e3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>f1_negative</th>\n",
       "      <th>f1_neutral</th>\n",
       "      <th>f1_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>partisan</td>\n",
       "      <td>1129</td>\n",
       "      <td>0.775022</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.833807</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.752137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non_polarized</td>\n",
       "      <td>642</td>\n",
       "      <td>0.697819</td>\n",
       "      <td>0.670177</td>\n",
       "      <td>0.528409</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>objective</td>\n",
       "      <td>189</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.545580</td>\n",
       "      <td>0.382022</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8d9f886-323d-4182-8c6a-afb93b0563e3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f8d9f886-323d-4182-8c6a-afb93b0563e3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f8d9f886-323d-4182-8c6a-afb93b0563e3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-dadcfb60-f518-45a7-8540-ca817ba92e03\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dadcfb60-f518-45a7-8540-ca817ba92e03')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-dadcfb60-f518-45a7-8540-ca817ba92e03 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_1ba19794-44be-418f-9cce-0d89550eba33\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sent_given_pol')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_1ba19794-44be-418f-9cce-0d89550eba33 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('sent_given_pol');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "sent_given_pol",
       "summary": "{\n  \"name\": \"sent_given_pol\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"slice\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"partisan\",\n          \"non_polarized\",\n          \"objective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 470,\n        \"min\": 189,\n        \"max\": 1129,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1129,\n          642,\n          189\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06272214951681596,\n        \"min\": 0.6507936507936508,\n        \"max\": 0.775022143489814,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.775022143489814,\n          0.6978193146417445,\n          0.6507936507936508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macro_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10078453607220561,\n        \"min\": 0.5455798176807293,\n        \"max\": 0.7450980732230733,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7450980732230733,\n          0.6701767676767677,\n          0.5455798176807293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_negative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23050882469783085,\n        \"min\": 0.38202247191011235,\n        \"max\": 0.8338068181818182,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8338068181818182,\n          0.5284090909090909,\n          0.38202247191011235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06569107036081959,\n        \"min\": 0.6493506493506493,\n        \"max\": 0.77,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.6493506493506493,\n          0.77,\n          0.7547169811320755\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13550497767768382,\n        \"min\": 0.5,\n        \"max\": 0.7521367521367521,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7521367521367521,\n          0.7121212121212122,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Saved detailed breakdowns to: ./runs_xlm_roberta_run13/details\n"
     ]
    }
   ],
   "source": [
    "# ===== Section 11 â€” Detailed Breakdown Reports (per-class + cross-slices) =====\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "def per_class_breakdown(y_true, y_pred, class_names):\n",
    "    rep = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=list(class_names),\n",
    "        output_dict=True, zero_division=0\n",
    "    )\n",
    "    # Keep only the class rows in the given order\n",
    "    rows = []\n",
    "    for cname in class_names:\n",
    "        if cname in rep:\n",
    "            rows.append({\n",
    "                \"class\": cname,\n",
    "                \"precision\": rep[cname][\"precision\"],\n",
    "                \"recall\":    rep[cname][\"recall\"],\n",
    "                \"f1\":        rep[cname][\"f1-score\"],\n",
    "                \"support\":   int(rep[cname][\"support\"]),\n",
    "            })\n",
    "        else:\n",
    "            rows.append({\"class\": cname, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"support\": 0})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def cross_slice_breakdown(\n",
    "    slice_true,  # array of ints for the slicing label (e.g., true sentiment indices)\n",
    "    slice_names, # names of the slicing label classes (e.g., sentiment class names)\n",
    "    task_true,   # array of ints for the task we evaluate (e.g., true polarity indices)\n",
    "    task_pred,   # array of ints for the task predictions (e.g., predicted polarity indices)\n",
    "    task_names,  # names of the task classes (e.g., polarity class names)\n",
    "    slice_label  # string for the slice axis name, e.g., \"sentiment\" or \"polarity\"\n",
    "):\n",
    "    \"\"\"\n",
    "    For each class s in slice_true, evaluate the task predictions on the subset where slice_true == s.\n",
    "    Returns one row per slice value, including macro-F1, accuracy, and per-class F1 for the task.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for idx, sname in enumerate(slice_names):\n",
    "        mask = (slice_true == idx)\n",
    "        n = int(mask.sum())\n",
    "        if n == 0:\n",
    "            # No samples for this slice in test set\n",
    "            row = {\"slice\": sname, \"support\": 0, \"accuracy\": np.nan, \"macro_f1\": np.nan}\n",
    "            for tname in task_names:\n",
    "                row[f\"f1_{tname}\"] = np.nan\n",
    "            rows.append(row)\n",
    "            continue\n",
    "\n",
    "        rep = classification_report(\n",
    "            task_true[mask], task_pred[mask],\n",
    "            target_names=list(task_names),\n",
    "            output_dict=True, zero_division=0\n",
    "        )\n",
    "        row = {\n",
    "            \"slice\": sname,\n",
    "            \"support\": n,\n",
    "            \"accuracy\": rep[\"accuracy\"],\n",
    "            \"macro_f1\": rep[\"macro avg\"][\"f1-score\"],\n",
    "        }\n",
    "        for tname in task_names:\n",
    "            row[f\"f1_{tname}\"] = rep[tname][\"f1-score\"]\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    # Sort slices by support (desc) for readability\n",
    "    df = df.sort_values(by=\"support\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Where to save things\n",
    "DETAILS_DIR = os.path.join(OUT_DIR, \"details\")\n",
    "os.makedirs(DETAILS_DIR, exist_ok=True)\n",
    "\n",
    "all_breakdowns = {}\n",
    "\n",
    "for key in MODELS_TO_RUN:\n",
    "    print(f\"\\n=== Detailed breakdowns for {key} ===\")\n",
    "    ysent_pred, ypol_pred = pred_cache[key]\n",
    "\n",
    "    # ---- Per-class reports on the full test set\n",
    "    sent_per_class = per_class_breakdown(ysent_test, ysent_pred, sent_le.classes_)\n",
    "    pol_per_class  = per_class_breakdown(ypol_test,  ypol_pred,  pol_le.classes_)\n",
    "\n",
    "    # Save + show\n",
    "    sent_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_per_class.csv\")\n",
    "    pol_csv  = os.path.join(DETAILS_DIR, f\"{key}_polarization_per_class.csv\")\n",
    "    sent_per_class.to_csv(sent_csv, index=False)\n",
    "    pol_per_class.to_csv(pol_csv, index=False)\n",
    "\n",
    "    print(\"\\nSentiment â€” per class (precision/recall/F1/support):\")\n",
    "    display(sent_per_class)\n",
    "\n",
    "    print(\"\\nPolarization â€” per class (precision/recall/F1/support):\")\n",
    "    display(pol_per_class)\n",
    "\n",
    "    # ---- Cross-slice reports\n",
    "    # Polarity performance within each (true) sentiment slice\n",
    "    pol_given_sent = cross_slice_breakdown(\n",
    "        slice_true=ysent_test, slice_names=sent_le.classes_,\n",
    "        task_true=ypol_test,   task_pred=ypol_pred, task_names=pol_le.classes_,\n",
    "        slice_label=\"sentiment\"\n",
    "    )\n",
    "    pol_given_sent_csv = os.path.join(DETAILS_DIR, f\"{key}_polarity_given_sentiment.csv\")\n",
    "    pol_given_sent.to_csv(pol_given_sent_csv, index=False)\n",
    "\n",
    "    print(\"\\nPolarity performance within each Sentiment slice (accuracy / macro-F1 / per-class F1):\")\n",
    "    display(pol_given_sent)\n",
    "\n",
    "    # Sentiment performance within each (true) polarity slice\n",
    "    sent_given_pol = cross_slice_breakdown(\n",
    "        slice_true=ypol_test,  slice_names=pol_le.classes_,\n",
    "        task_true=ysent_test,  task_pred=ysent_pred, task_names=sent_le.classes_,\n",
    "        slice_label=\"polarity\"\n",
    "    )\n",
    "    sent_given_pol_csv = os.path.join(DETAILS_DIR, f\"{key}_sentiment_given_polarity.csv\")\n",
    "    sent_given_pol.to_csv(sent_given_pol_csv, index=False)\n",
    "\n",
    "    print(\"\\nSentiment performance within each Polarity slice (accuracy / macro-F1 / per-class F1):\")\n",
    "    display(sent_given_pol)\n",
    "\n",
    "    # Keep for a single JSON bundle if you like\n",
    "    all_breakdowns[key] = {\n",
    "        \"sentiment_per_class_csv\": sent_csv,\n",
    "        \"polarization_per_class_csv\": pol_csv,\n",
    "        \"polarity_given_sentiment_csv\": pol_given_sent_csv,\n",
    "        \"sentiment_given_polarity_csv\": sent_given_pol_csv\n",
    "    }\n",
    "\n",
    "# Optional: write an index JSON pointing to all CSVs\n",
    "with open(os.path.join(DETAILS_DIR, \"index.json\"), \"w\") as f:\n",
    "    json.dump(all_breakdowns, f, indent=2)\n",
    "print(\"\\nSaved detailed breakdowns to:\", DETAILS_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q7YNE1ga4-c"
   },
   "source": [
    "### SECTION 11A\n",
    "Formerly 11C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "r9m5OlPQkFZ6",
    "outputId": "68f67e37-9b0c-4497-8058-52936579d1b6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ðŸŽ¯ MULTICLASS CALIBRATION - Optimize prediction biases for better performance\n",
      "======================================================================\n",
      "\n",
      "ðŸ”§ Calibrating xlm_roberta (xlm-roberta-base)...\n",
      "ðŸ“Š Step 1: Extracting polarization logits from trained model...\n",
      "   Loading model from: ./runs_xlm_roberta_run13/xlm_roberta\n",
      "   Warning: No trained weights found at ./runs_xlm_roberta_run13/xlm_roberta/pytorch_model.bin, using untrained model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Loading model from: ./runs_xlm_roberta_run13/xlm_roberta\n",
      "   Warning: No trained weights found at ./runs_xlm_roberta_run13/xlm_roberta/pytorch_model.bin, using untrained model\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   âœ“ Validation logits shape: (1959, 3)\n",
      "   âœ“ Test logits shape: (1960, 3)\n",
      "ðŸ” Step 2: Searching for optimal bias vector (coordinate search)...\n",
      "   âœ“ Optimal bias vector found (VAL macro-F1=0.379):\n",
      "      â€¢ non_polarized: -0.60\n",
      "      â€¢     objective: -0.10\n",
      "      â€¢      partisan: +0.00\n",
      "ðŸ“ˆ Step 3: Evaluating calibration impact on test set...\n",
      "\n",
      "   ðŸ“Š TEST MACRO-F1: 0.164 â†’ 0.377 (+0.213)\n",
      "\n",
      "   Per-class breakdown:\n",
      "   ðŸ“‰ non_polarized: P=0.328 R=1.000 F1=0.493 (n=642)  â†’  P=0.375 R=0.419 F1=0.396 (-0.098)\n",
      "   ðŸ“ˆ     objective: P=0.000 R=0.000 F1=0.000 (n=189)  â†’  P=0.161 R=0.101 F1=0.124 (+0.124)\n",
      "   ðŸ“ˆ      partisan: P=0.000 R=0.000 F1=0.000 (n=1129)  â†’  P=0.614 R=0.611 F1=0.613 (+0.613)\n",
      "\n",
      "âœ… Calibration complete! Bias vector saved to:\n",
      "   ./runs_xlm_roberta_run13/calibration_vector/xlm_roberta_bias_vector.json\n",
      "\n",
      "======================================================================\n",
      "ðŸŽ‰ CALIBRATION FINISHED - All models optimized!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SECTION 11C â€” MULTICLASS POLARITY CALIBRATION (v2)\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np, json, os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments, DataCollatorWithPadding\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions for Calibration\n",
    "# ============================================================================\n",
    "\n",
    "class _PlainPairDS(Dataset):\n",
    "    \"\"\"Simple dataset for inference-only (no labels needed)\"\"\"\n",
    "    def __init__(self, titles, texts, tokenizer, max_length=224):\n",
    "        self.titles, self.texts = list(titles), list(texts)\n",
    "        self.tok = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_tt = \"token_type_ids\" in tokenizer.model_input_names\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tok(\n",
    "            text=str(self.titles[idx]),\n",
    "            text_pair=str(self.texts[idx]),\n",
    "            truncation=\"only_second\",\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=self.use_tt\n",
    "        )\n",
    "\n",
    "def _get_pol_logits(model_key, titles, texts):\n",
    "    \"\"\"Get polarization logits from trained model\"\"\"\n",
    "    # Load tokenizer and model\n",
    "    run_dir = os.path.join(OUT_DIR, model_key)\n",
    "    model_name = MODEL_CONFIGS[model_key][\"name\"]\n",
    "\n",
    "    print(f\"   Loading model from: {run_dir}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(run_dir if os.path.exists(os.path.join(run_dir, \"tokenizer.json\")) else model_name)\n",
    "\n",
    "    # Rebuild model and load weights\n",
    "    model = MultiTaskModel(model_name, num_sent_classes, num_pol_classes)\n",
    "\n",
    "    # Load weights\n",
    "    model_file = os.path.join(run_dir, \"pytorch_model.bin\")\n",
    "    if os.path.exists(model_file):\n",
    "        model.load_state_dict(torch.load(model_file, map_location=device), strict=False)\n",
    "    else:\n",
    "        print(f\"   Warning: No trained weights found at {model_file}, using untrained model\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Create dataset and trainer\n",
    "    collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=os.path.join(run_dir, \"calib_tmp\"),\n",
    "        per_device_eval_batch_size=64,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    dummy_trainer = MultiTaskTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        data_collator=collator,\n",
    "        class_weights=None,\n",
    "        task_weights=None\n",
    "    )\n",
    "\n",
    "    ds = _PlainPairDS(titles, texts, tokenizer, MAX_LENGTH)\n",
    "    out = dummy_trainer.predict(ds)\n",
    "    _, pol_logits = out.predictions\n",
    "\n",
    "    return pol_logits\n",
    "\n",
    "# ============================================================================\n",
    "# Calibration Functions\n",
    "# ============================================================================\n",
    "\n",
    "def coord_search_biases(pol_logits_val, y_val, class_names, passes=2, grid=(-0.8, 0.8, 0.1)):\n",
    "    lo, hi, step = grid\n",
    "    C = pol_logits_val.shape[1]\n",
    "    b = np.zeros(C, dtype=np.float32)\n",
    "\n",
    "    def macro_f1_with(bias_vec):\n",
    "        y_pred = np.argmax(pol_logits_val + bias_vec.reshape(1, -1), axis=1)\n",
    "        rep = classification_report(y_val, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "        return rep[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    best = macro_f1_with(b)\n",
    "    for _ in range(passes):\n",
    "        improved = False\n",
    "        for c in range(C):\n",
    "            best_b_c, best_score_c = b[c], best\n",
    "            for val in np.arange(lo, hi + 1e-9, step):\n",
    "                b_try = b.copy()\n",
    "                b_try[c] = val\n",
    "                score = macro_f1_with(b_try)\n",
    "                if score > best_score_c + 1e-6:\n",
    "                    best_score_c, best_b_c = score, val\n",
    "            if best_b_c != b[c]:\n",
    "                b[c] = best_b_c\n",
    "                best = best_score_c\n",
    "                improved = True\n",
    "        if not improved:\n",
    "            break\n",
    "    return b, float(best)\n",
    "\n",
    "CALIB_DIR2 = os.path.join(OUT_DIR, \"calibration_vector\")\n",
    "os.makedirs(CALIB_DIR2, exist_ok=True)\n",
    "\n",
    "print(\"ðŸŽ¯ MULTICLASS CALIBRATION - Optimize prediction biases for better performance\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for key in MODELS_TO_RUN:\n",
    "    print(f\"\\nðŸ”§ Calibrating {key} ({MODEL_CONFIGS[key]['name']})...\")\n",
    "\n",
    "    print(f\"ðŸ“Š Step 1: Extracting polarization logits from trained model...\")\n",
    "    pol_val_logits = _get_pol_logits(key, X_val[TITLE_COL].values,  X_val[TEXT_COL].values)\n",
    "    pol_tst_logits = _get_pol_logits(key, X_test[TITLE_COL].values, X_test[TEXT_COL].values)\n",
    "    print(f\"   âœ“ Validation logits shape: {pol_val_logits.shape}\")\n",
    "    print(f\"   âœ“ Test logits shape: {pol_tst_logits.shape}\")\n",
    "\n",
    "    y_val = ypol_val\n",
    "    y_tst = ypol_test\n",
    "    class_names = list(pol_le.classes_)\n",
    "\n",
    "    print(f\"ðŸ” Step 2: Searching for optimal bias vector (coordinate search)...\")\n",
    "    b_vec, val_macro = coord_search_biases(pol_val_logits, y_val, class_names, passes=3, grid=(-0.8, 0.8, 0.1))\n",
    "    print(f\"   âœ“ Optimal bias vector found (VAL macro-F1={val_macro:.3f}):\")\n",
    "    for cname, bias_val in zip(class_names, b_vec):\n",
    "        print(f\"      â€¢ {cname:>13}: {bias_val:+.2f}\")\n",
    "\n",
    "    # Test before/after\n",
    "    print(f\"ðŸ“ˆ Step 3: Evaluating calibration impact on test set...\")\n",
    "    y_before = np.argmax(pol_tst_logits, axis=1)\n",
    "    rep_before = classification_report(y_tst, y_before, target_names=class_names, output_dict=True, zero_division=0)\n",
    "\n",
    "    y_after = np.argmax(pol_tst_logits + b_vec.reshape(1, -1), axis=1)\n",
    "    rep_after  = classification_report(y_tst, y_after, target_names=class_names, output_dict=True, zero_division=0)\n",
    "\n",
    "    improvement = rep_after['macro avg']['f1-score'] - rep_before['macro avg']['f1-score']\n",
    "    print(f\"\\n   ðŸ“Š TEST MACRO-F1: {rep_before['macro avg']['f1-score']:.3f} â†’ {rep_after['macro avg']['f1-score']:.3f} ({improvement:+.3f})\\n\")\n",
    "    print(\"   Per-class breakdown:\")\n",
    "    for cname in class_names:\n",
    "        b = rep_before[cname]; a = rep_after[cname]\n",
    "        f1_change = a['f1-score'] - b['f1-score']\n",
    "        emoji = \"ðŸ“ˆ\" if f1_change > 0 else \"ðŸ“‰\" if f1_change < 0 else \"âž¡ï¸\"\n",
    "        print(f\"   {emoji} {cname:>13}: P={b['precision']:.3f} R={b['recall']:.3f} F1={b['f1-score']:.3f} (n={int(b['support'])})\"\n",
    "              f\"  â†’  P={a['precision']:.3f} R={a['recall']:.3f} F1={a['f1-score']:.3f} ({f1_change:+.3f})\")\n",
    "\n",
    "    # Save calibration results\n",
    "    calib_file = os.path.join(CALIB_DIR2, f\"{key}_bias_vector.json\")\n",
    "    with open(calib_file, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"bias_vector\": {class_names[i]: float(b_vec[i]) for i in range(len(class_names))},\n",
    "            \"val_macro_f1\": val_macro,\n",
    "            \"test_macro_f1_before\": float(rep_before[\"macro avg\"][\"f1-score\"]),\n",
    "            \"test_macro_f1_after\":  float(rep_after[\"macro avg\"][\"f1-score\"])\n",
    "        }, f, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… Calibration complete! Bias vector saved to:\")\n",
    "    print(f\"   {calib_file}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ðŸŽ‰ CALIBRATION FINISHED - All models optimized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCGT3gEDcN9X"
   },
   "source": [
    "## SECTION 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "NhPV4I6TcP53",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2d3e8ce0-3a84-429a-a8d2-befbf97efdcd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "[xlm_roberta] xlm-roberta-base\n",
      "Token length stats: {'mean': 107.0766, 'p50': 96.0, 'p90': 170.0, 'p95': 183.0, 'p99': 223.02000000000044, 'max': 950}\n",
      "âœ… SECTION 11+: Evaluation & Calibration completed in 6.2m 12s\n",
      "ðŸ•’ Total runtime so far: 1.5h 28m\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "â±ï¸  EXECUTION TIME SUMMARY\n",
      "============================================================\n",
      "SECTION 2: Environment & Imports         : 5.0s\n",
      "SECTION 3: Configuration Setup           : 0.0s\n",
      "SECTION 4: Data Loading & Preprocessing  : 40.8s\n",
      "SECTION 5-9: Model Architecture & Training Setup : 10.7s\n",
      "SECTION 10: Model Training Execution     : 1.3h 21m\n",
      "SECTION 11+: Evaluation & Calibration    : 6.2m 12s\n",
      "======================================== : ==========\n",
      "TOTAL EXECUTION TIME                     : 1.5h 28m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ===== Section 12 â€” Length Diagnostics (clean) =====\n",
    "import warnings\n",
    "\n",
    "def token_lengths_summary(texts, titles, tokenizer, n=5000):\n",
    "    # Random sample (or full if dataset is small)\n",
    "    n = min(n, len(texts))\n",
    "    idx = np.random.choice(len(texts), size=n, replace=False) if len(texts) > n else np.arange(len(texts))\n",
    "\n",
    "    lengths = []\n",
    "    # Silence the \"sequence > 512\" warnings emitted by some tokenizers for inspection\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", message=\"Token indices sequence length is longer.*\")\n",
    "        for i in idx:\n",
    "            s = f\"{titles[i]} [SEP] {texts[i]}\"\n",
    "            # We want raw length pre-truncation to choose MAX_LENGTH wisely\n",
    "            ids = tokenizer.encode(s, add_special_tokens=True, truncation=False)\n",
    "            lengths.append(len(ids))\n",
    "\n",
    "    arr = np.array(lengths)\n",
    "    stats = {\n",
    "        \"mean\": float(arr.mean()),\n",
    "        \"p50\":  float(np.percentile(arr, 50)),\n",
    "        \"p90\":  float(np.percentile(arr, 90)),\n",
    "        \"p95\":  float(np.percentile(arr, 95)),\n",
    "        \"p99\":  float(np.percentile(arr, 99)),\n",
    "        \"max\":  int(arr.max())\n",
    "    }\n",
    "    print(\"Token length stats:\", stats)\n",
    "    return stats\n",
    "\n",
    "for key in MODELS_TO_RUN:\n",
    "    name = MODEL_CONFIGS[key][\"name\"]\n",
    "    tok = AutoTokenizer.from_pretrained(name)\n",
    "    print(f\"\\n[{key}] {name}\")\n",
    "    token_lengths_summary(\n",
    "        texts=X_train[TEXT_COL].values,\n",
    "        titles=X_train[TITLE_COL].values,\n",
    "        tokenizer=tok,\n",
    "        n=5000\n",
    "    )\n",
    "\n",
    "# Tip:\n",
    "# If p95 is comfortably < 192, you're fine. If you see p95 > 192, consider MAX_LENGTH=224\n",
    "# (Update in Section 3 if you decide to bump it.)\n",
    "\n",
    "# Final timing summary\n",
    "timer.end_section(\"SECTION 11+: Evaluation & Calibration\")\n",
    "timer.get_summary()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "toc_visible": true,
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "ac98b5d3dc1144c09f0f9fb24c789d44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_342e71f582ff4a66845b483a11bac671",
       "IPY_MODEL_59fb778f256f444a850f634b1646314d",
       "IPY_MODEL_0175eefc9bf647deae27658864c1f865"
      ],
      "layout": "IPY_MODEL_2445b9bab3b34857a63a5c9cd90676a5"
     }
    },
    "342e71f582ff4a66845b483a11bac671": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a58712652de141bca5fc836c014a201e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_26734b469d464ee68e56c85549cb182d",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "59fb778f256f444a850f634b1646314d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8bbd9bbcf1144109d4dfc61c2d06f37",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7df97acc02fe4fb9b951d09bfaa527de",
      "value": 25
     }
    },
    "0175eefc9bf647deae27658864c1f865": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8e8485a3c4b4a22b3c0847826012d5e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_57d43ceae54f4752992836b266341d8a",
      "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡3.19kB/s]"
     }
    },
    "2445b9bab3b34857a63a5c9cd90676a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58712652de141bca5fc836c014a201e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26734b469d464ee68e56c85549cb182d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8bbd9bbcf1144109d4dfc61c2d06f37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7df97acc02fe4fb9b951d09bfaa527de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8e8485a3c4b4a22b3c0847826012d5e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57d43ceae54f4752992836b266341d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d18c4daa45984195aaa14c98f4f8c3ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6c84ce403764b25a455d0400097ca83",
       "IPY_MODEL_8e39c02a48924536b5252c845a26fb95",
       "IPY_MODEL_e90196b7d3444476aafde2870d2f67ea"
      ],
      "layout": "IPY_MODEL_1742957ba814493a9650bdc3b2d582f6"
     }
    },
    "c6c84ce403764b25a455d0400097ca83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1b6669197b345c4827af28464b424ef",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c5a5e22fb5e340a7929e03e9926f30f1",
      "value": "config.json:â€‡100%"
     }
    },
    "8e39c02a48924536b5252c845a26fb95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_859091769b32452dbcd6165ead4062d7",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_859f1205c3a74c238519032470ce2104",
      "value": 615
     }
    },
    "e90196b7d3444476aafde2870d2f67ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a4f67fb284d4431b0afc0b1a38d5f46",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_48ef93b086154b2d91e91426398aa6ff",
      "value": "â€‡615/615â€‡[00:00&lt;00:00,â€‡87.2kB/s]"
     }
    },
    "1742957ba814493a9650bdc3b2d582f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1b6669197b345c4827af28464b424ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a5e22fb5e340a7929e03e9926f30f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "859091769b32452dbcd6165ead4062d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "859f1205c3a74c238519032470ce2104": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a4f67fb284d4431b0afc0b1a38d5f46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48ef93b086154b2d91e91426398aa6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50cb9220a0e44eabb44e15a3baba8f82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_791c40444fc84dc18716ca8006383a6f",
       "IPY_MODEL_f3fbbbc76f454fd1883b6ac017d8006c",
       "IPY_MODEL_54d3b412dbde40d69e357857184256fc"
      ],
      "layout": "IPY_MODEL_59a2cea8fe86442da9b31ea111bac610"
     }
    },
    "791c40444fc84dc18716ca8006383a6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4f568cd8e5843ae952f5f79177963c4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_91c0b0d7d49b4b188b06cd8e67fda2f2",
      "value": "sentencepiece.bpe.model:â€‡100%"
     }
    },
    "f3fbbbc76f454fd1883b6ac017d8006c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00a2142c74cd422185a5d398eff22a27",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78d74012e21647abac53ccbffa617f68",
      "value": 5069051
     }
    },
    "54d3b412dbde40d69e357857184256fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b14114509df54190a045630f155a5cdb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e18ea15456fa4edb8131e94d1b3f69a4",
      "value": "â€‡5.07M/5.07Mâ€‡[00:00&lt;00:00,â€‡22.2MB/s]"
     }
    },
    "59a2cea8fe86442da9b31ea111bac610": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4f568cd8e5843ae952f5f79177963c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91c0b0d7d49b4b188b06cd8e67fda2f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "00a2142c74cd422185a5d398eff22a27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78d74012e21647abac53ccbffa617f68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b14114509df54190a045630f155a5cdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e18ea15456fa4edb8131e94d1b3f69a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e31832b374494c88b83dc4aa965d2438": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2f13a6a184d42d5a9af4e30d35e5dd3",
       "IPY_MODEL_5783152de22c425fa3b1784682e3fef9",
       "IPY_MODEL_75382b27edc24f2b9ff8b5d20c4438ac"
      ],
      "layout": "IPY_MODEL_a7dd8dee3c584dab8f35df96907a6e9d"
     }
    },
    "f2f13a6a184d42d5a9af4e30d35e5dd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ef3e6ba26cb4d06b393ead22b29a311",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0dafe1bb25c24009bffd4c0b9d3dcbd4",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "5783152de22c425fa3b1784682e3fef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_caef5d45c572400a98552764d6966dc2",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad5cdcd75d6a48ce8cd258716393b3cf",
      "value": 9096718
     }
    },
    "75382b27edc24f2b9ff8b5d20c4438ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d41e42c58584426a92b573544073a6ca",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9c38aa92b909431c9f015707b6b3bbf2",
      "value": "â€‡9.10M/9.10Mâ€‡[00:00&lt;00:00,â€‡25.2MB/s]"
     }
    },
    "a7dd8dee3c584dab8f35df96907a6e9d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ef3e6ba26cb4d06b393ead22b29a311": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dafe1bb25c24009bffd4c0b9d3dcbd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caef5d45c572400a98552764d6966dc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad5cdcd75d6a48ce8cd258716393b3cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d41e42c58584426a92b573544073a6ca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c38aa92b909431c9f015707b6b3bbf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba7202fa4a9d46da951e5104a0378423": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e3b9f486192429aa1d1ac6f3e3feb96",
       "IPY_MODEL_f1cd618b11704d55a6463e75817212f7",
       "IPY_MODEL_82072ff4bf4a4c32994a360d8f3f6c22"
      ],
      "layout": "IPY_MODEL_39c0907358fa44ac97d57e36abe602dd"
     }
    },
    "5e3b9f486192429aa1d1ac6f3e3feb96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c3c61a9faa148b0b9d7b23c6bb17b95",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_04e8057c90de4fa6941bc92fac914900",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "f1cd618b11704d55a6463e75817212f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ed7000438394f0eb0a9c74adb6a5aa4",
      "max": 1115567652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fca038edd904435eba922ad7a20ad5e3",
      "value": 1115567652
     }
    },
    "82072ff4bf4a4c32994a360d8f3f6c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aaffdef901f4b9cb39811e6a0c156fb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d2870ead377f495c9ca51fbbd5b96730",
      "value": "â€‡1.12G/1.12Gâ€‡[00:02&lt;00:00,â€‡914MB/s]"
     }
    },
    "39c0907358fa44ac97d57e36abe602dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c3c61a9faa148b0b9d7b23c6bb17b95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e8057c90de4fa6941bc92fac914900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ed7000438394f0eb0a9c74adb6a5aa4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fca038edd904435eba922ad7a20ad5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2aaffdef901f4b9cb39811e6a0c156fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2870ead377f495c9ca51fbbd5b96730": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}